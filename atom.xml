<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>鄢玉兵的博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://yanyubing.xyz/"/>
  <updated>2020-10-20T09:23:30.567Z</updated>
  <id>https://yanyubing.xyz/</id>
  
  <author>
    <name>鄢玉兵</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>实例分割</title>
    <link href="https://yanyubing.xyz/2020/10/20/%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2/"/>
    <id>https://yanyubing.xyz/2020/10/20/%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2/</id>
    <published>2020-10-20T09:16:23.229Z</published>
    <updated>2020-10-20T09:23:30.567Z</updated>
    
    <content type="html"><![CDATA[<h1 id="实例分割"><a href="#实例分割" class="headerlink" title="实例分割"></a>实例分割</h1><p>1.对比与目标检测，更加的精确，获取的每个像素值对应的对象，基于pytorch框架</p><p>yolact</p><p>源码：<a href="https://github.com/dbolya/yolact" target="_blank" rel="noopener">https://github.com/dbolya/yolact</a></p><p>教程：<a href="https://www.youtube.com/watch?v=KEHVHHnNDv0" target="_blank" rel="noopener">https://www.youtube.com/watch?v=KEHVHHnNDv0</a></p><p>mask rcnn</p><p>源码：<a href="https://github.com/facebookresearch/maskrcnn-benchmark" target="_blank" rel="noopener">https://github.com/facebookresearch/maskrcnn-benchmark</a></p><p>教程：<a href="https://www.youtube.com/watch?v=yltGEJxrrqQ" target="_blank" rel="noopener">https://www.youtube.com/watch?v=yltGEJxrrqQ</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;实例分割&quot;&gt;&lt;a href=&quot;#实例分割&quot; class=&quot;headerlink&quot; title=&quot;实例分割&quot;&gt;&lt;/a&gt;实例分割&lt;/h1&gt;&lt;p&gt;1.对比与目标检测，更加的精确，获取的每个像素值对应的对象，基于pytorch框架&lt;/p&gt;
&lt;p&gt;yolact&lt;/p&gt;
&lt;p
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>数据读取</title>
    <link href="https://yanyubing.xyz/2020/10/20/%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96/"/>
    <id>https://yanyubing.xyz/2020/10/20/%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96/</id>
    <published>2020-10-20T06:13:50.788Z</published>
    <updated>2020-10-20T07:43:57.681Z</updated>
    
    <content type="html"><![CDATA[<h1 id="python进行数据的读取，储存"><a href="#python进行数据的读取，储存" class="headerlink" title="python进行数据的读取，储存"></a>python进行数据的读取，储存</h1><p>一：数据的主要形式</p><p>文本，视频，音频，MySQL数据库</p><p>二：文本</p><p><a href="https://zhuanlan.zhihu.com/p/25087295" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25087295</a></p><p>三：视频</p><p><a href="https://blog.csdn.net/qq_25436597/article/details/79621833" target="_blank" rel="noopener">https://blog.csdn.net/qq_25436597/article/details/79621833</a></p><p>四：音频</p><p><a href="https://blog.csdn.net/luolinll1212/article/details/97954215" target="_blank" rel="noopener">https://blog.csdn.net/luolinll1212/article/details/97954215</a></p><p>五：MySQL</p><p><a href="https://my.oschina.net/u/3750423/blog/4315037" target="_blank" rel="noopener">https://my.oschina.net/u/3750423/blog/4315037</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;python进行数据的读取，储存&quot;&gt;&lt;a href=&quot;#python进行数据的读取，储存&quot; class=&quot;headerlink&quot; title=&quot;python进行数据的读取，储存&quot;&gt;&lt;/a&gt;python进行数据的读取，储存&lt;/h1&gt;&lt;p&gt;一：数据的主要形式&lt;/p&gt;

      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>torch环境准备</title>
    <link href="https://yanyubing.xyz/2020/10/19/torch%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/"/>
    <id>https://yanyubing.xyz/2020/10/19/torch%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/</id>
    <published>2020-10-19T09:28:17.185Z</published>
    <updated>2020-10-21T03:24:00.055Z</updated>
    
    <content type="html"><![CDATA[<h1 id="torch环境准备"><a href="#torch环境准备" class="headerlink" title="torch环境准备"></a>torch环境准备</h1><p>①装系统</p><p><a href="https://blog.csdn.net/baidu_36602427/article/details/86548203" target="_blank" rel="noopener">https://blog.csdn.net/baidu_36602427/article/details/86548203</a></p><p>②安装向日葵</p><p>方便远程，可以继续安装其他比较耗时的软件</p><p><a href="https://sunlogin.oray.com/download/" target="_blank" rel="noopener">https://sunlogin.oray.com/download/</a></p><p>③输入法</p><p><a href="https://www.jianshu.com/p/cafe12618293" target="_blank" rel="noopener">https://www.jianshu.com/p/cafe12618293</a></p><p>④安装pycharm</p><p><a href="https://blog.csdn.net/HelloZEX/article/details/80747274" target="_blank" rel="noopener">https://blog.csdn.net/HelloZEX/article/details/80747274</a></p><p>⑤安装anconda，创建yolov5虚拟环境</p><p><a href="https://blog.csdn.net/BigData_Mining/article/details/102954343" target="_blank" rel="noopener">https://blog.csdn.net/BigData_Mining/article/details/102954343</a></p><p>⑥下载yolov5源码</p><p><a href="https://github.com/ultralytics/yolov5" target="_blank" rel="noopener">https://github.com/ultralytics/yolov5</a></p><p>⑦yolov5虚拟环境依赖包的配置<br>⑧配置cuda，cudnn，安装pytorch</p><p><a href="https://blog.csdn.net/u013084111/article/details/104167056" target="_blank" rel="noopener">https://blog.csdn.net/u013084111/article/details/104167056</a></p><p>⑨下载权重文件<br>⑩demo测试</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;torch环境准备&quot;&gt;&lt;a href=&quot;#torch环境准备&quot; class=&quot;headerlink&quot; title=&quot;torch环境准备&quot;&gt;&lt;/a&gt;torch环境准备&lt;/h1&gt;&lt;p&gt;①装系统&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>course.fast.ai</title>
    <link href="https://yanyubing.xyz/2020/10/19/course.fast.ai/"/>
    <id>https://yanyubing.xyz/2020/10/19/course.fast.ai/</id>
    <published>2020-10-19T08:13:12.180Z</published>
    <updated>2020-10-21T03:08:44.502Z</updated>
    
    <content type="html"><![CDATA[<h1 id="course-fast-ai"><a href="#course-fast-ai" class="headerlink" title="course.fast.ai"></a>course.fast.ai</h1><p><a href="https://course.fast.ai" target="_blank" rel="noopener">https://course.fast.ai</a></p><h3 id="一：小tips"><a href="#一：小tips" class="headerlink" title="一：小tips"></a>一：小tips</h3><p>1.Mac不支持英伟达GPU</p><p>2.找模型的过程就是优化权值的过程：权值分配</p><p>3.SGD(随机梯度下降)：用来更新权值</p><p>4.神经网络的本质只是加法和乘法的运算，只是会运行很多很多次</p><p>5.本质：(输入,权值)得到预测值，预测值和label对比得到loss，loss反过来调整权值。我们需要的是data和label。</p><p>6.bing有搜索图片的API</p><h3 id="二：过拟合"><a href="#二：过拟合" class="headerlink" title="二：过拟合"></a>二：过拟合</h3><p>1.产生过拟合的原因</p><p>模型复杂程度是相对的，复杂的模型可能会造成过拟合。</p><p>2.过拟合的表现形式</p><p>训练损失继续下降，而验证集损失开始上升</p><h3 id="三：迁移学习"><a href="#三：迁移学习" class="headerlink" title="三：迁移学习"></a>三：迁移学习</h3><p>1.怎么做</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;course-fast-ai&quot;&gt;&lt;a href=&quot;#course-fast-ai&quot; class=&quot;headerlink&quot; title=&quot;course.fast.ai&quot;&gt;&lt;/a&gt;course.fast.ai&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://cours
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>瑕疵检测</title>
    <link href="https://yanyubing.xyz/2020/10/19/%E7%91%95%E7%96%B5%E6%A3%80%E6%B5%8B/"/>
    <id>https://yanyubing.xyz/2020/10/19/%E7%91%95%E7%96%B5%E6%A3%80%E6%B5%8B/</id>
    <published>2020-10-19T05:54:04.809Z</published>
    <updated>2020-10-19T05:57:13.674Z</updated>
    
    <content type="html"><![CDATA[<p>​                                                                   瓦片裂痕检测</p><h2 id="传统算法方向的选择"><a href="#传统算法方向的选择" class="headerlink" title="传统算法方向的选择"></a>传统算法方向的选择</h2><p>最近做图像处理与识别相关的事情，先从OpenCV/Matlab入手，看传统算法在瑕疵检测方向能做到什么程度。</p><p>因之前并没有相关的经验，乍开始生怕闭门造车，遂多方搜寻，相关的会议与论述很多，不乏深度学习或者深度学习与传统算法相结合的，以有限的资源来看，深度学习并没有特别大的优势：表现在</p><ol><li><p>深度学习对训练图库的要求很高，很难得到很好的训练结果</p></li><li><p>深度学习的灵活度较低，若适用场景有些许改变，均需要重新训练，这在商用时会是很大的问题</p></li><li><p>深度学习的部署成本较高，同时对部署场景有较高要求（光线/摄像效果等）*<br>当然，深度学习大势所趋，也不必因噎废食，万一是一时的浅见呢。后续也会投身到这个方向去。</p></li></ol><h2 id="瑕疵检测关注的两个问题"><a href="#瑕疵检测关注的两个问题" class="headerlink" title="瑕疵检测关注的两个问题"></a>瑕疵检测关注的两个问题</h2><h3 id="瑕疵的标注"><a href="#瑕疵的标注" class="headerlink" title="瑕疵的标注"></a>瑕疵的标注</h3><p>对瑕疵的标注是为了更直观的展示，主要是给人看的</p><h3 id="瑕疵的量化"><a href="#瑕疵的量化" class="headerlink" title="瑕疵的量化"></a>瑕疵的量化</h3><p>真正机器关心的是怎么量化，是用数量表示还是百分比是个值得考虑的问题</p><h2 id="历程"><a href="#历程" class="headerlink" title="历程"></a>历程</h2><h3 id="1-图像去噪-gt-灰度化-gt-二值化"><a href="#1-图像去噪-gt-灰度化-gt-二值化" class="headerlink" title="1.图像去噪-&gt;灰度化-&gt;二值化"></a>1.图像去噪-&gt;灰度化-&gt;二值化</h3><p>二值化之后就可以看到绝大部分的瑕疵点已经凸显出来了，但是有三个问题：</p><ol><li>黑点瑕疵与白点瑕疵是二值化的两个极端，故无法同时出现。</li><li>量化如何去除Logo与其他印刷的干扰<br>问题1后续用边缘检测替代<br>问题2采用像素点计数的方法，计算百分比，然后与无瑕疵的百分比作比较，准确度不高，也显得 low的。</li></ol><h3 id="2-图像去噪-gt-灰度化-gt-canny-gt-形态学（闭运算）-gt-连通域"><a href="#2-图像去噪-gt-灰度化-gt-canny-gt-形态学（闭运算）-gt-连通域" class="headerlink" title="2.图像去噪-&gt;灰度化-&gt;canny-&gt;形态学（闭运算）-&gt;连通域"></a>2.图像去噪-&gt;灰度化-&gt;canny-&gt;形态学（闭运算）-&gt;连通域</h3><p>边缘检测后进行闭运算，瑕疵会形成大大小小的连通域，可以统计连通域的个数，然后与无瑕疵logo与其他印刷形成的连通域个数作比较，这种情况几乎不会漏掉。这是感觉可行的选择之一。</p><h3 id="3-OpenCV-matchTemplate"><a href="#3-OpenCV-matchTemplate" class="headerlink" title="3.OpenCV matchTemplate"></a>3.OpenCV matchTemplate</h3><p>实验室条件下，可以营造比较理想的条件，所以考虑了OpenCV的模板匹配，同时也测试了模板匹配在不理想情况下的表现。<br>结果证明因为手机瑕疵检测的需求目标较低，模板匹配是比较能够胜任的一个办法。只要模板与识别目标的拍摄角度差别不是太大，都可以很好的识别瑕疵。图片的轻微缩放大多也可以应付。</p><h2 id="其他处理"><a href="#其他处理" class="headerlink" title="其他处理"></a>其他处理</h2><p>前面都是软件方面处理的流程，在如何获得更加理想的图片方面也做了一些尝试：</p><ol><li>采用各种不同颜色的光源，如蓝光/红光，区别不大</li><li>对图片进行白平衡调整，有改善</li><li>摄像头加偏振镜防止图像反光，有改善但不明显</li><li>图片浮雕处理，肉眼看上去瑕疵显著了，但对机器而言并没有区别，故没有采纳</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;​                                                                   瓦片裂痕检测&lt;/p&gt;
&lt;h2 id=&quot;传统算法方向的选择&quot;&gt;&lt;a href=&quot;#传统算法方向的选择&quot; class=&quot;headerlink&quot;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>数据集</title>
    <link href="https://yanyubing.xyz/2020/08/28/%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    <id>https://yanyubing.xyz/2020/08/28/%E6%95%B0%E6%8D%AE%E9%9B%86/</id>
    <published>2020-08-28T02:10:47.267Z</published>
    <updated>2020-08-28T02:33:26.869Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><p>1.数据是算法的粮食，没有好的数据，算法再优秀，也生产不出来好的模型；作为AI工程师，最开始就要了解公司数据的产生过程，才可以很好的把控模型的优劣</p><p>2.目标检测/分类、数据集制作过程应该有详细的生成流程，包括如下：</p><p>①数据集产生的基本要求（应当与模型实际工作环境尽量保持一致或者，同时需要包含到工作环境中的一切可能性，例如图片的输入大小。。。）</p><p>②数据集的产生，采样过程（如无人机飞行录制视频、拍照等形式）</p><p>③定标注种类，定标注要求（与实际业务挂钩）</p><p>④组织标注人员，审查人员（对工作量的预估，每天可以生产多少数据，费用计算。。。）</p><p>⑤数据集合格之后进行模型训练，对比训练效果，进行微调来增加精度</p><p>⑥精度达到一定程度的时候，开始直接使用模型来标注数据集，标注错误的地方人工修改</p><p>3.补充</p><p>①数据的生成过程中需要大量的人工操作，其中部分可以使用代码处理可以节约大量的时间</p><p>如：</p><p>数据标注文本规范的检查（yolo对应的box字段为5个，如果哪一行出现了10个字段，则会导致代码报错）</p><p>类别的检测（裁剪出box保存到对应类别目录下，box文件名中包含原始图片的文件名，检测标注类别是否准确，修改），同时也做了类别的统计</p><p>②数据生产过程应当作为一个流水线的工作形态，直到完成最优模型之前，一直需要；标注的数据出问题，会导致耗费大量的精力来修改，更正，得不偿失!</p><p>③为了达到最优的模型，数据集上面不能掉链子</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;数据集&quot;&gt;&lt;a href=&quot;#数据集&quot; class=&quot;headerlink&quot; title=&quot;数据集&quot;&gt;&lt;/a&gt;数据集&lt;/h1&gt;&lt;p&gt;1.数据是算法的粮食，没有好的数据，算法再优秀，也生产不出来好的模型；作为AI工程师，最开始就要了解公司数据的产生过程，才可以很好的
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>wordpress搭建</title>
    <link href="https://yanyubing.xyz/2020/08/13/wordpress%E6%90%AD%E5%BB%BA/"/>
    <id>https://yanyubing.xyz/2020/08/13/wordpress%E6%90%AD%E5%BB%BA/</id>
    <published>2020-08-13T02:47:04.590Z</published>
    <updated>2020-08-13T02:48:18.180Z</updated>
    
    <content type="html"><![CDATA[<h2 id="—————-环境安装————–"><a href="#—————-环境安装————–" class="headerlink" title="—————-环境安装————–"></a>—————-环境安装————–</h2><p>——–数据库（无法安装成功）<br>sudo apt install mariadb-server mariadb-client -y</p><p>启动mariadb<br>sudo systemctl start mariadb</p><p>查看状态<br>sudo systemctl status mariadb</p><p>######apache2安装<br>sudo apt install apache</p><p>———-php安装<br>sudo apt install php</p><h2 id="—————环境安装—————"><a href="#—————环境安装—————" class="headerlink" title="—————环境安装—————-"></a>—————环境安装—————-</h2><p>参考：<br>注意ubutun18.04LTS直接安装mariadb无法成功：<br><a href="https://computingforgeeks.com/install-mariadb-10-on-ubuntu-18-04-and-centos-7/" target="_blank" rel="noopener">https://computingforgeeks.com/install-mariadb-10-on-ubuntu-18-04-and-centos-7/</a></p><p>主要流程的参考：<br><a href="https://www.youtube.com/watch?v=na-fT9ZgWPM" target="_blank" rel="noopener">https://www.youtube.com/watch?v=na-fT9ZgWPM</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;—————-环境安装————–&quot;&gt;&lt;a href=&quot;#—————-环境安装————–&quot; class=&quot;headerlink&quot; title=&quot;—————-环境安装————–&quot;&gt;&lt;/a&gt;—————-环境安装————–&lt;/h2&gt;&lt;p&gt;——–数据库（无法安装成功）&lt;br&gt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>svn服务器的搭建</title>
    <link href="https://yanyubing.xyz/2020/08/12/svn%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%90%AD%E5%BB%BA/"/>
    <id>https://yanyubing.xyz/2020/08/12/svn%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%90%AD%E5%BB%BA/</id>
    <published>2020-08-12T03:31:41.371Z</published>
    <updated>2020-08-12T03:32:42.361Z</updated>
    
    <content type="html"><![CDATA[<h4 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤:"></a>操作步骤:</h4><p>1.<br>sudo apt-get update</p><p>2.<br>./home/yanyubing/ubuntu-svn-script/setupSVN.sh</p><p>svn仓库地址:<br>/var/lib/svn</p><p>链接地址:<br><a href="http://192.168.16.56/svn/repository/" target="_blank" rel="noopener">http://192.168.16.56/svn/repository/</a></p><p>账号：<br>admin</p><p>密码：<br>123456</p><p>####创建仓库<br>sudo svnadmin create /var/lib/svn/repository2</p><p>####创建仓库之后修改仓库的所有者和所有者的组为www-data<br>sudo chown -R  www-data.www-data /var/lib/svn/repository2</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;操作步骤&quot;&gt;&lt;a href=&quot;#操作步骤&quot; class=&quot;headerlink&quot; title=&quot;操作步骤:&quot;&gt;&lt;/a&gt;操作步骤:&lt;/h4&gt;&lt;p&gt;1.&lt;br&gt;sudo apt-get update&lt;/p&gt;
&lt;p&gt;2.&lt;br&gt;./home/yanyubing/ubun
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>PythonWebCrawler</title>
    <link href="https://yanyubing.xyz/2020/07/12/PythonWebCrawler/"/>
    <id>https://yanyubing.xyz/2020/07/12/PythonWebCrawler/</id>
    <published>2020-07-12T03:28:32.954Z</published>
    <updated>2020-07-12T03:29:07.005Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Python-Web-Crawler"><a href="#Python-Web-Crawler" class="headerlink" title="Python Web Crawler"></a>Python Web Crawler</h1><p>1：</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Python-Web-Crawler&quot;&gt;&lt;a href=&quot;#Python-Web-Crawler&quot; class=&quot;headerlink&quot; title=&quot;Python Web Crawler&quot;&gt;&lt;/a&gt;Python Web Crawler&lt;/h1&gt;&lt;p&gt;1：&lt;/p&gt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>python数据结构和算法</title>
    <link href="https://yanyubing.xyz/2020/07/10/python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    <id>https://yanyubing.xyz/2020/07/10/python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/</id>
    <published>2020-07-10T12:29:46.756Z</published>
    <updated>2020-07-10T13:00:25.462Z</updated>
    
    <content type="html"><![CDATA[<p>一：栈</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># stack</span><br><span class="line"></span><br><span class="line">class Stack():</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.items = []</span><br><span class="line"></span><br><span class="line">    def push(self, item):</span><br><span class="line">        self.items.append(item)</span><br><span class="line"></span><br><span class="line">    def pop(self):</span><br><span class="line">        return self.items.pop()</span><br><span class="line"></span><br><span class="line">    def is_empty(self):</span><br><span class="line">        return self.items == []</span><br><span class="line"></span><br><span class="line">    def peek(self):</span><br><span class="line">        if not self.is_empty():</span><br><span class="line">            return self.items[0]</span><br><span class="line">        else:</span><br><span class="line">            return []</span><br><span class="line"></span><br><span class="line">    def get_stacks(self):</span><br><span class="line">        return self.items</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">s = Stack()</span><br><span class="line">s.push(&apos;a&apos;)</span><br><span class="line">s.push(&apos;b&apos;)</span><br><span class="line">s.push(&apos;c&apos;)</span><br><span class="line">print(s.get_stacks())</span><br><span class="line">s.pop()</span><br><span class="line">print(s.get_stacks())</span><br><span class="line">print(s.peek())</span><br></pre></td></tr></table></figure><p>二：stack_balanced_parens</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># stack_balanced_parens</span><br><span class="line"># 用于ide的括号查全(),[],&#123;&#125;</span><br><span class="line">import sys</span><br><span class="line"></span><br><span class="line">sys.path.append(&apos;D:/yan/python/data_structures_and_algorithms_in_python/&apos;)</span><br><span class="line">from demo01 import Stack_demo</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def is_paren_balanced(paren_string):</span><br><span class="line">    s = Stack_demo()</span><br><span class="line">    for paren in paren_string:</span><br><span class="line">        if is_paren(s.peek(), paren):</span><br><span class="line">            # 匹配则弹出</span><br><span class="line">            s.pop()</span><br><span class="line">        else:  # 不匹配则加入</span><br><span class="line">            s.push(paren)</span><br><span class="line">    if s.is_empty():</span><br><span class="line">        return True</span><br><span class="line">    else:</span><br><span class="line">        return False</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def is_paren(pa1, pa2):</span><br><span class="line">    if pa1 == &apos;(&apos; and pa2 == &apos;)&apos;:</span><br><span class="line">        return True</span><br><span class="line">    if pa1 == &apos;[&apos; and pa2 == &apos;]&apos;:</span><br><span class="line">        return True</span><br><span class="line">    if pa1 == &apos;&#123;&apos; and pa2 == &apos;&#125;&apos;:</span><br><span class="line">        return True</span><br><span class="line">    else:</span><br><span class="line">        return False</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if &apos;__name__&apos; == &apos;__main__&apos;:</span><br><span class="line">    string = &apos;(([]))&apos;</span><br><span class="line">    flag = is_paren_balanced(string)</span><br><span class="line">    print(flag)</span><br></pre></td></tr></table></figure><p>三：</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一：栈&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>leetcode</title>
    <link href="https://yanyubing.xyz/2020/07/05/leetcode/"/>
    <id>https://yanyubing.xyz/2020/07/05/leetcode/</id>
    <published>2020-07-05T12:20:52.390Z</published>
    <updated>2020-07-06T07:52:44.291Z</updated>
    
    <content type="html"><![CDATA[<p>leetcode刷题与总结</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.</span><br><span class="line">https://leetcode-cn.com/problems/add-two-numbers/</span><br><span class="line"></span><br><span class="line">总结:能够用一个循环解决的不要使用多个循环</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2. </span><br><span class="line">https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/</span><br><span class="line"></span><br><span class="line">总结:少写循环，最小子串问题，可以找到临时最小值之后步伐加大</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">3</span><br><span class="line"># https://leetcode-cn.com/problems/longest-common-prefix/</span><br><span class="line"></span><br><span class="line">总结：①找到最短的字符串②然后从最短字符串第一位开始依次增加</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;leetcode刷题与总结&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>feature_matching总结</title>
    <link href="https://yanyubing.xyz/2020/06/16/feature_matching%E6%80%BB%E7%BB%93/"/>
    <id>https://yanyubing.xyz/2020/06/16/feature_matching%E6%80%BB%E7%BB%93/</id>
    <published>2020-06-15T16:42:36.218Z</published>
    <updated>2020-06-17T06:45:44.272Z</updated>
    
    <content type="html"><![CDATA[<pre><code>feature_matching总结</code></pre><p>1：一般特征提取的方法有</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">harris corner detector</span><br><span class="line">SIFT</span><br><span class="line">SURF</span><br><span class="line">FAST</span><br><span class="line">BRIEF</span><br><span class="line">ORB</span><br><span class="line">BRISK</span><br></pre></td></tr></table></figure><p>2：一般特征匹配的方法有</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Brute-Force Matcher</span><br><span class="line">FLANN(Fast Library for Approximate Nearest Neighbors) Matcher</span><br></pre></td></tr></table></figure><p>3：什么是特征点(Feature detection)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Edges：强梯度变换</span><br><span class="line">Corners / interest points：两个边缘的交点</span><br><span class="line">Blobs / regions of interest points：LoG和DoH 斑点检测器</span><br><span class="line">Ridges：从灰度图像计算的脊线描述符可以看作是中间轴的概括（一般不会使用，算法复杂，航空和医学）</span><br></pre></td></tr></table></figure><p>4：什么是特征描述符(Feature description)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">描述特征点周围的向量</span><br></pre></td></tr></table></figure><p>5：什么是特征匹配(Feature matching)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;ratio test&quot; or &quot;nearest neighbor distance ratio test&quot;</span><br><span class="line">匹配两个图片特征点之间的差异性</span><br></pre></td></tr></table></figure><p>6：harris corner detector</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">拐角是一个点，其局部邻域位于两个主要且不同的边缘方向。换句话说，一个角可以解释为两个边缘的交点，其中边缘是图像亮度的突然变化。</span><br></pre></td></tr></table></figure><p>7：SIFT</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">尺度不变特征变换，特点：</span><br><span class="line">局部性：特征是局部性的，因此对遮挡和混乱都很健壮（没有事先分割）</span><br><span class="line">独特性：单个特征可以与大型对象数据库匹配</span><br><span class="line">数量：即使是很小的物体也可以生成许多特征</span><br><span class="line">效率：接近实时性能</span><br><span class="line">可扩展性：可以轻松扩展到各种不同的功能类型，每种功能都增加了鲁棒性</span><br><span class="line"></span><br><span class="line">比例空间峰选择：查找特征的潜在位置，使得尺度不变</span><br><span class="line">比例空间分为八度，八度的数量和比例取决于原始图像的大小。因此，我们生成原始图像的几个八度。每个八度的图像大小是前一个图像的一半。</span><br><span class="line"></span><br><span class="line">模糊化：在一个八度音程中，使用高斯模糊运算符逐渐模糊图像</span><br><span class="line"></span><br><span class="line">DOG：（高斯核的差）</span><br><span class="line">我们使用那些模糊的图像来生成另一组图像，即高斯差分（DoG）；这些DoG图像非常适合找出图像中有趣的关键点。</span><br><span class="line"></span><br><span class="line">寻找关键点：</span><br><span class="line">将图像中的一个像素与其8个邻居，下一个比例的9个像素和先前比例的9个像素进行比较。这样，总共进行了26次检查。如果是局部极值，则可能是关键点。从根本上说，关键点是最好的代表。</span><br><span class="line"></span><br><span class="line">关键点本地化：准确定位功能关键点。</span><br><span class="line">他们使用了尺度空间的泰勒级数展开来获得更精确的极值位置，并且如果该极值处的强度小于阈值（根据论文为0.03），则将其拒绝。DoG对边缘的响应较高，因此也需要删除边缘。</span><br><span class="line">主要是去除边缘特性</span><br><span class="line"></span><br><span class="line">方向分配：为关键点分配方向，目的是使得旋转不变</span><br><span class="line">取360°分为36份，每份分为10°；如果该点（在“方向收集区域”中）的渐变方向为18.759度。则那么它将进入10–19度的bin（直方图）中。</span><br><span class="line">提取直方图中的最高峰，并且将其超过80％的任何峰也视为计算方向。它创建的位置和比例相同但方向不同的关键点。它有助于匹配的稳定性。</span><br><span class="line"></span><br><span class="line">关键点描述符：将关键点描述为高维向量。</span><br><span class="line">到此为止，每个店都有位置，比例和方向。接下来是为每个关键点周围的局部图像区域计算一个描述符，该描述符对于诸如视点和照明的变化之类的变化具有高度的独特性和不变性。为此，将在关键点周围使用一个16x16的窗口。它分为16个4x4大小的子块。</span><br><span class="line">对于每个子块，创建8 bin方向直方图。</span><br><span class="line">①旋转相关性特征向量使用梯度方向。显然，如果旋转图像，一切都会改变。所有的梯度方向也会改变。为了实现旋转独立性，从每个方向减去关键点的旋转。因此，每个梯度方向都相对于关键点的方向。</span><br><span class="line">②照明依赖性如果我们将较大的阈值设为阈值，则可以实现照明依赖性。因此，任何大于0.2的数（128个数）都将更改为0.2。再次将该结果特征向量归一化。现在，您有了一个与照明无关的特征向量！</span><br><span class="line"></span><br><span class="line">关键点匹配：</span><br><span class="line">通过识别两个图像之间的关键点来匹配它们之间的关键点。但是在某些情况下，第二个最接近的匹配可能非常接近第一个。它可能是由于噪音或其他原因而发生的。在那种情况下，采用最接近距离与第二最接近距离之比。如果大于0.8，将被拒绝。根据论文，它可以消除大约90％的错误匹配，而只丢弃5％的正确匹配。</span><br></pre></td></tr></table></figure><p>8：SURF</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">快</span><br></pre></td></tr></table></figure><p>9：FAST</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">快，拐角检测器：</span><br><span class="line">由于检测到的角必须在包括角的两个边缘的中心周围具有较暗或较亮的像素值环，因此清晰的图像效果不佳。</span><br></pre></td></tr></table></figure><p>10：BRIEF</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Binary Robust Independent Elementary Features：二进制独立鲁棒特征描述符</span><br></pre></td></tr></table></figure><p>11： ORB</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Oriented FAST and Rotated BRIEF</span><br><span class="line">在特征检测任务上，ORB的性能与SIFT一样好（并且比SURF更好），而速度却快了两个数量级。ORB基于著名的FAST关键点检测器和Brief描述符。</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;feature_matching总结&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;1：一般特征提取的方法有&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>paper-summary</title>
    <link href="https://yanyubing.xyz/2020/06/13/paper-summary/"/>
    <id>https://yanyubing.xyz/2020/06/13/paper-summary/</id>
    <published>2020-06-13T02:26:00.570Z</published>
    <updated>2020-06-19T02:08:36.678Z</updated>
    
    <content type="html"><![CDATA[<h3 id="paper"><a href="#paper" class="headerlink" title="paper"></a>paper</h3><p>1：<strong>Pyramid Mask Text Detector</strong> (2019)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">1:pixel-level regression  代替传统Mask R-CNN的  binary text mask</span><br><span class="line">①二进制掩码定义原始图像的关注区域（ROI）。mask像素值 1表示图像像素属于ROI。mask像素值0表示图像像素是背景的一部分。</span><br><span class="line">②2D空间转换为3D空间的思想</span><br><span class="line"></span><br><span class="line">2: 传统方式没有解决的问题</span><br><span class="line">①监督简化：场景基本上基于不同的背景，但是没有特别的形状</span><br><span class="line">②错误的分割方式：会导致不属于RIO区域的背景会被识别进RIO区域</span><br><span class="line">③错误传播：二进制mask的区域基于Mask R-CNN的预测框，当预测框不准确时，mask也会错误</span><br><span class="line"></span><br><span class="line">3： “soft” semantic segmentation</span><br><span class="line">①根据距离文本框的距离编码0-1；</span><br><span class="line"></span><br><span class="line">4： plane clustering algorithm</span><br><span class="line">平面聚类算法：</span><br><span class="line">①找到四边形的中心0</span><br><span class="line">②向量计算0P=a*OM+b*OM;得到a,b</span><br><span class="line">③根据a,b的值范围，判断P属于哪个区域</span><br><span class="line"></span><br><span class="line">5：使用到的数据增强方式:</span><br><span class="line">①. Random horizon flip with a probability of 0.5.</span><br><span class="line">②. Random resize the height and width of images to 640-</span><br><span class="line">2560 individually, without keeping the original aspect</span><br><span class="line">ratio.</span><br><span class="line">③Random select one 640 × 640 crop region from the</span><br><span class="line">resized image.</span><br><span class="line"></span><br><span class="line">6：使用二进制差值上采样替代反卷积</span><br><span class="line">①因为反卷积之后会产生过多的棋盘纹，不利于后续回归</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;paper&quot;&gt;&lt;a href=&quot;#paper&quot; class=&quot;headerlink&quot; title=&quot;paper&quot;&gt;&lt;/a&gt;paper&lt;/h3&gt;&lt;p&gt;1：&lt;strong&gt;Pyramid Mask Text Detector&lt;/strong&gt; (2019)&lt;/p&gt;
&lt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>PyTorch</title>
    <link href="https://yanyubing.xyz/2020/05/31/PyTorch/"/>
    <id>https://yanyubing.xyz/2020/05/31/PyTorch/</id>
    <published>2020-05-31T13:01:12.594Z</published>
    <updated>2020-05-31T13:28:51.882Z</updated>
    
    <content type="html"><![CDATA[<p>PyTorch官方书籍deep-learning-with-pytorch</p><p>1:深度学习框架对比</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Theano是最早的深度学习框架之一，已停止积极发展。</span><br><span class="line">TensorFlow：</span><br><span class="line"></span><br><span class="line">完全消耗Keras，将其升级为一流的API</span><br><span class="line">提供了立即执行的“渴望模式”</span><br><span class="line">宣布TF 2.0将默认启用eager模式</span><br><span class="line">PyTorch：</span><br><span class="line"></span><br><span class="line">消耗了Caffe2作为后端</span><br><span class="line">替换了基于Lua的Torch项目中重复使用的大多数低级代码</span><br><span class="line">增加了对ONNX的支持，这是一种与供应商无关的模型描述和交换格式</span><br><span class="line">添加了名为TorchScript的延迟执行“图形模式”运行时</span><br><span class="line">发行版本1.0</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;PyTorch官方书籍deep-learning-with-pytorch&lt;/p&gt;
&lt;p&gt;1:深度学习框架对比&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span clas
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>机器学习记录(已掌握)</title>
    <link href="https://yanyubing.xyz/2020/05/31/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E5%B7%B2%E6%8E%8C%E6%8F%A1)/"/>
    <id>https://yanyubing.xyz/2020/05/31/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E5%B7%B2%E6%8E%8C%E6%8F%A1)/</id>
    <published>2020-05-31T11:30:27.688Z</published>
    <updated>2020-05-31T12:36:55.738Z</updated>
    
    <content type="html"><![CDATA[<p>1：一元线性回归</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">适用于一个特征：x对应的标签y的数据集</span><br><span class="line"></span><br><span class="line">y=wx+b：找到最优的w和b使得代价函数最小</span><br></pre></td></tr></table></figure><p>2：损失函数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">最小二乘法</span><br><span class="line">代价函数j=预测值h减去真实值y的平方求和，除以2倍的样本个数m</span><br><span class="line"></span><br><span class="line">常见的损失函数种类：https://zhuanlan.zhihu.com/p/47202768</span><br></pre></td></tr></table></figure><p>3： 梯度下降（优化算法）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">对损失函数求导，往斜率反方向更新值，得到局部最优解。</span><br><span class="line">1：为什么不直接对损失函数求导取倒数为0的点？倒数为0只能说明斜率为0，不能说明是最小值，或者极小值</span><br><span class="line"></span><br><span class="line">2：带动量的梯度下降可以越过鞍部</span><br><span class="line"></span><br><span class="line">3:问题点是，非凸函数难以找到全局最小值</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1：一元线性回归&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>得到ROI区域总结</title>
    <link href="https://yanyubing.xyz/2020/05/25/%E5%BE%97%E5%88%B0ROI%E5%8C%BA%E5%9F%9F%E6%80%BB%E7%BB%93/"/>
    <id>https://yanyubing.xyz/2020/05/25/%E5%BE%97%E5%88%B0ROI%E5%8C%BA%E5%9F%9F%E6%80%BB%E7%BB%93/</id>
    <published>2020-05-25T09:42:37.290Z</published>
    <updated>2020-05-25T09:43:20.898Z</updated>
    
    <content type="html"><![CDATA[<p>1：基于颜色值不同的ROI区域</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"># 检测答案区域,根据颜色判断,并且保存区域</span><br><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 判断像素是不是红色</span><br><span class="line">def isRed(pixel):</span><br><span class="line">    # 纯红色</span><br><span class="line">    if pixel[2] &gt; pixel[0] + 100 and pixel[2] &gt; pixel[1] + 100 and (pixel[2] &gt; 200):</span><br><span class="line">        return &apos;t&apos;</span><br><span class="line">    else:</span><br><span class="line">        return &apos;f&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ①除了红色区域的所有区域转为白色</span><br><span class="line">def getRedPicture(path):</span><br><span class="line">    image = cv2.imread(path)</span><br><span class="line">    h, w, c = image.shape</span><br><span class="line"></span><br><span class="line">    for i in range(w):</span><br><span class="line">        for j in range(h):</span><br><span class="line">            pixel = image[j][i]</span><br><span class="line">            if isRed(pixel) == &apos;f&apos;:</span><br><span class="line">                pixel[:] = 255</span><br><span class="line">    print(path, &apos;finished---getRedPicture&apos;)</span><br><span class="line">    # 图片的下方一行需要手动去除</span><br><span class="line">    image[3100:, :] = 255</span><br><span class="line">    return image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取轮廓的最上下两个点，只需要根据上下两个点的距离过滤</span><br><span class="line">def getContours_XY_dots(cnt):</span><br><span class="line">    # 储存x坐标</span><br><span class="line">    xs = []</span><br><span class="line">    # 储存y坐标</span><br><span class="line">    ys = []</span><br><span class="line">    for c in cnt:</span><br><span class="line">        ys.append(c[0][1])</span><br><span class="line">        xs.append(c[0][0])</span><br><span class="line">    xs.sort(key=int)</span><br><span class="line">    ys.sort(key=int)</span><br><span class="line"></span><br><span class="line">    min_x = xs[0]</span><br><span class="line">    max_x = xs[-1]</span><br><span class="line">    max_y = ys[-1]</span><br><span class="line">    min_y = ys[0]</span><br><span class="line">    return min_x, max_x, min_y, max_y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取红色区域的定位</span><br><span class="line">def getRedLocation(path):</span><br><span class="line">    # 获取红色图片</span><br><span class="line">    img = getRedPicture(path)</span><br><span class="line"></span><br><span class="line">    # 转换为灰度</span><br><span class="line">    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)</span><br><span class="line"></span><br><span class="line">    # 二值化</span><br><span class="line">    _, thresh1 = cv2.threshold(img_gray, 200, 255, cv2.THRESH_BINARY)</span><br><span class="line">    # 黑色和白色对调，因为膨胀或者腐蚀的前景都是白色</span><br><span class="line">    dst = 255 - thresh1</span><br><span class="line">    # 膨胀核</span><br><span class="line">    kernel = np.ones((5, 5), np.uint8)</span><br><span class="line">    # 膨胀之后的图片</span><br><span class="line">    dilation = cv2.dilate(dst, kernel, iterations=5)  # 膨胀</span><br><span class="line">    # 查找轮廓</span><br><span class="line">    _, contours, hierarchy = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line">    # 对轮廓进行判断,①轮廓的高取值范围，②轮廓的面积取值范围，最后添加到最终的轮廓中</span><br><span class="line">    res_contours = []  # 储存需要的轮廓</span><br><span class="line">    for index, cnt in enumerate(contours):</span><br><span class="line">        area = cv2.contourArea(cnt)</span><br><span class="line">        print(index, &apos;--------&apos;, area)</span><br><span class="line">        min_x, max_x, min_y, max_y = getContours_XY_dots(cnt)</span><br><span class="line">        yLength = max_y - min_y</span><br><span class="line">        print(yLength)</span><br><span class="line">        # 这里范围可调</span><br><span class="line">        if area &gt; 500 and area &lt; 20000 and yLength &gt; 10 and yLength &lt; 70:</span><br><span class="line">            res_contours.append(cnt)</span><br><span class="line"></span><br><span class="line">    res = cv2.drawContours(img, res_contours, -1, (0, 255, 0), 10)</span><br><span class="line"></span><br><span class="line">    # 遍历最终的轮廓，得到最小x,y,最大x,y的坐标</span><br><span class="line">    # 储存一张图片的所有box</span><br><span class="line">    bboxes = []</span><br><span class="line">    for res in res_contours:</span><br><span class="line">        min_x, max_x, min_y, max_y = getContours_XY_dots(res)</span><br><span class="line">        box = min_x, max_x, min_y, max_y</span><br><span class="line">        bboxes.append(box)</span><br><span class="line">    return bboxes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 图片地址</span><br><span class="line">def saveAllRedLocation(path):</span><br><span class="line">    image = cv2.imread(path)</span><br><span class="line">    bboxes = getRedLocation(path)</span><br><span class="line">    # bboxes排序，根据纵坐标</span><br><span class="line">    bboxes.sort(key=lambda x: int(x[2]))</span><br><span class="line">    index = 0</span><br><span class="line">    # 储存每个box的图片</span><br><span class="line">    for box in bboxes:</span><br><span class="line">        index += 1</span><br><span class="line">        path_out = &apos;red/&apos; + path.split(&apos;/&apos;)[1].split(&apos;.&apos;)[0] + &apos;_&apos; + str(index) + &apos;.jpg&apos;</span><br><span class="line">        print(path_out)</span><br><span class="line">        cv2.imwrite(path_out, image[box[2]:box[3], box[0]:box[1]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">path = &apos;books&apos;</span><br><span class="line">files = os.listdir(path)</span><br><span class="line"># 储存整本书的所有红色区域</span><br><span class="line">for file in files:</span><br><span class="line">    pathname = path + &apos;/&apos; + file</span><br><span class="line">    saveAllRedLocation(pathname)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1：基于颜色值不同的ROI区域&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>倾斜校正相关总结对比</title>
    <link href="https://yanyubing.xyz/2020/05/22/%E5%80%BE%E6%96%9C%E6%A0%A1%E6%AD%A3%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%E5%AF%B9%E6%AF%94/"/>
    <id>https://yanyubing.xyz/2020/05/22/%E5%80%BE%E6%96%9C%E6%A0%A1%E6%AD%A3%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%E5%AF%B9%E6%AF%94/</id>
    <published>2020-05-22T02:30:15.814Z</published>
    <updated>2020-06-28T11:44:48.173Z</updated>
    
    <content type="html"><![CDATA[<h3 id="倾斜校正相关总结对比"><a href="#倾斜校正相关总结对比" class="headerlink" title="倾斜校正相关总结对比"></a>倾斜校正相关总结对比</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">以下一种方式即可：核心逻辑都是找到倾斜角度，然后校正；根据最小外接矩形得到的图形，可能会得到误差较大（四边形的选取很重要，思路有①横向膨胀②ocr定位文字区域获取）；找到多个角度之后取直方图最优区间的平均值，</span><br></pre></td></tr></table></figure><p>方案1：最小外接矩形→倾斜角度→得到变换矩阵→纺射变换得到校正图</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">地址：https://www.pyimagesearch.com/2017/02/20/text-skew-correction-opencv-python/</span><br><span class="line"></span><br><span class="line">效果：书本的校正效果95分</span><br><span class="line">困难点：通过局部图片得到倾斜角度，这个局部图片的确定，如果杂点过多，很难得到角度</span><br><span class="line">困难点的解决方案：找到高度的h1,h2；h1整行为白色（往下一个像素就会有黑色）,h2整行也为白色（往上一行就会有黑色），然后截取；</span><br></pre></td></tr></table></figure><p>代码:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"># import the necessary packages</span><br><span class="line">import numpy as np</span><br><span class="line">import argparse</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 得到目标区域,num为起始位置的区域得分&lt;30</span><br><span class="line">def getLocation(image, n):</span><br><span class="line">    h, w, c = image.shape</span><br><span class="line">    # 转成灰度和二值图</span><br><span class="line">    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    thresh = cv2.threshold(gray, 127, 255,</span><br><span class="line">                           cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]</span><br><span class="line">    # 定义两个高度，第一个和最后一个就是高度起始和结束</span><br><span class="line">    h_temp = []</span><br><span class="line">    # 找到高度的h1,h2；h1整行为白色（往下一个像素就会有黑色）,h2整行也为白色（往上一行就会有黑色），然后截取</span><br><span class="line">    start = 0</span><br><span class="line">    # h/5开始，找到黑色区域起始位置</span><br><span class="line">    for i in range(int(n * h / 30), h, 2):</span><br><span class="line">        # 每一条初始化像素值个数</span><br><span class="line">        global num</span><br><span class="line">        num = 0</span><br><span class="line">        for j in range(w):</span><br><span class="line">            if thresh[i][j] &lt; 100:</span><br><span class="line">                # 开始有黑色点</span><br><span class="line">                # 像素值个数+1</span><br><span class="line">                num += 1</span><br><span class="line">        # 黑点个数为10</span><br><span class="line">        if 0 &lt; num &lt; 10:</span><br><span class="line">            start = i</span><br><span class="line">            break</span><br><span class="line"></span><br><span class="line">    # 已经没有黑色区域的时候，遍历到全白</span><br><span class="line">    if num == 0:</span><br><span class="line">        start = int(n * h / 30)</span><br><span class="line"></span><br><span class="line">    # 白色区域开始遍历</span><br><span class="line">    for i in range(start, h, 2):</span><br><span class="line">        # 每一条初始化像素值个数</span><br><span class="line">        num = 0</span><br><span class="line">        for j in range(w):</span><br><span class="line">            if thresh[i][j] &lt; 100:</span><br><span class="line">                # 开始有黑色点</span><br><span class="line">                # 像素值个数+1</span><br><span class="line">                num += 1</span><br><span class="line">        if num &gt; 0:</span><br><span class="line">            h_temp.append(i)</span><br><span class="line"></span><br><span class="line">        if num == 0 and len(h_temp) &gt; 0:</span><br><span class="line">            # 证明已经经过了黑色区域，结束循环</span><br><span class="line">            break</span><br><span class="line">    if len(h_temp) &gt; 0:</span><br><span class="line">        h_temp.sort(key=int)</span><br><span class="line"></span><br><span class="line">        h1 = h_temp[0]</span><br><span class="line">        h2 = h_temp[-1]</span><br><span class="line">        # 取值</span><br><span class="line">        imagenew = image[h1:h2, :]</span><br><span class="line">        # 纵向上下拼接20个像素的白色区域</span><br><span class="line">        image_temp = np.zeros((10, imagenew.shape[1], 3), np.uint8)</span><br><span class="line">        image_temp[:] = 255</span><br><span class="line">        # 拼接结果</span><br><span class="line">        result = np.vstack([image_temp, imagenew, image_temp])</span><br><span class="line">    else:</span><br><span class="line">        result = np.zeros((10, 10, 3), np.uint8)</span><br><span class="line">    return result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 传入图片地址，获取角度</span><br><span class="line">def getAngle(image, n):</span><br><span class="line">    # 获取目标区域</span><br><span class="line">    location = getLocation(image, n)</span><br><span class="line"></span><br><span class="line">    # location转成灰度，得到角度</span><br><span class="line">    gray = cv2.cvtColor(location, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    gray = cv2.bitwise_not(gray)</span><br><span class="line">    # 二值化</span><br><span class="line">    thresh = cv2.threshold(gray, 0, 255,</span><br><span class="line">                           cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]</span><br><span class="line"></span><br><span class="line">    coords = np.column_stack(np.where(thresh &gt; 0))</span><br><span class="line">    angle = cv2.minAreaRect(coords)[-1]</span><br><span class="line">    if angle &lt; -45:</span><br><span class="line">        angle = -(90 + angle)</span><br><span class="line">    else:</span><br><span class="line">        angle = -angle</span><br><span class="line">    print(&apos;angle:&apos;, angle)</span><br><span class="line"></span><br><span class="line">    return angle</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取最终的角度</span><br><span class="line">def getResAngle(image):</span><br><span class="line">    angles = []</span><br><span class="line">    for n in range(30):</span><br><span class="line">        angle_temp = getAngle(image, n)</span><br><span class="line">        angles.append(angle_temp)</span><br><span class="line"></span><br><span class="line">    # 角度排序</span><br><span class="line">    angles.sort()</span><br><span class="line">    # 计算大于0和小于0的倾斜角度</span><br><span class="line">    Asum = 0</span><br><span class="line">    asum = 0</span><br><span class="line">    for a in angles:</span><br><span class="line">        # 判断角度大于0和小于0的个数:用来确定最终的偏斜角度</span><br><span class="line">        if a &gt; 0:</span><br><span class="line">            Asum += 1</span><br><span class="line">        if a &lt; 0:</span><br><span class="line">            asum += 1</span><br><span class="line">        # 去除异常值的点</span><br><span class="line">        if a &gt; 15 or a &lt; -15:</span><br><span class="line">            angles.remove(a)</span><br><span class="line">    # 获取最终角度的值</span><br><span class="line">    if Asum &gt; asum:</span><br><span class="line">        angleRes = angles[-1]</span><br><span class="line">    else:</span><br><span class="line">        angleRes = angles[0]</span><br><span class="line">    print(&apos;最后取得的角度为&apos;, angleRes)</span><br><span class="line">    return angleRes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 校正图片</span><br><span class="line">def correctSkew(image, angle):</span><br><span class="line">    # rotate the image to deskew it</span><br><span class="line">    (h, w) = image.shape[:2]</span><br><span class="line">    center = (w // 2, h // 2)</span><br><span class="line">    M = cv2.getRotationMatrix2D(center, angle, 1.0)</span><br><span class="line">    rotated = cv2.warpAffine(image, M, (w, h),</span><br><span class="line">                             flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)</span><br><span class="line"></span><br><span class="line">    return rotated</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">imagepath = &apos;image/2.jpg&apos;</span><br><span class="line">image = cv2.imread(imagepath)</span><br><span class="line">angleRes = getResAngle(image)</span><br><span class="line"></span><br><span class="line"># 校正</span><br><span class="line">rotated = correctSkew(image, angleRes)</span><br><span class="line">cv2.imwrite(&apos;rotate.jpg&apos;, rotated)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;倾斜校正相关总结对比&quot;&gt;&lt;a href=&quot;#倾斜校正相关总结对比&quot; class=&quot;headerlink&quot; title=&quot;倾斜校正相关总结对比&quot;&gt;&lt;/a&gt;倾斜校正相关总结对比&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;t
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>OCR相关总结对比</title>
    <link href="https://yanyubing.xyz/2020/05/13/OCR%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%E5%AF%B9%E6%AF%94/"/>
    <id>https://yanyubing.xyz/2020/05/13/OCR%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%E5%AF%B9%E6%AF%94/</id>
    <published>2020-05-13T03:01:04.332Z</published>
    <updated>2020-06-23T08:09:23.712Z</updated>
    
    <content type="html"><![CDATA[<p>OCR总结和对比；实现书本的题干提取</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">总结：OCR对于识别的准确率基本可以满足要求，只是前提是定位的准确和一些预处理操作以及对应不同场景的不同处理方案的搭配（如中英文不同，特殊字符的处理等等）</span><br></pre></td></tr></table></figure><p>1：百度ocr</p><p>1.1:特点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1：付费</span><br><span class="line">2：偶尔报错</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;C:/Users/yanyubing/Desktop/zex/010_GUI/ocr/ocr_Topic.py&quot;, line 112, in &lt;module&gt;</span><br><span class="line">    results = client.general(image)[&quot;words_result&quot;]</span><br><span class="line">KeyError: &apos;words_result&apos;</span><br><span class="line">3：网络请求</span><br><span class="line">4：准确率基本满足要求</span><br><span class="line">5：识别数字很烂</span><br><span class="line"></span><br><span class="line">总结：可以满足生产需求</span><br></pre></td></tr></table></figure><p>1.2:代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"># 题干的ocr</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import cv2</span><br><span class="line">from aip import AipOcr</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot; 你的 APPID AK SK &quot;&quot;&quot;</span><br><span class="line">#这里有更改</span><br><span class="line">APP_ID = &apos;198605*&apos;</span><br><span class="line">API_KEY = &apos;R7fGy5Yh900UQKXmlppPc69d&apos;</span><br><span class="line">SECRET_KEY = &apos;v2OKtKnslZq34qNQKQ4dZCGwjONxK9xY&apos;</span><br><span class="line"></span><br><span class="line">client = AipOcr(APP_ID, API_KEY, SECRET_KEY)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_file_content(filePath):</span><br><span class="line">    with open(filePath, &apos;rb&apos;) as fp:</span><br><span class="line">        return fp.read()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># step1：获取定位框的最左排序个数</span><br><span class="line"># num:输入获取的个数</span><br><span class="line">def getTopic(num):</span><br><span class="line">    # 没有题干的提前结束</span><br><span class="line">    if num == 0:</span><br><span class="line">        return</span><br><span class="line">    global str_temp</span><br><span class="line"></span><br><span class="line">    # 获取所有识别的集合</span><br><span class="line">    left_temp = []</span><br><span class="line"></span><br><span class="line">    for result in results:</span><br><span class="line">        # 文本</span><br><span class="line">        text = result[&quot;words&quot;]</span><br><span class="line"></span><br><span class="line">        # 定位</span><br><span class="line">        location = result[&quot;location&quot;]</span><br><span class="line"></span><br><span class="line">        # 得到字段：最左边，高度定位，和文本信息</span><br><span class="line">        strtemp = str(location[&apos;left&apos;]) + &apos;,&apos; + str(location[&apos;top&apos;]) + &apos;,&apos; + text</span><br><span class="line"></span><br><span class="line">        # 添加</span><br><span class="line">        left_temp.append(strtemp)</span><br><span class="line"></span><br><span class="line">    # 获取需要的集合,根据左边的位置排序</span><br><span class="line">    lefts = []</span><br><span class="line">    while 1:</span><br><span class="line">        # 获取最小的x值</span><br><span class="line">        min_x = 10000</span><br><span class="line">        for temp in left_temp:</span><br><span class="line">            if int(temp.split(&apos;,&apos;)[0]) &lt; min_x:</span><br><span class="line">                min_x = int(temp.split(&apos;,&apos;)[0])</span><br><span class="line">                str_temp = temp</span><br><span class="line"></span><br><span class="line">        lefts.append(str_temp)</span><br><span class="line">        # print(str_temp)</span><br><span class="line">        left_temp.remove(str_temp)</span><br><span class="line"></span><br><span class="line">        if len(lefts) == num:</span><br><span class="line">            break</span><br><span class="line">    # 左边位置排序之后再根据上下位置排序</span><br><span class="line">    result = []</span><br><span class="line"></span><br><span class="line">    while 1:</span><br><span class="line">        # 获取最小的x值</span><br><span class="line">        min_y = 10000</span><br><span class="line">        for temp in lefts:</span><br><span class="line">            if int(temp.split(&apos;,&apos;)[1]) &lt; min_y:</span><br><span class="line">                min_y = int(temp.split(&apos;,&apos;)[1])</span><br><span class="line">                str_temp = temp</span><br><span class="line"></span><br><span class="line">        result.append(str_temp)</span><br><span class="line">        # print(str_temp)</span><br><span class="line">        lefts.remove(str_temp)</span><br><span class="line"></span><br><span class="line">        if len(lefts) == 0:</span><br><span class="line">            # 过滤完全结束</span><br><span class="line">            break</span><br><span class="line"></span><br><span class="line">    return result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取所有书名，按照顺序排序</span><br><span class="line">def getBookNames(path):</span><br><span class="line">    booknames = []</span><br><span class="line">    filesname = os.listdir(path)</span><br><span class="line">    for i in range(len(filesname)):</span><br><span class="line">        name = path + &apos;/&apos; + str(i + 1) + &apos;.jpg&apos;</span><br><span class="line">        booknames.append(name)</span><br><span class="line">    return booknames</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 输入图片所在目录</span><br><span class="line">dir = input(&apos;输入图片所在文件夹:\n&apos;)</span><br><span class="line"></span><br><span class="line"># 获取所有的书名</span><br><span class="line">booknames = getBookNames(dir)</span><br><span class="line"></span><br><span class="line"># 输入对应要获取题干的个数，</span><br><span class="line"># nums = []</span><br><span class="line">nums = input(&apos;连续输入页码题干个数\n&apos;)</span><br><span class="line"># for bookname in booknames:</span><br><span class="line">#     num = int(input(&apos;输入需要获取页面:&apos; + bookname + &apos;的题干的个数:\n&apos;))</span><br><span class="line">#     nums.append(num)</span><br><span class="line"></span><br><span class="line"># 整本书的结果</span><br><span class="line">allResults = []</span><br><span class="line"># 遍历所有书</span><br><span class="line">for index in range(len(booknames)):</span><br><span class="line">    image = get_file_content(booknames[index])</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot; 调用通用文字识别, 图片参数为本地图片 &quot;&quot;&quot;</span><br><span class="line">    results = client.general(image)[&quot;words_result&quot;]</span><br><span class="line"></span><br><span class="line">    # 一页书的结果</span><br><span class="line">    result = getTopic(int(nums[index]))</span><br><span class="line">    print(&quot;----&quot;, index, &quot;----&quot;)</span><br><span class="line">    for re in result:</span><br><span class="line">        # 添加页码信息</span><br><span class="line">        r = re + &apos;,&apos; + booknames[index]</span><br><span class="line">        # 整本书的结果</span><br><span class="line">        allResults.append(result)</span><br><span class="line"></span><br><span class="line"># 查看整本书的结果</span><br><span class="line">for result in allResults:</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure><p>2：pse+rcnn</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1：免费</span><br><span class="line">2：需要编译：本人使用vs2017+python3.7编译</span><br><span class="line">3：可以识别竖向文字，斜向文字也可以</span><br><span class="line">4：识别通用文字效果不太好:</span><br><span class="line">5：对于英文识别错误率高</span><br><span class="line">对于英文：误识，漏识严重</span><br><span class="line">对于中文:也存在一定的误识和漏识</span><br><span class="line">github地址：https://github.com/ouyanghuiyu/chineseocr_lite</span><br><span class="line"></span><br><span class="line">总结：无法满足生产需求。①定位有尺寸压缩，并且定位有偏差；②识别有误识</span><br><span class="line"></span><br><span class="line">解决方案：总体而言是因为pse定位存在误差，导致识别上的错误；使用自己的mark去定位，然后识别，准确率可以达到99%</span><br><span class="line">①取mark一定100%准确</span><br><span class="line">②根据mark去location一定100%准确</span><br><span class="line">③识别准确率才能到达极限</span><br><span class="line">④识别数字可以，识别英文很烂</span><br></pre></td></tr></table></figure><p>3：ocr.space</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">特点：</span><br><span class="line">①需要翻墙</span><br><span class="line">②多种语言和特殊字符的支持</span><br><span class="line">③使用简洁：但是有限制</span><br></pre></td></tr></table></figure><p>4： CRAFT(英文字符识别)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">地址：https://github.com/clovaai/CRAFT-pytorch+https://github.com/clovaai/deep-text-recognition-benchmark</span><br><span class="line">原理：CRAFT+deep-text-recognition(检测+识别)</span><br><span class="line">特点：</span><br><span class="line">①英文识别能力强，单个单词准确率达到99%</span><br><span class="line">②定位准确：切割单个单词准确率高99%</span><br><span class="line">③需要自己糅合</span><br></pre></td></tr></table></figure><p>4.1：定位</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"># 定位和识别一体</span><br><span class="line">import argparse</span><br><span class="line">import os</span><br><span class="line">import shutil</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">from getLocations import getLocation</span><br><span class="line"></span><br><span class="line"># 存放txt的文件夹</span><br><span class="line">result_folder = &apos;txtResult/&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取txt文件</span><br><span class="line">def getTextFile(path):</span><br><span class="line">    # 存放定位之后的文件路径</span><br><span class="line"></span><br><span class="line">    # 存在结果文件夹</span><br><span class="line">    if os.path.exists(result_folder):</span><br><span class="line">        # 删除文件夹(非空)</span><br><span class="line">        shutil.rmtree(result_folder)</span><br><span class="line">    # 运行，会产生位置信息的txt文件</span><br><span class="line">    getLocation(path, result_folder)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取整个文件夹识别之后的集合</span><br><span class="line"># 格式为： &apos;&apos;&apos;文件路径：value&apos;&apos;&apos;</span><br><span class="line">def saveLocation(pathin, pathout):</span><br><span class="line">    if not os.path.exists(pathout):</span><br><span class="line">        os.mkdir(pathout)</span><br><span class="line">    # 获取原文件夹底下的文件列表</span><br><span class="line">    files = os.listdir(pathin)</span><br><span class="line">    # 遍历列表</span><br><span class="line">    for file in files:</span><br><span class="line">        # 获取不带后缀的文件名</span><br><span class="line">        filename = file.split(&apos;.&apos;)[0]</span><br><span class="line">        # 图片文件路径</span><br><span class="line">        ImgFilepath = pathin + &apos;/&apos; + file</span><br><span class="line">        # 读取图片</span><br><span class="line">        image = cv2.imread(ImgFilepath)</span><br><span class="line">        # 构建lines集合储存txt文件的lines</span><br><span class="line">        lines = []</span><br><span class="line">        # txt文件路径</span><br><span class="line">        TxtFilepath = result_folder + &apos;/&apos; + filename + &apos;.txt&apos;</span><br><span class="line">        # 读取txt文件</span><br><span class="line">        f = open(TxtFilepath)</span><br><span class="line">        line = f.readlines()</span><br><span class="line">        for li in line:</span><br><span class="line">            lines.append(li)</span><br><span class="line">        # 记录第几条数据</span><br><span class="line">        index = 0</span><br><span class="line">        # 去除多条数据中的空格</span><br><span class="line">        lines = [x.strip() for x in lines if x.strip() != &apos;&apos;]</span><br><span class="line">        # 根据横坐标位置排序，为了后面便于拼接</span><br><span class="line">        lines.sort(key=lambda x: int(x.split(&apos;,&apos;)[0]))</span><br><span class="line">        # 遍历lines，得到坐标位置</span><br><span class="line">        for line in lines:</span><br><span class="line">            # 除去每条数据中的空格</span><br><span class="line">            line = line[:-1]</span><br><span class="line">            index += 1</span><br><span class="line">            ls = line.split(&apos;,&apos;)</span><br><span class="line">            # 判断坐标位置的大小，得到左上和右下坐标的矩形框</span><br><span class="line">            # 左上</span><br><span class="line">            lt = (min(ls[0], ls[6]), min(ls[1], ls[3]))</span><br><span class="line"></span><br><span class="line">            # 右下</span><br><span class="line">            rd = (max(ls[4], ls[2]), max(ls[5], ls[7]))</span><br><span class="line">            # 得到定位之后的单个单词位置</span><br><span class="line">            imagetemp = image[int(lt[1]):int(rd[1]), int(lt[0]):int(rd[0])]</span><br><span class="line">            # 文件路径名，如1_1，则是第一个图的第一个单词</span><br><span class="line">            path_new = pathout + &apos;/&apos; + filename + &apos;_&apos; + str(index) + &apos;.jpg&apos;</span><br><span class="line">            cv2.imwrite(path_new, imagetemp)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 预处理文件处理,修改path</span><br><span class="line">path = &apos;two&apos;</span><br><span class="line">pathin = path</span><br><span class="line">pathout = path + &apos;out&apos;</span><br><span class="line">getTextFile(path)</span><br><span class="line"></span><br><span class="line">saveLocation(pathin, pathout)</span><br></pre></td></tr></table></figure><p>4.2:识别</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br></pre></td><td class="code"><pre><span class="line">import string</span><br><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torch.backends.cudnn as cudnn</span><br><span class="line">import torch.utils.data</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line">from utils import CTCLabelConverter, AttnLabelConverter</span><br><span class="line">from dataset import RawDataset, AlignCollate</span><br><span class="line">from model import Model</span><br><span class="line"></span><br><span class="line">device = torch.device(&apos;cuda&apos; if torch.cuda.is_available() else &apos;cpu&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def demo(opt):</span><br><span class="line">    # 储存所有的文本信息</span><br><span class="line">    # 格式：图片名称：值</span><br><span class="line">    values = []</span><br><span class="line">    # 临时存储，需要变换</span><br><span class="line">    valuetemp = []</span><br><span class="line">    &quot;&quot;&quot; model configuration &quot;&quot;&quot;</span><br><span class="line">    # CTC模型</span><br><span class="line">    if &apos;CTC&apos; in opt.Prediction:</span><br><span class="line">        converter = CTCLabelConverter(opt.character)</span><br><span class="line">    else:</span><br><span class="line">        converter = AttnLabelConverter(opt.character)</span><br><span class="line">    opt.num_class = len(converter.character)</span><br><span class="line"></span><br><span class="line">    if opt.rgb:</span><br><span class="line">        opt.input_channel = 3</span><br><span class="line">    model = Model(opt)</span><br><span class="line">    print(&apos;model input parameters&apos;, opt.imgH, opt.imgW, opt.num_fiducial, opt.input_channel, opt.output_channel,</span><br><span class="line">          opt.hidden_size, opt.num_class, opt.batch_max_length, opt.Transformation, opt.FeatureExtraction,</span><br><span class="line">          opt.SequenceModeling, opt.Prediction)</span><br><span class="line">    model = torch.nn.DataParallel(model).to(device)</span><br><span class="line"></span><br><span class="line">    # load model</span><br><span class="line">    print(&apos;loading pretrained model from %s&apos; % opt.saved_model)</span><br><span class="line">    model.load_state_dict(torch.load(opt.saved_model, map_location=device))</span><br><span class="line"></span><br><span class="line">    # prepare data. two demo images from https://github.com/bgshih/crnn#run-demo</span><br><span class="line">    AlignCollate_demo = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD)</span><br><span class="line">    # 加载数据目录</span><br><span class="line">    demo_data = RawDataset(root=opt.image_folder, opt=opt)  # use RawDataset</span><br><span class="line">    #</span><br><span class="line">    demo_loader = torch.utils.data.DataLoader(</span><br><span class="line">        demo_data, batch_size=opt.batch_size,</span><br><span class="line">        shuffle=False,</span><br><span class="line">        num_workers=int(opt.workers),</span><br><span class="line">        collate_fn=AlignCollate_demo, pin_memory=True)</span><br><span class="line"></span><br><span class="line">    # predict</span><br><span class="line">    model.eval()</span><br><span class="line"></span><br><span class="line">    with torch.no_grad():</span><br><span class="line"></span><br><span class="line">        # image_path_list为文件夹列表</span><br><span class="line">        for image_tensors, image_path_list in demo_loader:</span><br><span class="line"></span><br><span class="line">            batch_size = image_tensors.size(0)</span><br><span class="line"></span><br><span class="line">            image = image_tensors.to(device)</span><br><span class="line"></span><br><span class="line">            # For max length prediction</span><br><span class="line">            length_for_pred = torch.IntTensor([opt.batch_max_length] * batch_size).to(device)</span><br><span class="line"></span><br><span class="line">            text_for_pred = torch.LongTensor(batch_size, opt.batch_max_length + 1).fill_(0).to(device)</span><br><span class="line"></span><br><span class="line">            if &apos;CTC&apos; in opt.Prediction:</span><br><span class="line">                preds = model(image, text_for_pred)</span><br><span class="line"></span><br><span class="line">                # Select max probabilty (greedy decoding) then decode index to character</span><br><span class="line">                preds_size = torch.IntTensor([preds.size(1)] * batch_size)</span><br><span class="line">                _, preds_index = preds.max(2)</span><br><span class="line">                preds_index = preds_index.view(-1)</span><br><span class="line">                preds_str = converter.decode(preds_index.data, preds_size.data)</span><br><span class="line"></span><br><span class="line">            else:</span><br><span class="line">                preds = model(image, text_for_pred, is_train=False)</span><br><span class="line"></span><br><span class="line">                # select max probabilty (greedy decoding) then decode index to character</span><br><span class="line">                _, preds_index = preds.max(2)</span><br><span class="line"></span><br><span class="line">                preds_str = converter.decode(preds_index, length_for_pred)</span><br><span class="line"></span><br><span class="line">            log = open(f&apos;./log_demo_result.txt&apos;, &apos;a&apos;)</span><br><span class="line"></span><br><span class="line">            dashed_line = &apos;-&apos; * 80</span><br><span class="line"></span><br><span class="line">            head = f&apos;&#123;&quot;image_path&quot;:25s&#125;\t&#123;&quot;predicted_labels&quot;:25s&#125;\tconfidence score&apos;</span><br><span class="line"></span><br><span class="line">            print(f&apos;&#123;dashed_line&#125;\n&#123;head&#125;\n&#123;dashed_line&#125;&apos;)</span><br><span class="line"></span><br><span class="line">            log.write(f&apos;&#123;dashed_line&#125;\n&#123;head&#125;\n&#123;dashed_line&#125;\n&apos;)</span><br><span class="line"></span><br><span class="line">            preds_prob = F.softmax(preds, dim=2)</span><br><span class="line"></span><br><span class="line">            preds_max_prob, _ = preds_prob.max(dim=2)</span><br><span class="line"></span><br><span class="line">            for img_name, pred, pred_max_prob in zip(image_path_list, preds_str, preds_max_prob):</span><br><span class="line"></span><br><span class="line">                if &apos;Attn&apos; in opt.Prediction:</span><br><span class="line">                    pred_EOS = pred.find(&apos;[s]&apos;)</span><br><span class="line"></span><br><span class="line">                    pred = pred[:pred_EOS]  # prune after &quot;end of sentence&quot; token ([s])</span><br><span class="line"></span><br><span class="line">                    pred_max_prob = pred_max_prob[:pred_EOS]</span><br><span class="line"></span><br><span class="line">                # calculate confidence score (= multiply of pred_max_prob)</span><br><span class="line">                confidence_score = pred_max_prob.cumprod(dim=0)[-1]</span><br><span class="line">                #</span><br><span class="line">                # print(f&apos;&#123;img_name:25s&#125;\t&#123;pred:25s&#125;\t&#123;confidence_score:0.4f&#125;&apos;)</span><br><span class="line">                # 拼接：文件名称:值</span><br><span class="line">                value = img_name + &quot;:&quot; + pred</span><br><span class="line">                valuetemp.append(value)</span><br><span class="line">                log.write(f&apos;&#123;img_name:25s&#125;\t&#123;pred:25s&#125;\t&#123;confidence_score:0.4f&#125;\n&apos;)</span><br><span class="line"></span><br><span class="line">            log.close()</span><br><span class="line"></span><br><span class="line">    # 遍历image_path_list</span><br><span class="line">    for i in image_path_list:</span><br><span class="line">        image_path = i.split(&apos;/&apos;)[1].split(&apos;_&apos;)[0]</span><br><span class="line">        # 开始处理临时储存</span><br><span class="line">        # 用于储存同一种的文件</span><br><span class="line">        onePicture = []</span><br><span class="line">        # 遍历添加</span><br><span class="line">        for v in valuetemp:</span><br><span class="line">            if v.split(&apos;/&apos;)[1].split(&apos;_&apos;)[0] == image_path:</span><br><span class="line">                # 得到一张图片的所有信息</span><br><span class="line">                onePicture.append(v)</span><br><span class="line">        # 根据.jpg的最后一个字符排序</span><br><span class="line">        onePicture.sort(key=lambda x: int(x.split(&apos;.&apos;)[0].split(&apos;_&apos;)[1]))</span><br><span class="line">        # 拼接每张图片</span><br><span class="line">        text = i.split(&apos;/&apos;)[0][:-3] + &apos;/&apos; + i.split(&apos;/&apos;)[1].split(&apos;_&apos;)[0] + &apos;.jpg&apos; + &apos;:&apos;</span><br><span class="line">        # 遍历onePicture</span><br><span class="line">        for o in onePicture:</span><br><span class="line">            text = text + o.split(&apos;:&apos;)[1] + &apos; &apos;</span><br><span class="line">        # 除去尾部空格</span><br><span class="line">        text = text.strip()</span><br><span class="line">        # 拼接完成之后添加</span><br><span class="line">        values.append(text)</span><br><span class="line">    return values</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 识别主程序</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(&apos;--image_folder&apos;, help=&apos;path to image_folder which contains text images&apos;)</span><br><span class="line">    parser.add_argument(&apos;--workers&apos;, type=int, help=&apos;number of data loading workers&apos;, default=4)</span><br><span class="line">    parser.add_argument(&apos;--batch_size&apos;, type=int, default=192, help=&apos;input batch size&apos;)</span><br><span class="line">    parser.add_argument(&apos;--saved_model&apos;, help=&quot;path to saved_model to evaluation&quot;)</span><br><span class="line">    &quot;&quot;&quot; Data processing &quot;&quot;&quot;</span><br><span class="line">    parser.add_argument(&apos;--batch_max_length&apos;, type=int, default=25, help=&apos;maximum-label-length&apos;)</span><br><span class="line">    parser.add_argument(&apos;--imgH&apos;, type=int, default=32, help=&apos;the height of the input image&apos;)</span><br><span class="line">    parser.add_argument(&apos;--imgW&apos;, type=int, default=100, help=&apos;the width of the input image&apos;)</span><br><span class="line">    parser.add_argument(&apos;--rgb&apos;, action=&apos;store_true&apos;, help=&apos;use rgb input&apos;)</span><br><span class="line">    parser.add_argument(&apos;--character&apos;, type=str, default=&apos;0123456789abcdefghijklmnopqrstuvwxyz&apos;, help=&apos;character label&apos;)</span><br><span class="line">    parser.add_argument(&apos;--sensitive&apos;, action=&apos;store_true&apos;, help=&apos;for sensitive character mode&apos;)</span><br><span class="line">    parser.add_argument(&apos;--PAD&apos;, action=&apos;store_true&apos;, help=&apos;whether to keep ratio then pad for image resize&apos;)</span><br><span class="line">    &quot;&quot;&quot; Model Architecture &quot;&quot;&quot;</span><br><span class="line">    parser.add_argument(&apos;--Transformation&apos;, type=str, help=&apos;Transformation stage. None|TPS&apos;)</span><br><span class="line">    parser.add_argument(&apos;--FeatureExtraction&apos;, type=str, help=&apos;FeatureExtraction stage. VGG|RCNN|ResNet&apos;)</span><br><span class="line">    parser.add_argument(&apos;--SequenceModeling&apos;, type=str, help=&apos;SequenceModeling stage. None|BiLSTM&apos;)</span><br><span class="line">    parser.add_argument(&apos;--Prediction&apos;, type=str, help=&apos;Prediction stage. CTC|Attn&apos;)</span><br><span class="line">    parser.add_argument(&apos;--num_fiducial&apos;, type=int, default=20, help=&apos;number of fiducial points of TPS-STN&apos;)</span><br><span class="line">    parser.add_argument(&apos;--input_channel&apos;, type=int, default=1, help=&apos;the number of input channel of Feature extractor&apos;)</span><br><span class="line">    parser.add_argument(&apos;--output_channel&apos;, type=int, default=512,</span><br><span class="line">                        help=&apos;the number of output channel of Feature extractor&apos;)</span><br><span class="line">    parser.add_argument(&apos;--hidden_size&apos;, type=int, default=256, help=&apos;the size of the LSTM hidden state&apos;)</span><br><span class="line"></span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line">    # 更改这里的位置</span><br><span class="line">    opt.image_folder = &apos;twoout/&apos;</span><br><span class="line">    &quot;&quot;&quot; vocab / character number configuration &quot;&quot;&quot;</span><br><span class="line">    if opt.sensitive:</span><br><span class="line">        opt.character = string.printable[:-6]  # same with ASTER setting (use 94 char).</span><br><span class="line"></span><br><span class="line">    cudnn.benchmark = True</span><br><span class="line">    cudnn.deterministic = True</span><br><span class="line">    opt.num_gpu = torch.cuda.device_count()</span><br><span class="line"></span><br><span class="line">    print(opt)</span><br><span class="line">    demo(opt)</span><br><span class="line"></span><br><span class="line">    values = demo(opt)</span><br><span class="line">    # 除去重复元素</span><br><span class="line">    values = list(set(values))</span><br><span class="line">    # 排序</span><br><span class="line">    values.sort(key=lambda x: int(x.split(&apos;/&apos;)[1].split(&apos;.&apos;)[0]))</span><br><span class="line">    for v in values:</span><br><span class="line">        print(v)</span><br></pre></td></tr></table></figure><p>5：paddle_ocr（微型模型，中英文混用，效果略优；通用模型也可以）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1：优势在于部署的时候有微型模型，中英文混用，速度快。</span><br><span class="line">2：适用于对精度要求不是特别高的场合</span><br><span class="line">3：免费</span><br><span class="line">4：部署简单</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;OCR总结和对比；实现书本的题干提取&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td c
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>阿里云函数计算</title>
    <link href="https://yanyubing.xyz/2020/05/06/%E9%98%BF%E9%87%8C%E4%BA%91%E5%87%BD%E6%95%B0%E8%AE%A1%E7%AE%97/"/>
    <id>https://yanyubing.xyz/2020/05/06/%E9%98%BF%E9%87%8C%E4%BA%91%E5%87%BD%E6%95%B0%E8%AE%A1%E7%AE%97/</id>
    <published>2020-05-06T07:06:55.455Z</published>
    <updated>2020-05-07T03:26:05.197Z</updated>
    
    <content type="html"><![CDATA[<p>阿里云函数计算流程总结：基于flask框架的http触发器，完成模板的匹配功能</p><p>1：安装docker，设置开启自启</p><p>2：下载fun <a href="https://github.com/alibaba/funcraft/releases?spm=a2c4g.11186623.2.15.6a3a66een3mFgU" target="_blank" rel="noopener">https://github.com/alibaba/funcraft/releases?spm=a2c4g.11186623.2.15.6a3a66een3mFgU</a> </p><p>3： 在本地创建一个目录test(作为临时目录存放依赖),  然后终端进入到该目录下，把自己配置的yml文件放在该目录下</p><p>4：test目录下运行fun install init    初始化环境为python3，会出现funfile文件</p><p>5：在funfile文件中编写安装的依赖</p><p>6： 执行sudo fun install安装依赖 ，会在test目录下出现.fun文件(拉取镜像过程很慢)</p><p>7：因为torch无法使用funfile安装， 在本地重新创建一个目录，在该目录下执行fun install sbox –runtime python3  –interactive进入沙箱环境 </p><p>8： 执行pip install -t . torch 安装</p><p>9： 安装成功后，把安装的内容复制到项目的.fun/python/lib/python3.6/site-packages 目录下 )</p><p>10：更改flaskapp的入口函数，将test目录底下的所有内容复制放到项目根目录</p><p>11：执行fun deploy -y部署 </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;阿里云函数计算流程总结：基于flask框架的http触发器，完成模板的匹配功能&lt;/p&gt;
&lt;p&gt;1：安装docker，设置开启自启&lt;/p&gt;
&lt;p&gt;2：下载fun &lt;a href=&quot;https://github.com/alibaba/funcraft/releases?spm
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>python_gui</title>
    <link href="https://yanyubing.xyz/2020/05/01/python_gui/"/>
    <id>https://yanyubing.xyz/2020/05/01/python_gui/</id>
    <published>2020-05-01T15:31:31.016Z</published>
    <updated>2020-05-05T07:46:43.407Z</updated>
    
    <content type="html"><![CDATA[<h3 id="PythonGUI-Tkinter"><a href="#PythonGUI-Tkinter" class="headerlink" title="PythonGUI-Tkinter"></a>PythonGUI-Tkinter</h3><p>为了做出可以提供给其他人使用的AI(CV方向)算法程序—实现切割纸张可视化（或者是制作label）</p><p>1：实现图片的切割，储存，检查，目录的创建</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br></pre></td><td class="code"><pre><span class="line"># Radio Buttons:单选框,创建多个单选框</span><br><span class="line">import os</span><br><span class="line">import time</span><br><span class="line">from tkinter import *</span><br><span class="line"></span><br><span class="line"># 初始化窗口</span><br><span class="line">import cv2</span><br><span class="line">from PIL import ImageTk, Image</span><br><span class="line"></span><br><span class="line">root = Tk()</span><br><span class="line">root.title(&apos;GUI_cutPaper&apos;)</span><br><span class="line"></span><br><span class="line"># 创建目录</span><br><span class="line">Label(root, text=&apos;输入要创建的目录路径，如：‘勤学早/Unit1/第一课时/第一大题’&apos;).grid(row=1, column=0)</span><br><span class="line">e_Dir = Entry(root)</span><br><span class="line">e_Dir.grid(row=2, column=0)</span><br><span class="line"></span><br><span class="line"># 输入图片，用来切割</span><br><span class="line">Label(root, text=&apos;输入要切割的图片路径，如：‘book/1.jpg’&apos;).grid(row=3, column=0)</span><br><span class="line">e_book = Entry(root)</span><br><span class="line">e_book.grid(row=4, column=0)</span><br><span class="line"></span><br><span class="line"># 保存图片</span><br><span class="line">Label(root, text=&apos;输入图片的保存路径,如：‘勤学早/Unit1/第一课时/第一大题/1.jpg’&apos;).grid(row=5, column=0)</span><br><span class="line">e_saveImage = Entry(root)</span><br><span class="line">e_saveImage.grid(row=6, column=0)</span><br><span class="line"></span><br><span class="line"># 检测图片</span><br><span class="line">Label(root, text=&apos;输入要检测的目录路径，如：‘勤学早’&apos;).grid(row=7, column=0)</span><br><span class="line">e_check = Entry(root)</span><br><span class="line">e_check.grid(row=8, column=0)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 鼠标事件，获取需要切割点的y坐标</span><br><span class="line">def on_EVENT_LBUTTONDOWN(event, x, y, flags, param):</span><br><span class="line">    if event == cv2.EVENT_LBUTTONDOWN:</span><br><span class="line">        xy = &quot;%d,%d&quot; % (x, y)</span><br><span class="line">        print(xy)</span><br><span class="line">        # cv2.circle(img, (x, y), 1, (255, 0, 0), thickness=-1)</span><br><span class="line">        # cv2.putText(img, xy, (x, y), cv2.FONT_HERSHEY_PLAIN,</span><br><span class="line">        #             1.0, (0, 0, 0), thickness=1)</span><br><span class="line">        dotsY.append(y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 创建目录</span><br><span class="line">def createDir():</span><br><span class="line">    path = e_Dir.get()</span><br><span class="line">    if os.path.exists(path):</span><br><span class="line">        # 提示信息</span><br><span class="line">        Label(root, text=&apos;文件路径已存在，请重新输入&apos;).grid(row=0, column=3)</span><br><span class="line">    else:</span><br><span class="line">        os.makedirs(path)</span><br><span class="line">        Label(root, text=path + &apos; ：创建成功&apos;).grid(row=0, column=3)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 存储切割的图片</span><br><span class="line">def saveImage():</span><br><span class="line">    # 遍历所有的file进行切割</span><br><span class="line">    global dotsY</span><br><span class="line">    dotsY = []</span><br><span class="line">    file_path_in = e_book.get()</span><br><span class="line">    global img</span><br><span class="line"></span><br><span class="line">    if not os.path.exists(file_path_in):</span><br><span class="line">        Label(root, text=file_path_in + &apos;输入的文件路径不存在，请重新输入&apos;).grid(row=0, column=3)</span><br><span class="line">    else:</span><br><span class="line">        img = cv2.imread(file_path_in)</span><br><span class="line">        cv2.namedWindow(&quot;image&quot;, 0)</span><br><span class="line">        cv2.resizeWindow(&apos;image&apos;, 600, 800)</span><br><span class="line">        cv2.imshow(&apos;image&apos;, img)</span><br><span class="line">        cv2.setMouseCallback(&quot;image&quot;, on_EVENT_LBUTTONDOWN)</span><br><span class="line">        cv2.waitKey(0)</span><br><span class="line">        cv2.destroyAllWindows()</span><br><span class="line">    print(&apos;得到的y坐标点为&apos;, dotsY)</span><br><span class="line">    file_path_out = e_saveImage.get()</span><br><span class="line">    if os.path.exists(file_path_out):</span><br><span class="line">        Label(root, text=file_path_in + &apos;输出的文件路径已经存在，请检查&apos;).grid(row=0, column=3)</span><br><span class="line">        return</span><br><span class="line">    image = img[dotsY[0]:dotsY[1], :]</span><br><span class="line">    # 处理带有中文的目录结构</span><br><span class="line">    cv2.imencode(&apos;.jpg&apos;, image)[1].tofile(file_path_out)</span><br><span class="line">    Label(root, text=file_path_out + &apos;文件保存成功&apos;).grid(row=0, column=3)</span><br><span class="line">    time.sleep(1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">index = 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取所有的文件名</span><br><span class="line">def listdir(path, list_name):</span><br><span class="line">    for file in os.listdir(path):</span><br><span class="line">        file_path = os.path.join(path, file)</span><br><span class="line">        if os.path.isdir(file_path):</span><br><span class="line">            listdir(file_path, list_name)</span><br><span class="line">        elif os.path.splitext(file_path)[1] == &apos;.jpg&apos;:</span><br><span class="line">            list_name.append(file_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 储存列表名</span><br><span class="line">listName = []</span><br><span class="line"># 储存所有转换之后的图片</span><br><span class="line">my_images = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 检查图片</span><br><span class="line">def checkImage():</span><br><span class="line">    # 前进，后退，退出按钮</span><br><span class="line">    button_back = Button(root, text=&apos;&lt;&lt;&apos;, command=back)</span><br><span class="line">    button_quit = Button(root, text=&apos;Exit&apos;, command=root.quit)</span><br><span class="line">    button_forward = Button(root, text=&apos;&gt;&gt;&apos;, command=forward)</span><br><span class="line">    button_back.grid(row=11, column=2)</span><br><span class="line">    button_quit.grid(row=11, column=3)</span><br><span class="line">    button_forward.grid(row=11, column=4)</span><br><span class="line"></span><br><span class="line">    global listName</span><br><span class="line"></span><br><span class="line">    path = e_check.get()</span><br><span class="line">    listdir(path, listName)</span><br><span class="line">    print(len(listName))</span><br><span class="line">    global my_images</span><br><span class="line"></span><br><span class="line">    for i in range(len(listName)):</span><br><span class="line">        # 打开图片，图片放入对象，对象再放入screen</span><br><span class="line">        my_img = ImageTk.PhotoImage(Image.open(listName[i]).resize((600, 300)))</span><br><span class="line">        my_images.append(my_img)</span><br><span class="line">    Label(root, image=my_images[0]).grid(row=10, column=3)</span><br><span class="line">    mainloop()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def showImage(index):</span><br><span class="line">    my_label = Label(root, image=my_images[index])</span><br><span class="line">    my_label.grid(row=10, column=3)</span><br><span class="line"></span><br><span class="line">    message = &apos;路径:&apos; + listName[index] + &apos;  Image &apos; + str(index + 1) + &apos; of&apos; + str(len(listName))</span><br><span class="line">    # 添加状态栏(多少张图片，多少个)</span><br><span class="line"></span><br><span class="line">    Label(root, text=message).grid(row=9, column=3)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def back():</span><br><span class="line">    # 申明全局变量</span><br><span class="line">    global index</span><br><span class="line">    index = (index - 1) % len(listName)</span><br><span class="line">    showImage(index)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def forward():</span><br><span class="line">    # 申明全局变量</span><br><span class="line">    global index</span><br><span class="line">    index = (index + 1) % len(listName)</span><br><span class="line">    showImage(index)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 三大组件位置</span><br><span class="line">button_CreateFile = Button(root, text=&quot;createDir&quot;, command=createDir)</span><br><span class="line">button_saveImage = Button(root, text=&quot;saveImage&quot;, command=saveImage)</span><br><span class="line">button_CheckImage = Button(root, text=&quot;checkImage&quot;, command=checkImage)</span><br><span class="line"></span><br><span class="line">button_CreateFile.grid(row=15, column=15, padx=2)</span><br><span class="line">button_saveImage.grid(row=16, column=15, padx=2)</span><br><span class="line">button_CheckImage.grid(row=17, column=15, padx=2)</span><br><span class="line"></span><br><span class="line">Label(root, text=&apos;使用步骤：&apos;).grid(row=12, column=0)</span><br><span class="line">Label(root, text=&apos;1、创建目录:输入需要创建的目录，点击createDir&apos;).grid(row=13, column=0)</span><br><span class="line">Label(root, text=&apos;2、切割图片:&apos;).grid(row=14, column=0)</span><br><span class="line">Label(root, text=&apos;①输入要切割的输入图片路径，以.jpg结尾&apos;).grid(row=15, column=0)</span><br><span class="line">Label(root, text=&apos;②输入需要保存的路径，以.jpg结尾&apos;).grid(row=16, column=0)</span><br><span class="line">Label(root, text=&apos;③点击saveImage进行切割操作&apos;).grid(row=17, column=0)</span><br><span class="line">Label(root, text=&apos;3、检测图片：输入需要检测图片的根目录，点击checkImage&apos;).grid(row=18, column=0)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root.mainloop()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;PythonGUI-Tkinter&quot;&gt;&lt;a href=&quot;#PythonGUI-Tkinter&quot; class=&quot;headerlink&quot; title=&quot;PythonGUI-Tkinter&quot;&gt;&lt;/a&gt;PythonGUI-Tkinter&lt;/h3&gt;&lt;p&gt;为了做出可以提供给其
      
    
    </summary>
    
    
    
  </entry>
  
</feed>
