<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>鄢玉兵的博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://yanyubing.xyz/"/>
  <updated>2021-07-03T01:32:57.068Z</updated>
  <id>https://yanyubing.xyz/</id>
  
  <author>
    <name>鄢玉兵</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>javascript（微信小程序）</title>
    <link href="https://yanyubing.xyz/2021/06/28/javascript%EF%BC%88%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%EF%BC%89/"/>
    <id>https://yanyubing.xyz/2021/06/28/javascript%EF%BC%88%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%EF%BC%89/</id>
    <published>2021-06-28T02:48:34.621Z</published>
    <updated>2021-07-03T01:32:57.068Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line">一：js起源</span><br><span class="line">最开始做网页前端验证的，后续功能加强</span><br><span class="line"></span><br><span class="line">二：ES,DOM,BOM</span><br><span class="line">ES标准</span><br><span class="line">DOM：操作文档</span><br><span class="line">BOM：操作浏览器</span><br><span class="line"></span><br><span class="line">三：功能</span><br><span class="line">alert()：弹出</span><br><span class="line">document.write()：写文档</span><br><span class="line">console.log()：日志，谷歌浏览器调试模式 Fn+F12</span><br><span class="line"></span><br><span class="line">四：往哪写</span><br><span class="line">可以写在body里面，button属性，a超链接中；但是不推荐</span><br><span class="line">1.一般写在script标签中</span><br><span class="line">2.可以写在外部，使用script引入：多次引用（推荐使用）</span><br><span class="line">3.script标签一旦引入外部标签，就不能在编写内部代码，</span><br><span class="line"></span><br><span class="line">五：基本语法</span><br><span class="line">1.注释</span><br><span class="line">2.严格区分大小写</span><br><span class="line">3.每一条语句以分号结尾（不是必须）</span><br><span class="line">4.会忽略多个空格和换行</span><br><span class="line"></span><br><span class="line">六：字面量（常量）和变量</span><br><span class="line">1.变量的声明与赋值</span><br><span class="line"></span><br><span class="line">七：标识符</span><br><span class="line">标识符的使用规则</span><br><span class="line">底层使用utf-8编码保存，理论上可以使用所有utf-8的字符（如中文）</span><br><span class="line"></span><br><span class="line">八：数据类型</span><br><span class="line">String：转义字符</span><br><span class="line">Number：</span><br><span class="line">最大值 Number.MAX_VALUE，NaN:Not a number</span><br><span class="line">大于0的最小值 Number.MIN_VALUE</span><br><span class="line">注意浮点数的1/3转换二进制的问题</span><br><span class="line">Boolean：</span><br><span class="line">Null：空对象</span><br><span class="line">Undefined：未定义（赋值）</span><br><span class="line">Object：</span><br><span class="line">typeof()：检测数据类型</span><br><span class="line"></span><br><span class="line">九：强制类型转换</span><br><span class="line">a.toString()</span><br><span class="line">String(a)</span><br><span class="line">Number(a):true(1),flase(0),Null(0)</span><br><span class="line">parseInt(a)：转换为Int,读取截止到不是数字</span><br><span class="line">parseInt(a,10)：指定数字进制</span><br><span class="line">Boolean()</span><br><span class="line"></span><br><span class="line">十：其他进制</span><br><span class="line">a=0x10:16进制</span><br><span class="line">a=010:8进制</span><br><span class="line">a=0b10：2进制</span><br><span class="line"></span><br><span class="line">十一：运算符(操作符)</span><br><span class="line">算术运算符</span><br><span class="line"></span><br><span class="line">十二：一元运算符</span><br><span class="line">自增，自减</span><br><span class="line">a++</span><br><span class="line">a--</span><br><span class="line"></span><br><span class="line">十三：逻辑运算符</span><br><span class="line">! 非</span><br><span class="line">&amp;&amp; 与</span><br><span class="line">|| 或</span><br><span class="line"></span><br><span class="line">十四：赋值运算符</span><br><span class="line">+=，-=，...</span><br><span class="line"></span><br><span class="line">十五：关系运算符</span><br><span class="line">&gt;,&lt;,==</span><br><span class="line"></span><br><span class="line">十六：Unicode编码</span><br><span class="line">\u：转义字符输出（十六进制）</span><br><span class="line">在页面中使用unicode编码：&amp;#xxxx（xxxx为十进制数）</span><br><span class="line"></span><br><span class="line">十七：NaN比较</span><br><span class="line">NaN不与任何值相等，包括它本身</span><br><span class="line">isNaN()判断一个值是不是NaN</span><br><span class="line"></span><br><span class="line">十八：相等运算符</span><br><span class="line">===：全等（类型也会比较）</span><br><span class="line">！==：不全等</span><br><span class="line"></span><br><span class="line">十九：条件运算符</span><br><span class="line">条件表达式?预计1：语句2（true执行1返回执行结果，false执行2返回执行结果）</span><br><span class="line"></span><br><span class="line">二十：运算符优先级</span><br><span class="line"></span><br><span class="line">二十一：代码块</span><br><span class="line">同时执行或不执行</span><br><span class="line"></span><br><span class="line">二十二：if</span><br><span class="line">if语句只能控制紧随其后的一句话（使用&#123;&#125;代码块作用）</span><br><span class="line">if(条件语句)&#123;</span><br><span class="line">...</span><br><span class="line">&#125;else&#123;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if()&#123;</span><br><span class="line">&#125;else if()&#123;</span><br><span class="line">&#125;</span><br><span class="line">else if()&#123;</span><br><span class="line">&#125;else&#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">二十三：prompt()</span><br><span class="line">可以弹出提示框，带有文本框</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>jetsonnano-全</title>
    <link href="https://yanyubing.xyz/2021/01/29/jetsonnano-%E5%85%A8/"/>
    <id>https://yanyubing.xyz/2021/01/29/jetsonnano-%E5%85%A8/</id>
    <published>2021-01-29T07:09:14.450Z</published>
    <updated>2021-02-03T01:03:00.379Z</updated>
    
    <content type="html"><![CDATA[<p>1.python环境</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">可以使用系统自带python3.6.9</span><br></pre></td></tr></table></figure><p>2.拉取代码</p><p>3.安装依赖</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">包含torch和torchvison，注意jetpack版本，注意torch依赖的Numpy版本</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.python环境&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;co
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>全栈-python高级</title>
    <link href="https://yanyubing.xyz/2021/01/18/%E5%85%A8%E6%A0%88-python%E9%AB%98%E7%BA%A7/"/>
    <id>https://yanyubing.xyz/2021/01/18/%E5%85%A8%E6%A0%88-python%E9%AB%98%E7%BA%A7/</id>
    <published>2021-01-18T03:44:13.876Z</published>
    <updated>2021-01-18T03:49:36.841Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.liaoxuefeng.com/wiki/1016959663602400" target="_blank" rel="noopener">https://www.liaoxuefeng.com/wiki/1016959663602400</a></p><p>进程和线程</p><p>图形界面</p><p>网络编程</p><p>电子邮件</p><p>访问数据库</p><p>web开发</p><p>异步IO</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://www.liaoxuefeng.com/wiki/1016959663602400&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.liaoxuefeng.com/wiki/1016959663602
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>花书</title>
    <link href="https://yanyubing.xyz/2021/01/14/%E8%8A%B1%E4%B9%A6/"/>
    <id>https://yanyubing.xyz/2021/01/14/%E8%8A%B1%E4%B9%A6/</id>
    <published>2021-01-14T06:31:49.652Z</published>
    <updated>2021-01-14T06:37:23.149Z</updated>
    
    <content type="html"><![CDATA[<h1 id="花书"><a href="#花书" class="headerlink" title="花书"></a>花书</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.范数(p24)</span><br><span class="line">在机器学习中，我们经常使用成为范数的函数来衡量向量的大小</span><br><span class="line">理解：主要是用来平衡权重向量W，减小过拟合（过滤权重向量中不必要的特征）</span><br><span class="line">L0范数：向量中非0元素的个数</span><br><span class="line">L1范数：向量的个元素的绝对值之和（通常用来代替L0范数）</span><br><span class="line">L2范数：向量离圆点的欧几里得距离</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;花书&quot;&gt;&lt;a href=&quot;#花书&quot; class=&quot;headerlink&quot; title=&quot;花书&quot;&gt;&lt;/a&gt;花书&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span 
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>全栈-尚硅谷python</title>
    <link href="https://yanyubing.xyz/2021/01/12/%E5%85%A8%E6%A0%88-%E5%B0%9A%E7%A1%85%E8%B0%B7python/"/>
    <id>https://yanyubing.xyz/2021/01/12/%E5%85%A8%E6%A0%88-%E5%B0%9A%E7%A1%85%E8%B0%B7python/</id>
    <published>2021-01-12T01:31:03.992Z</published>
    <updated>2021-01-13T09:26:31.233Z</updated>
    
    <content type="html"><![CDATA[<p>全栈-尚硅谷python</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">一：windows path环境变量</span><br><span class="line">注意：在任意位置都可以访问path环境变量</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">二：纯文本与富文本</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">三：字符集</span><br><span class="line">字符转换为二进制码过程-编码</span><br><span class="line">二进制码转换为字符的过程-解码</span><br><span class="line"></span><br><span class="line">编码→解码：使用字符集规则</span><br><span class="line">每个国家有自己的字符集，现在统一使用Unicode（万国码）：万国码的实现使用最多的是utf-8</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">四：浮点数计算精度问题</span><br><span class="line">0.1+0.2=0.30000000000000004</span><br><span class="line">计算机中浮点数转换为二进制有精度损失</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">五：关系运算符</span><br><span class="line">== ：比较值</span><br><span class="line">is,is not ：比较的对象的id</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">六：列表获取索引值</span><br><span class="line">lists.index(&apos;xxx&apos;):返回第一个元素的索引值</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">七：可变序列与不可变序列</span><br><span class="line">list：可变序列，也只能改变值，无法改变对象的id</span><br><span class="line">str():不可变序列，可转为list修改之后改回str</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">八：元祖(不可变对象)</span><br><span class="line">元祖解包</span><br><span class="line">a,b,*c=my_tuple</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">九：复制</span><br><span class="line">浅复制会复制对象内部的值，如果值也是一个可变对象，这个可变对象不会被复制</span><br><span class="line">&gt;&gt;&gt;a = &#123;1: [1,2,3]&#125;</span><br><span class="line">&gt;&gt;&gt; b = a.copy()</span><br><span class="line">&gt;&gt;&gt; a, b</span><br><span class="line">(&#123;1: [1, 2, 3]&#125;, &#123;1: [1, 2, 3]&#125;)</span><br><span class="line">&gt;&gt;&gt; a[1].append(4)</span><br><span class="line">&gt;&gt;&gt; a, b</span><br><span class="line">(&#123;1: [1, 2, 3, 4]&#125;, &#123;1: [1, 2, 3, 4]&#125;)</span><br><span class="line">深复制会复制对象内部的值，如果值也是一个可变对象，这个可变对象也会被复制</span><br><span class="line">&gt;&gt;&gt;import copy</span><br><span class="line">&gt;&gt;&gt; c = copy.deepcopy(a)</span><br><span class="line">&gt;&gt;&gt; a, c</span><br><span class="line">(&#123;1: [1, 2, 3, 4]&#125;, &#123;1: [1, 2, 3, 4]&#125;)</span><br><span class="line">&gt;&gt;&gt; a[1].append(5)</span><br><span class="line">&gt;&gt;&gt; a, c</span><br><span class="line">(&#123;1: [1, 2, 3, 4, 5]&#125;, &#123;1: [1, 2, 3, 4]&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">十：集合</span><br><span class="line">集合中不储存重复元素；集合中只能存储不可变对象，str...</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">十一：不定长参数</span><br><span class="line">def sum(*a):</span><br><span class="line">pass</span><br><span class="line">可变参数不是必须写在最后，但是注意，带*的参数后的所有参数，必须以关键字参数的形式传递</span><br><span class="line">装包与解包：</span><br><span class="line">**形参只能有一个，必须写在所有参数的最后</span><br><span class="line">def sum(a,b,**c):</span><br><span class="line">pass</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">十二：文档字符串</span><br><span class="line">def fn(a:int) -&gt; int:#提示传入参数a为int类型，返回值是int类型</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">文档字符串...</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">pass</span><br><span class="line">使用help(fn)查看文档字符串</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">十三：作用域</span><br><span class="line"># 在Python中一共有两种作用域</span><br><span class="line">#  全局作用域</span><br><span class="line">#   - 全局作用域在程序执行时创建，在程序执行结束时销毁</span><br><span class="line">#   - 所有函数以外的区域都是全局作用域</span><br><span class="line">#   - 在全局作用域中定义的变量，都属于全局变量，全局变量可以在程序的任意位置被访问</span><br><span class="line">#   </span><br><span class="line">#  函数作用域</span><br><span class="line">#   - 函数作用域在函数调用时创建，在调用结束时销毁</span><br><span class="line">#   - 函数每调用一次就会产生一个新的函数作用域</span><br><span class="line">#   - 在函数作用域中定义的变量，都是局部变量，它只能在函数内部被访问</span><br><span class="line">#  变量的查找</span><br><span class="line">#   - 当我们使用变量时，会优先在当前作用域中寻找该变量，如果有则使用，</span><br><span class="line">#       如果没有则继续去上一级作用域中寻找，如果有则使用，</span><br><span class="line">#       如果依然没有则继续去上一级作用域中寻找，以此类推</span><br><span class="line">#       直到找到全局作用域，依然没有找到，则会抛出异常</span><br><span class="line">#           NameError: name &apos;a&apos; is not defined</span><br><span class="line"></span><br><span class="line">a = 20</span><br><span class="line">def fn3():</span><br><span class="line">    # a = 10 # 在函数中为变量赋值时，默认都是为局部变量赋值</span><br><span class="line">    # 如果希望在函数内部修改全局变量，则需要使用global关键字，来声明变量</span><br><span class="line">    global a # 声明在函数内部的使用a是全局变量，此时再去修改a时，就是在修改全局的a</span><br><span class="line">    a = 10 # 修改全局变量</span><br><span class="line">    print(&apos;函数内部：&apos;,&apos;a =&apos;,a)</span><br><span class="line"></span><br><span class="line"># fn3()</span><br><span class="line"># print(&apos;函数外部：&apos;,&apos;a =&apos;,a)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">十四：命名空间</span><br><span class="line">scope=locals()#当前命名空间，scope为字典类型</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">十五：高阶函数</span><br><span class="line"># 高阶函数</span><br><span class="line"># 接收函数作为参数，或者将函数作为返回值的函数是高阶函数（称为闭包）</span><br><span class="line">def fn():</span><br><span class="line">    a = 10</span><br><span class="line">    # 函数内部再定义一个函数</span><br><span class="line">    def inner():</span><br><span class="line">        print(&apos;我是fn2&apos; , a)</span><br><span class="line">    # 将内部函数 inner作为返回值返回   </span><br><span class="line">    return inner</span><br><span class="line"># 当我们使用一个函数作为参数时，实际上是将指定的代码传递进了目标函数</span><br><span class="line">当函数中需要不同的函数功能时，内部函数可以抽离出来作为参数</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">十六：匿名函数（一般作为参数使用，其他地方不会使用）</span><br><span class="line"># filter()</span><br><span class="line"># filter()可以从序列中过滤出符合条件的元素，保存到一个新的序列中</span><br><span class="line"># 参数：</span><br><span class="line">#  1.函数，根据该函数来过滤序列（可迭代的结构）</span><br><span class="line">#  2.需要过滤的序列（可迭代的结构）</span><br><span class="line"># 返回值：</span><br><span class="line">#   过滤后的新序列（可迭代的结构）</span><br><span class="line"></span><br><span class="line"># fn4是作为参数传递进filter()函数中</span><br><span class="line">#   而fn4实际上只有一个作用，就是作为filter()的参数</span><br><span class="line">#   filter()调用完毕以后，fn4就已经没用</span><br><span class="line"># 匿名函数 lambda 函数表达式 （语法糖）</span><br><span class="line">#   lambda函数表达式专门用来创建一些简单的函数，他是函数创建的又一种方式</span><br><span class="line">#   语法：lambda 参数列表 : 返回值</span><br><span class="line">#   匿名函数一般都是作为参数使用，其他地方一般不会使用</span><br><span class="line"></span><br><span class="line"># map()函数可以对可跌倒对象中的所有元素做指定的操作，然后将其添加到一个新的对象中返回</span><br><span class="line">l = [1,2,3,4,5,6,7,8,9,10]</span><br><span class="line"></span><br><span class="line">r = map(lambda i : i ** 2 , l)</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">十七：sort()</span><br><span class="line">sort()排序</span><br><span class="line">sorted()对任何序列都可以排序，返回值为新的序列</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">十八：装饰器</span><br><span class="line">程序的设计，要求开发对程序的扩展，要关闭对程序的修改</span><br><span class="line">def begin_end(old):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">        用来对其他函数进行扩展，使其他函数可以在执行前打印开始执行，执行后打印执行结束</span><br><span class="line">        参数：</span><br><span class="line">            old 要扩展的函数对象</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    # 创建一个新函数</span><br><span class="line">    def new_function(*args , **kwargs):</span><br><span class="line">        print(&apos;开始执行~~~~&apos;)</span><br><span class="line">        # 调用被扩展的函数</span><br><span class="line">        result = old(*args , **kwargs)</span><br><span class="line">        print(&apos;执行结束~~~~&apos;)</span><br><span class="line">        # 返回函数的执行结果</span><br><span class="line">        return result</span><br><span class="line">    # 返回新函数        </span><br><span class="line">    return new_function</span><br><span class="line">    </span><br><span class="line">@begin_end#可以为一个函数增加多个装饰器，内部先装饰</span><br><span class="line">def say_hello():</span><br><span class="line">    print(&apos;大家好~~~&apos;)</span><br><span class="line">#   在开发中，我们都是通过装饰器来扩展函数的功能的</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">十八：类</span><br><span class="line">class MyClass():</span><br><span class="line">pass</span><br><span class="line">mc=MyClass()#创建一个MyClass的对象</span><br><span class="line"></span><br><span class="line">result=isinstance(mc,MyClass)#判断对象是不是该类的</span><br><span class="line"></span><br><span class="line"># 调用方法，对象.方法名()</span><br><span class="line"># 方法调用和函数调用的区别</span><br><span class="line"># 如果是函数调用，则调用时传几个参数，就会有几个实参</span><br><span class="line"># 但是如果是方法调用，默认传递一个参数，所以方法中至少要定义一个形参</span><br><span class="line"></span><br><span class="line">类的方法中，无法直接访问类的属性</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">十九：方法</span><br><span class="line">魔术方法：(双下划线开始，双下划线结尾__init__(self))</span><br><span class="line"></span><br><span class="line"># 创建对象的流程</span><br><span class="line"># p1 = Person()的运行流程</span><br><span class="line">#   1.创建一个变量</span><br><span class="line">#   2.在内存中创建一个新对象</span><br><span class="line">#   3.__init__(self)方法执行</span><br><span class="line">#   4.将对象的id赋值给变量</span><br><span class="line"></span><br><span class="line">class Person():</span><br><span class="line">    # init会在对象创建以后离开执行</span><br><span class="line">    # init可以用来向新创建的对象中初始化属性</span><br><span class="line">    # 调用类创建对象时，类后边的所有参数都会依次传递到init()中</span><br><span class="line">    def __init__(self,name):</span><br><span class="line">        # print(self)</span><br><span class="line">        # 通过self向新建的对象中初始化属性</span><br><span class="line">        self.name = name</span><br><span class="line"></span><br><span class="line">    def say_hello(self):</span><br><span class="line">        print(&apos;大家好，我是%s&apos;%self.name)</span><br><span class="line"></span><br><span class="line">p=Person(&apos;swk&apos;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;全栈-尚硅谷python&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>opencv实战20</title>
    <link href="https://yanyubing.xyz/2021/01/09/opencv%E5%AE%9E%E6%88%9820/"/>
    <id>https://yanyubing.xyz/2021/01/09/opencv%E5%AE%9E%E6%88%9820/</id>
    <published>2021-01-09T03:45:40.011Z</published>
    <updated>2021-01-09T05:59:22.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="opencv实战20讲"><a href="#opencv实战20讲" class="headerlink" title="opencv实战20讲"></a>opencv实战20讲</h1><p>一：颜色分割</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 颜色分割</span><br><span class="line"></span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line"># 1.读取图片</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">image = cv2.imread(&apos;bird.jpg&apos;)</span><br><span class="line"># 2.滤波操作，减少图片中的细微差异</span><br><span class="line">blur2 = cv2.bilateralFilter(image, 9, 75, 75)</span><br><span class="line"># 3.bgr转换为hsv，因为HSV空间中，三者相对独立，可以准确描述像素的亮度，饱和度和色度</span><br><span class="line">hsv = cv2.cvtColor(blur2, cv2.COLOR_BGR2HSV)</span><br><span class="line"># 4.查找范围</span><br><span class="line">low_blue = np.array([55, 0, 0])</span><br><span class="line">high_blue = np.array([118, 255, 255])</span><br><span class="line"># 5.mask</span><br><span class="line">mask = cv2.inRange(hsv, low_blue, high_blue)</span><br><span class="line"># 6.提取最终图片</span><br><span class="line">res = cv2.bitwise_and(image, image, mask=mask)</span><br><span class="line">cv2.imshow(&apos;image.jpg&apos;, res)</span><br><span class="line">cv2.waitKey(0)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;opencv实战20讲&quot;&gt;&lt;a href=&quot;#opencv实战20讲&quot; class=&quot;headerlink&quot; title=&quot;opencv实战20讲&quot;&gt;&lt;/a&gt;opencv实战20讲&lt;/h1&gt;&lt;p&gt;一：颜色分割&lt;/p&gt;
&lt;figure class=&quot;highligh
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>greedAi</title>
    <link href="https://yanyubing.xyz/2021/01/06/greedAi/"/>
    <id>https://yanyubing.xyz/2021/01/06/greedAi/</id>
    <published>2021-01-06T02:08:38.611Z</published>
    <updated>2021-01-06T04:25:31.802Z</updated>
    
    <content type="html"><![CDATA[<h3 id="贪心学院代码"><a href="#贪心学院代码" class="headerlink" title="贪心学院代码"></a>贪心学院代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#https://www.youtube.com/playlist?list=PLt2F7ir0KONp5cx8qXWUz18eSDZP1erGr</span><br></pre></td></tr></table></figure><p>demo15</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># 线性回归,逻辑回归</span><br><span class="line">from sklearn import linear_model</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 创建逻辑回归模型</span><br><span class="line">reg = linear_model.LogisticRegression()</span><br><span class="line"># 创建线性回归模型</span><br><span class="line">leg = linear_model.LinearRegression()</span><br><span class="line"></span><br><span class="line">x1 = [20, 23, 31, 42, 50, 60]</span><br><span class="line">x2 = [3, 7, 10, 13, 7, 5]</span><br><span class="line">y = np.array([0, 1, 1, 1, 0, 0])</span><br><span class="line"># 创建x</span><br><span class="line">x = np.array([[x1[index], x2[index]] for index in range(len(x1))])</span><br><span class="line">print(x)</span><br><span class="line"># 训练</span><br><span class="line">reg.fit(x, y)</span><br><span class="line">leg.fit(x, y)</span><br><span class="line"># 预测</span><br><span class="line">res1 = reg.predict(np.array([[28, 8]]))</span><br><span class="line"># 概率</span><br><span class="line">res1_1 = reg.predict_proba(np.array([[28, 8]]))</span><br><span class="line"></span><br><span class="line">res2 = leg.predict(np.array([[28, 8]]))</span><br><span class="line">print(res1)</span><br><span class="line">print(res1_1)</span><br><span class="line"></span><br><span class="line">print(res2)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;贪心学院代码&quot;&gt;&lt;a href=&quot;#贪心学院代码&quot; class=&quot;headerlink&quot; title=&quot;贪心学院代码&quot;&gt;&lt;/a&gt;贪心学院代码&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gut
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>学习</title>
    <link href="https://yanyubing.xyz/2020/12/25/%E5%AD%A6%E4%B9%A0/"/>
    <id>https://yanyubing.xyz/2020/12/25/%E5%AD%A6%E4%B9%A0/</id>
    <published>2020-12-25T06:14:55.394Z</published>
    <updated>2021-01-14T06:17:12.008Z</updated>
    
    <content type="html"><![CDATA[<p>学习路线</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">已完成</span><br><span class="line">course课程：</span><br><span class="line">1.Neural Networks and Deep Learning</span><br><span class="line">2.Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization</span><br><span class="line">3.Convolutional Neural Networks</span><br><span class="line">4.AI for everyone</span><br><span class="line">5.Machine Learning</span><br><span class="line"></span><br><span class="line">斯坦福大学公开课：</span><br><span class="line">https://www.youtube.com/watch?v=vT1JzLTH4G4&amp;list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv</span><br><span class="line"></span><br><span class="line">微软：</span><br><span class="line">https://www.youtube.com/playlist?list=PLlrxD0HtieHhS8VzuMCfQD4uJ9yne1mE6</span><br><span class="line">https://github.com/microsoft/c9-python-getting-started</span><br><span class="line"></span><br><span class="line">全栈开发：</span><br><span class="line">尚硅谷Python进阶路线</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">进行中</span><br><span class="line"></span><br><span class="line">贪心学院计算机视觉：</span><br><span class="line">https://www.youtube.com/watch?v=U2NZsyLYiKk&amp;list=PLt2F7ir0KONp5cx8qXWUz18eSDZP1erGr&amp;index=47</span><br><span class="line"></span><br><span class="line">书籍：</span><br><span class="line">花书</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">未开始</span><br><span class="line"></span><br><span class="line">书籍：</span><br><span class="line">pytorch深度学习</span><br><span class="line">计算机视觉-算法与应用</span><br><span class="line"></span><br><span class="line">贪心学院NLP：</span><br><span class="line">https://www.youtube.com/watch?v=1dQnPCKMaCY&amp;list=PLt2F7ir0KONoH2HXXlKpBSmUKkokOgOvr</span><br><span class="line"></span><br><span class="line">计算机视觉十大应用：</span><br><span class="line">01-10</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;学习路线&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>疑虑汇总</title>
    <link href="https://yanyubing.xyz/2020/12/14/%E7%96%91%E8%99%91%E6%B1%87%E6%80%BB/"/>
    <id>https://yanyubing.xyz/2020/12/14/%E7%96%91%E8%99%91%E6%B1%87%E6%80%BB/</id>
    <published>2020-12-14T07:34:04.311Z</published>
    <updated>2020-12-14T07:49:46.187Z</updated>
    
    <content type="html"><![CDATA[<h1 id="疑虑汇总"><a href="#疑虑汇总" class="headerlink" title="疑虑汇总"></a>疑虑汇总</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">一：抽帧的时候一秒内多次抽帧采样是否会造成过拟合</span><br><span class="line">答：是</span><br><span class="line"></span><br><span class="line">二：如果确定事件的发生基于一定的前提，例如：需要判断人是否在丢垃圾，只需要获取人的正面图片作为人的样本标签（因为人只有正面的时候才会产生我们所需要的识别的业务），只标注正面的人是否可行？</span><br><span class="line">答：可行，只是同时需要增加人体其他状态的类别</span><br><span class="line"></span><br><span class="line">三：对于使用Box位置关系来判断人行为是否发生的情况，可能二维上相交，但是三维上不想交，例如人是否佩戴安全帽？</span><br><span class="line">答：还未得到理想答案</span><br><span class="line"></span><br><span class="line">四：相交的关系会影响到物体的完整类别（例如人佩戴安全帽，如果类别分开则需要人脑，安全帽两个类别，但是佩戴了安全帽的人脑会显示不全），是采用多个物体的形式还是整体作为一个状态（或者把佩戴了安全帽的人作为一个类别）？</span><br><span class="line">答：应该根据实际业务来看，此种形式（人佩戴了安全帽）还是保留了人和安全帽的部分特征，那么作为一个类别也可行；但是某种情况下会被完全遮挡的时候作为一个类别就不可行，例如人手拿某个物体的时候。</span><br><span class="line"></span><br><span class="line">五：对于不同角度的固定摄像头(a,b)采集的视频，使用一个模型训练和应用还是每个摄像头的视频使用一个模型？如果是一个视频，那么a,b采集的数据的比例是否要保持1:1左右。</span><br><span class="line">答：还未得到理想答案</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;疑虑汇总&quot;&gt;&lt;a href=&quot;#疑虑汇总&quot; class=&quot;headerlink&quot; title=&quot;疑虑汇总&quot;&gt;&lt;/a&gt;疑虑汇总&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pr
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>论文解读hog-cvpr2005</title>
    <link href="https://yanyubing.xyz/2020/12/02/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BBhog-cvpr2005/"/>
    <id>https://yanyubing.xyz/2020/12/02/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BBhog-cvpr2005/</id>
    <published>2020-12-02T06:58:34.002Z</published>
    <updated>2020-12-02T07:40:57.609Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Histograms-of-Oriented-Gradients-for-Human-Detection"><a href="#Histograms-of-Oriented-Gradients-for-Human-Detection" class="headerlink" title="Histograms of Oriented Gradients for Human Detection"></a><strong>Histograms of Oriented Gradients for Human Detection</strong></h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">思想：在一副图像中，局部目标的表象和形状（appearance and shape）能够被梯度或边缘的方向密度分布很好地描述。（本质：梯度的统计信息，而梯度主要存在于边缘的地方）。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">给我的感觉是HOG+SVM适用于分类，并不适用于定位（对于尺度变化很大的目标），主要原因是HOG特征的维度是固定的</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">提取Hog特征的过程：</span><br><span class="line">1.灰度化</span><br><span class="line">2.Gamma校正</span><br><span class="line">3.计算图像每个像素的梯度（包括大小和方向，梯度的大小即为梯度值）；主要是为了捕获轮廓信息，同时进一步弱化光照的干扰。</span><br><span class="line">4.将图像划分成小cells（例如6*6像素/cell）</span><br><span class="line">5.统计每个cell的梯度直方图（不同梯度的个数）</span><br><span class="line">6.将每几个cell组成一个block（例如3*3个cell/block），一个block内所有cell的特征descriptor串联起来便得到该block的HOG特征descriptor</span><br><span class="line">7.将图像image内的所有block的HOG特征descriptor串联起来就可以得到该image（你要检测的目标）的HOG特征descriptor了。这个就是最终的可供分类使用的特征向量了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">总结：Dalal提出的Hog特征提取的过程：把样本图像分割为若干个像素的单元（cell），把梯度方向平均划分为9个区间（bin），在每个单元里面对所有像素的梯度方向在各个方向区间进行直方图统计，得到一个9维的特征向量，每相邻的4个单元构成一个块（block），把一个块内的特征向量联起来得到36维的特征向量，用块对样本图像进行扫描，扫描步长为一个单元。最后将所有块的特征串联起来，就得到了人体的特征。例如，对于64*128的图像而言，每8*8的像素组成一个cell，每2*2个cell组成一个块，因为每个cell有9个特征，所以每个块内有4*9=36个特征，以8个像素为步长，那么，水平方向将有7个扫描窗口，垂直方向将有15个扫描窗口。也就是说，64*128的图片，总共有36*7*15=3780个特征。</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Histograms-of-Oriented-Gradients-for-Human-Detection&quot;&gt;&lt;a href=&quot;#Histograms-of-Oriented-Gradients-for-Human-Detection&quot; class=&quot;headerl
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>python高级</title>
    <link href="https://yanyubing.xyz/2020/12/02/python%E9%AB%98%E7%BA%A7/"/>
    <id>https://yanyubing.xyz/2020/12/02/python%E9%AB%98%E7%BA%A7/</id>
    <published>2020-12-02T02:36:46.602Z</published>
    <updated>2020-12-02T03:30:29.087Z</updated>
    
    <content type="html"><![CDATA[<h1 id="python高级用法"><a href="#python高级用法" class="headerlink" title="python高级用法"></a>python高级用法</h1><p>一：数据库中的name age对，需要建立连接，把age赋值给name变量；如zs=18；可以解决造变量的问题（一般情况下尽量不使用，会造成变量过多，必须要多个变量的时候使用）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 获取数据库中年龄赋值给姓名变量</span><br><span class="line">a = &apos;zhangsan&apos;</span><br><span class="line">globals()[a] = &apos;18&apos;</span><br><span class="line">print(zhangsan)</span><br></pre></td></tr></table></figure><p>二：字典求交集并集</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 字典的操作</span><br><span class="line">d1 = dict(a=1, b=2)</span><br><span class="line">d2 = dict(b=2, c=3)</span><br><span class="line">v1 = d1.items()</span><br><span class="line">v2 = d2.items()</span><br><span class="line">print(type(v1 &amp; v2))#返回的set集合</span><br><span class="line">print(dict(v1 | v2))</span><br></pre></td></tr></table></figure><p>三：模块itertools</p><p>四：模块collections</p><p>五：模块operator</p><p>六：模块functools</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;python高级用法&quot;&gt;&lt;a href=&quot;#python高级用法&quot; class=&quot;headerlink&quot; title=&quot;python高级用法&quot;&gt;&lt;/a&gt;python高级用法&lt;/h1&gt;&lt;p&gt;一：数据库中的name age对，需要建立连接，把age赋值给name变量；
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>论文解读viola-cvpr</title>
    <link href="https://yanyubing.xyz/2020/12/01/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BBviola-cvpr/"/>
    <id>https://yanyubing.xyz/2020/12/01/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BBviola-cvpr/</id>
    <published>2020-12-01T08:31:37.236Z</published>
    <updated>2020-12-02T06:40:54.747Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Rapid-Object-Detection-using-a-Boosted-Cascade-of-Simple-Features"><a href="#Rapid-Object-Detection-using-a-Boosted-Cascade-of-Simple-Features" class="headerlink" title="*Rapid Object Detection using a Boosted Cascade of Simple *Features"></a>*<em>Rapid Object Detection using a Boosted Cascade of Simple *</em>Features</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">论文描述：使用boosted进行简单特征的级联达到快速的目标检测</span><br><span class="line">①使用了积分图的方式描述图片，更加快速的计算</span><br><span class="line">②使用了AdaBoost，从大量特征中选取少量特征</span><br><span class="line">③使用了级联结构：快速剔除背景区域，把算力用在目标区域上（focus-of-attention）</span><br></pre></td></tr></table></figure><p>1.环境条件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">图片像素大小：384*288像素，灰度图</span><br><span class="line">检测器大小：24*24像素</span><br><span class="line">应用于人脸检测的框架</span><br></pre></td></tr></table></figure><p>2.技术特点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">①Integral Image</span><br><span class="line">②AdaBoost cascade（有点像决策树）</span><br><span class="line">③Haar特征</span><br></pre></td></tr></table></figure><p>3.工作流程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">灰度图像计算积分图，利用积分图可以快速计算haar-like特征（一个正放的矩形区域只需要4次积分图上点的值，使得每个窗口的计算复杂度和窗口大小无关）</span><br><span class="line">训练AdaBoost cascade：从180k特征池中选择一组最有利于人脸检测的小特征</span><br><span class="line">每个sub_windows进行级联判断（可以快速舍去背景区域）</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Rapid-Object-Detection-using-a-Boosted-Cascade-of-Simple-Features&quot;&gt;&lt;a href=&quot;#Rapid-Object-Detection-using-a-Boosted-Cascade-of-Simpl
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>track</title>
    <link href="https://yanyubing.xyz/2020/11/27/track/"/>
    <id>https://yanyubing.xyz/2020/11/27/track/</id>
    <published>2020-11-27T08:35:44.977Z</published>
    <updated>2020-12-18T09:16:53.622Z</updated>
    
    <content type="html"><![CDATA[<h1 id="cv-track"><a href="#cv-track" class="headerlink" title="cv-track"></a>cv-track</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">1.box大小限制</span><br><span class="line">2.conf值的限定</span><br><span class="line">3.误识别的反喂https://www.pythonf.cn/read/70211；误识别的根本原因就是训练数据不够，对于hard negative的采样不全</span><br><span class="line">4.如果要识别人的正面，一定要标注人的侧面作为另一个类别</span><br><span class="line">5.视频流中对类别的位置判断，一般而言会同时出现多帧，如果只出现一帧，则很可能是识别错误，排除掉</span><br><span class="line">6.不要显示的使用for循环，可以使用向量化的时候使用numpy向量化；或者使用内建函数完成，有SIMD单元（优化）</span><br><span class="line">7.日志中不要打印时间的时候要看着时间的打印频率！文件大小爆掉</span><br><span class="line">8.提醒方式有，HTML界面监控，邮件提醒，短信提醒（紧急最优）</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;cv-track&quot;&gt;&lt;a href=&quot;#cv-track&quot; class=&quot;headerlink&quot; title=&quot;cv-track&quot;&gt;&lt;/a&gt;cv-track&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td cl
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>目标检测20年</title>
    <link href="https://yanyubing.xyz/2020/11/24/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B20%E5%B9%B4/"/>
    <id>https://yanyubing.xyz/2020/11/24/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B20%E5%B9%B4/</id>
    <published>2020-11-24T09:10:26.472Z</published>
    <updated>2020-12-01T08:14:09.351Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目标检测20年"><a href="#目标检测20年" class="headerlink" title="目标检测20年"></a>目标检测20年</h1><p>一：应用方向</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">instance segmentation</span><br><span class="line">image captioning</span><br><span class="line">object tracking</span><br><span class="line">such as autonomous driving, robot vision, video surveillance, etc. Fig</span><br></pre></td></tr></table></figure><p>二：研究方向</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">From the application point of view, object detection can be grouped into two research topics “general object detection&quot; and “detection applications”, where the former one aims to explore the methods of detecting different types of objects under a unified framework to simulate the human vision and cognition, and the later one refers to the detection under specific application scenarios, such as pedestrian detection, face detection, text detection, etc.</span><br></pre></td></tr></table></figure><p>三：阶段</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~-2012年：传统方式</span><br><span class="line">2012-~：深度学习阶段（分为one stage 与two stage）GPU技术美学</span><br></pre></td></tr></table></figure><p>四：速度优化</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">detection pipeline：cascaded detection, feature map shared computation</span><br><span class="line">detection backbone：network compression, lightweight network design</span><br><span class="line">numerical computation：integral image, vector quantization</span><br></pre></td></tr></table></figure><p>五：目标检测的困难和挑战</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">object rotation and scale changes </span><br><span class="line">accurate object localization</span><br><span class="line">dense and occluded object detection</span><br><span class="line">speed up of detection</span><br></pre></td></tr></table></figure><p>六：发展史</p><p>6.1：VJ detector（2001）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">特点：速度快</span><br><span class="line">技术：“integral image”，“feature selection”, and “detection cascades”</span><br><span class="line">主要用于人脸检测，这个方法在OpenCV中被实现为cvHaarDetectObjects()。</span><br></pre></td></tr></table></figure><p>6.2： HOG Detector（2005）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">特点：多尺度</span><br><span class="line">出发点用于行人检测</span><br></pre></td></tr></table></figure><p>6.3：DPM（ Deformable Part-based Model ）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">特点：For example, the problem of detecting a “car” can be considered as the detection of its window, body, and wheels. This part of the work, a.k.a. “star-model”, was completed by P. Felzenszwalb et al. </span><br><span class="line">技术： mixture models, hard negative mining, bounding box regression</span><br><span class="line">传统检测的最高点</span><br></pre></td></tr></table></figure><p>6.4：RCNN（Regions with CNN features 2014年）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RCNN原理：它首先通过选择性搜索[42]提取一组对象提案(对象候选框。 然后将每个建议重新缩放到一个固定大小的图像，并将其输入在Image Net(例如AlexNet[40]上训练的CNN模型，以提取特征。 最后，线性SVM分类器用于预测每个区域内存在一个对象，并识别对象类别</span><br><span class="line">特点：速度慢，尺度固定（224x224 image for AlexNet）。the redundant feature computations on a large number of overlapped proposals (over 2000 boxes from one image) leads to an extremely slow detection speed (14s per image with GPU).</span><br></pre></td></tr></table></figure><p>6.5：SPPNet</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">When using SPPNet for object detection, the feature maps can be computed from the entire image only once, and then fixed- length representations of arbitrary regions can be generated for training the detectors, which avoids repeatedly computing the convolutional features</span><br><span class="line">特点：SPPNet is more than 20 times faster than R-CNN without</span><br><span class="line">问题：first, the training is still multi-stage, second, SPPNet only fine-tunes its fully connected layers while simply ignores all previous layers.</span><br></pre></td></tr></table></figure><p>6.6：Fast RCNN（2015）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Fast RCNN increased the mAP from 58.5% (RCNN) to 70.0% while with a detection speed over 200 times faster than R-CNN.</span><br></pre></td></tr></table></figure><p>6.6：Faster RCNN（2015）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">第一个接近实时的深度学习检测器</span><br><span class="line">技术：Region Proposal Network(RPN)，proposal detection, feature extraction, bounding box regression, etc,</span><br></pre></td></tr></table></figure><p>6.7：Feature Pyramid Networks</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">特征金字塔，多尺度</span><br></pre></td></tr></table></figure><p>6.8：YOLO</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">特点：使用单层神经将整个图片划分为区域，并同时预测每个区域的边界框和概率</span><br><span class="line">问题：在检测小目标物体上定位不准确</span><br><span class="line">It was the first one-stage detector in deep learning era</span><br><span class="line">放弃了检验范式：proposal detection + verification</span><br></pre></td></tr></table></figure><p>6.9：Single Shot MultiBox Detector (SSD)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">The main contribution of SSD is the introduction of the multi-reference and multi-resolution detection techniques。</span><br><span class="line">It was the second one-stage detector in deep learning era</span><br></pre></td></tr></table></figure><p>6.10：RetinaNet</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">引入了focal loss</span><br></pre></td></tr></table></figure><p>七：数据集</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">•Pascal VOC</span><br><span class="line">•ILSVRC</span><br><span class="line">•MS-COCO</span><br><span class="line">•Open Images</span><br><span class="line"></span><br><span class="line">•Datasets of Other Detection Tasks：</span><br><span class="line">In addition to general object detection, the past 20 years also witness the prosperity of detection applications in specific areas, such as pedestrian detection, face detection, text detection, traffic sign/light detection, and remote sensing target detection. Tables 2-6 list some of the popular datasets of these detection tasks[ The #Cites shows statistics as of Feb. 2019.]. A detailed introduction of the detection methods of these tasks can be found in Section</span><br></pre></td></tr></table></figure><p>八：评判标准</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">早期为：漏检率和假阳性</span><br><span class="line">近期：近年来，最常用的目标检测评价是“平均精度(AP)”，最初是在VOC2007中引入的。 AP被定义为不同召回下的平均检测精度，通常以特定类别的方式进行评估。 为了比较所有对象类别的性能，通常使用所有对象类别上平均AP(MAP)作为性能的最终度量。 为了测量对象的定位精度，使用(IoU)检查预测框和地面真相框之间的IoU是否大于预定义的阈值，例如0.5。 如果是，对象将被标识为“成功检测到”，否则将被标识为“错过”。 基于0.5-IoU的mAP已经成为目标检测问题的事实度量多年。</span><br><span class="line">Map0.5-0.95被引入（IOU为0.5-0.95之间的精度）</span><br></pre></td></tr></table></figure><p>九：检测技术的演变</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Components, shapes and edges（before2000）：基于特征的，使得机器学习的兴起</span><br><span class="line">Early time&apos;s CNN for object detection（Y.LeCun）：全卷积网络的提出，相当于全连接层</span><br></pre></td></tr></table></figure><p>十：多尺度检测技术的演变</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">feature pyramids and sliding windows (before 2014)：</span><br><span class="line">可以解决长宽比固定的物体</span><br><span class="line">detection with object proposals (2010-2015)：</span><br><span class="line">deep regression (2013-2016)</span><br><span class="line">multi-reference detection (after 2015)</span><br><span class="line">multi-resolution detection (after 2016)</span><br></pre></td></tr></table></figure><p>十一：非极大值抑制技术的演变</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">贪婪的选择：</span><br><span class="line">贪婪选择是一种老式的，但最流行的方法来执行NMS在对象检测。 这个过程背后的思想是简单和直观的：对于一组重叠检测，选择具有最大检测分数的包围框，而其相邻框则根据预定义的重叠阈值（例如0.5)删除）。 上述处理是以贪婪的方式迭代执行的。（现在基本在使用此种方式）</span><br><span class="line">Bbox聚合：</span><br><span class="line">BB聚合是NMS[10,103,156,157]的另一组技术，其思想是将多个重叠包围盒组合或聚类成一个最终检测。 这种方法的优点是它充分考虑了对象关系及其空间布局。 有一些著名的检测器使用这种方法，如VJ检测器[10]和Overfeat[103]。</span><br><span class="line">Learning to NMS：</span><br></pre></td></tr></table></figure><p>十二：Technical Evolution of Hard Negative Mining</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">假设给你一堆包含一个或多个人物的图片，并且每一个人都给你一个bounding box做标记，如果要训练一个分类器去做分类的话，你的分类器需要既包含正训练样本（人）和负训练样本（背景）。</span><br><span class="line">你通过观察bounding box去创建一个有用的正训练样本，那么怎么做才能创建一个有用的负训练样本呢？</span><br><span class="line">一个很好的方式就是去在开始时随机创建一堆的bounding box候选框，并且不能与你的正样本有任何的重叠，把这些未与正样本重叠的新的bounding box作为你的负样本。</span><br><span class="line">好了，这样你的正负样本都有了，可以训练可以用的分类器了，你用滑动窗口在你的训练图片上进行运行，但是你会发现你的分类器并不是很好用，分类的效果并不是很好，因为它会抛出一堆的错误的正样本（当检测到人时实际上却并不是实际的人），这就问题来了，你训练了一个用于分类的分类器，然而这个分类器却并不能达到你想要的效果，那么应该怎么办呢？</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">使用滑动窗口的时候，出现的问题是：负样本/正样本的比例可能高达10^5以上，严重导致数据不平衡</span><br><span class="line"></span><br><span class="line">Bootstrap：</span><br><span class="line">当你得到错误的检测patch时，会明确的从这个patch中创建一个负样本，并把这个负样本添加到你的训练集中去。当你重新训练你的分类器后，分类器会表现的更好，并且不会像之前那样产生多的错误的正样本。</span><br><span class="line"></span><br><span class="line">HNM in deep learning based detectors：</span><br><span class="line">例如，在SSD[21]和OHEM[166]中，只有极小部分样本（损失值最大的样本）的梯度才会反向传播。 在细化细节[55]中，设计了一个“锚精化模块”来过滤容易的底片。 另一个改进是[23,169,170]设计新的损失函数，通过重塑标准的交叉熵损失，使其更多地关注硬的、错误分类的示例</span><br></pre></td></tr></table></figure><p>十三：检测速度</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">分为：“加快探测管道”、“加快探测引擎”和“加快数值计算”</span><br><span class="line">“speed up of detection pipeline”，“speed up of detection engine”，and “speed up of numerical computation”</span><br><span class="line"></span><br><span class="line">13.1Feature Map Shared Computation（特征图共享计算）</span><br><span class="line">13.2Speed up of Classifiers</span><br><span class="line">13.3Cascaded Detection</span><br><span class="line">13.4Network Pruning and Quantification and Network Distillation:</span><br><span class="line">网络蒸馏：使用大网络来训练小网络</span><br></pre></td></tr></table></figure><p>十四：主干网</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">AlexNet: AlexNet [40], an eight-layer deep network, was the first CNN model that started the deep learning revolution in computer vision. AlexNet famously won the 2012 ImageNet LSVRC-2012 competition by a large margin [15.3% VS 26.2% (second place) error rates]. As of Feb. 2019, the Alexnet paper has been cited over 30,000 times.</span><br><span class="line"></span><br><span class="line">VGG: VGG was proposed by Oxford&apos;s Visual Geometry Group (VGG) in 2014 [230]. VGG increased the model&apos;s depth to 16-19 layers and used very small (3x3) convolution filters instead of 5x5 and 7x7 those were previously used in AlexNet. VGG has achieved the state of the art performance on the ImageNet dataset of its time.</span><br><span class="line"></span><br><span class="line">GoogLeNet: GoogLeNet, a.k.a Inception [198, 231-233], is a big family of CNN models proposed by Google Inc. since 2014. GoogLeNet increased both of a CNN&apos;s width and depth (up to 22 layers). The main contribution of the Inception family is the introduction of factorizing convolution and batch normalization.</span><br><span class="line"></span><br><span class="line">ResNet: The Deep Residual Networks (ResNet) [234], proposed by K. He et al. in 2015, is a new type of convolutional network architecture that is substantially deeper (up to 152 layers) than those used previously. ResNet aims to ease the training of networks by reformulating its layers as learning residual functions with reference to the layer inputs. ResNet won multiple computer vision competitions in 2015, including ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.</span><br><span class="line"></span><br><span class="line">DenseNet: DenseNet [235] was proposed by G. Huang and Z. Liu et al. in 2017. The success of ResNet suggested that the short cut connection in CNN enables us to train deeper and more accurate models. The authors embraced this observation and introduced a densely connected block, which connects each layer to every other layer in a feedforward fashion.</span><br><span class="line"></span><br><span class="line">SENet: Squeeze and Excitation Networks (SENet) was proposed by J. Hu and L. Shen et al. in 2018 [236]. Its main contribution is the integration of global pooling and shuffling to learn channel-wise importance of the feature map. SENet won the 1st place in ILSVRC 2017 classification competition.</span><br><span class="line"></span><br><span class="line">• Object detectors with new engines</span><br><span class="line">In recent three years, many of the latest engines have been applied to object detection. For example, some latest object detection models such as STDN [237], DSOD [238], TinyDSOD [207], and Pelee [209] choose DenseNet [235] as their detection engine. The Mask RCNN [4], as the state of the art model for instance segmentation, applied the next generation of ResNet: ResNeXt [239] as its detection engine. Besides, to speed up detection, the depth-wise separable convolution operation, which was introduced by Xception [204], an improved version of Incepion, has also been used in detectors such as MobileNet [205] and LightHead RCNN [47].</span><br></pre></td></tr></table></figure><p>十五：特征</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.Feature Fusion特征融合</span><br><span class="line">Invariance and equivariance are two important properties in image feature representations</span><br><span class="line">①不变性和等变性（分类过程需要不变性，定位过程需要等变性）</span><br><span class="line">②卷积层越深，特征的不变性越强，但是等变性较差；有利于目标识别</span><br><span class="line">③卷积层越浅，特征的等变性较好，轮廓等特征易于学习</span><br><span class="line">④综上，特征融合很重要</span><br><span class="line"></span><br><span class="line">2.learning high-resolution features with large receptive fields学习具有大接收场的高分辨率特征。</span><br></pre></td></tr></table></figure><p>十六：定位方式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.Sliding Window</span><br><span class="line">2.Detection as sub-region search</span><br><span class="line">3.Detection as key points localization</span><br></pre></td></tr></table></figure><p>十七：提高定位准确度</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.Bounding Box Refinement</span><br><span class="line">2.Improving Loss Functions forAccurate Localization</span><br></pre></td></tr></table></figure><p>十八：语义分割semantic segmentation</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.Segmentation helps category recognition</span><br><span class="line">2.Segmentation helps accurate localization</span><br><span class="line">3.Segmentation can be embedded as context（飞机可能在天上，而不是在水中）</span><br></pre></td></tr></table></figure><p>十九：旋转和尺度改变的鲁棒性检测</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.旋转鲁棒性检测</span><br><span class="line">•Rotation invariant loss functions</span><br><span class="line">•Rotation calibration</span><br><span class="line">•Rotation Rol Pooling</span><br><span class="line">2.尺度鲁棒性检测</span><br><span class="line">•Scale adaptive training</span><br><span class="line">•Scale adaptive detection</span><br></pre></td></tr></table></figure><p>二十：应用</p><p>1.Pedestrian Detection行人检测</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.挑战：</span><br><span class="line">①小像素（远处相机）</span><br><span class="line">②困难负样本（类似的物体）</span><br><span class="line">③遮挡的行人</span><br><span class="line">④实时检测</span><br><span class="line"></span><br><span class="line">2.发展历史</span><br><span class="line">①传统方式：haar</span><br><span class="line">②深度学习：fast-Rcnn</span><br></pre></td></tr></table></figure><p>2.Face Detection脸部检测</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.挑战</span><br><span class="line">①Intra-class variation人脸形变</span><br><span class="line">②遮挡</span><br><span class="line">③Multi-scale detection</span><br><span class="line">④实时检测</span><br></pre></td></tr></table></figure><p>3.Text Detection文本检测</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.挑战</span><br><span class="line">Different fonts and languages</span><br><span class="line">Text rotation and perspective distortion</span><br><span class="line">Densely arranged text localization</span><br><span class="line">Broken and blurred characters</span><br></pre></td></tr></table></figure><p>4.Traffic Sign and Traffic Light Detection交通标志和交通灯检测（自动驾驶）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.挑战</span><br><span class="line">照明变换</span><br><span class="line">运动模糊</span><br><span class="line">雨雪天气</span><br><span class="line">实时检测</span><br></pre></td></tr></table></figure><p>5.Remote Sensing Target Detection遥感目标检测</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.大数据检测</span><br><span class="line">2.遮挡（云层）</span><br><span class="line">3.不同遥感分辨率差异</span><br></pre></td></tr></table></figure><p>二十一：未来发展</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.轻量级网络</span><br><span class="line">2.自动化ML</span><br><span class="line">3.自适应环境</span><br><span class="line">4.弱监督检测</span><br><span class="line">5.小目标检测</span><br><span class="line">6.视频中检测</span><br><span class="line">7.检测与信息融合</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;目标检测20年&quot;&gt;&lt;a href=&quot;#目标检测20年&quot; class=&quot;headerlink&quot; title=&quot;目标检测20年&quot;&gt;&lt;/a&gt;目标检测20年&lt;/h1&gt;&lt;p&gt;一：应用方向&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>数据采集流程（全）</title>
    <link href="https://yanyubing.xyz/2020/11/24/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E6%B5%81%E7%A8%8B%EF%BC%88%E5%85%A8%EF%BC%89/"/>
    <id>https://yanyubing.xyz/2020/11/24/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E6%B5%81%E7%A8%8B%EF%BC%88%E5%85%A8%EF%BC%89/</id>
    <published>2020-11-24T05:42:59.863Z</published>
    <updated>2020-11-24T07:46:53.521Z</updated>
    
    <content type="html"><![CDATA[<p><strong><em>\</em>数据采集工作流程解决方案（全）**</strong></p><p><strong>1.</strong> <strong><em>\</em>硬件准备**</strong></p><p>①工业主机：</p><p>参数：主机 Intel双核-j1800         8G内存  64G固态硬盘</p><p>链接：<a href="https://item.jd.com/63906155297.html" target="_blank" rel="noopener">https://item.jd.com/63906155297.html</a></p><p>②U盘：</p><p>Ubuntu20.04lts启动盘</p><p>③网络摄像头</p><p>④虚拟显卡</p><p>链接：<a href="https://item.jd.com/100006564772.html" target="_blank" rel="noopener">https://item.jd.com/100006564772.html</a></p><p><strong>2.</strong> <strong><em>\</em>流程**</strong></p><p>①工业主机系统重装</p><p>②安装向日葵，设置开机自启动</p><p>安装依赖包需参考：</p><p><a href="https://zhuanlan.zhihu.com/p/144426017" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/144426017</a></p><p>③安装pycharm和conda（如果对环境熟悉，可以选择不安装，建议安装便于程序的调试）</p><p>④代码拷贝（包含储存检测的代码和触发器传输文件代码）</p><p>⑤环境准备：</p><p>在pycharm中创建conda环境</p><p><a href="https://blog.csdn.net/weixin_30486037/article/details/97982277" target="_blank" rel="noopener">https://blog.csdn.net/weixin_30486037/article/details/97982277</a></p><p>清华源安装opencv</p><p>安装转码包ffmpeg：</p><p>最优方式参考<a href="https://blog.csdn.net/lwgkzl/article/details/77836207" target="_blank" rel="noopener">https://blog.csdn.net/lwgkzl/article/details/77836207</a></p><p><strong>3.</strong> <strong><em>\</em>需要调整的地方**</strong></p><p>网络摄像头：</p><p>①设置好网络摄像头参数为720p，10fps，设置时间水印为黄色</p><p>②记录网络摄像头ip</p><p>③设置网络摄像头账号和密码为yan  a18171458196</p><p>④调整网络摄像头的可视范围</p><p>代码：</p><p>①保存视频的时长，设置保存对象的box大小和比例，设置视频大小的阈值（每个场景都会有差异）</p><p>②保存视频以区域名前缀+时间构成</p><p>（例如：汉阳区政府区域</p><p>hyqzf_202011111110）</p><p><strong>4.</strong> <strong><em>\</em>最后**</strong></p><p>采集通道完成之后，观察上传的视频存在的问题，进行调整；最终达到该上传的就上传，不该上传的就不上传的平衡。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;&lt;em&gt;\&lt;/em&gt;数据采集工作流程解决方案（全）**&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;\&lt;/em&gt;硬件准备**&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;①工业主机：&lt;/p&gt;
&lt;p&gt;参数：主机 Inte
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>关于制作视频抽帧数据集这件事</title>
    <link href="https://yanyubing.xyz/2020/11/21/%E5%85%B3%E4%BA%8E%E5%88%B6%E4%BD%9C%E8%A7%86%E9%A2%91%E6%8A%BD%E5%B8%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BF%99%E4%BB%B6%E4%BA%8B/"/>
    <id>https://yanyubing.xyz/2020/11/21/%E5%85%B3%E4%BA%8E%E5%88%B6%E4%BD%9C%E8%A7%86%E9%A2%91%E6%8A%BD%E5%B8%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BF%99%E4%BB%B6%E4%BA%8B/</id>
    <published>2020-11-21T07:10:14.506Z</published>
    <updated>2020-11-23T02:13:53.829Z</updated>
    
    <content type="html"><![CDATA[<h1 id="关于制作视频抽帧数据集这件事"><a href="#关于制作视频抽帧数据集这件事" class="headerlink" title="关于制作视频抽帧数据集这件事"></a>关于制作视频抽帧数据集这件事</h1><p>一：制作视频数据集的原则</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.减少相同样本重复性（避免过拟合）</span><br><span class="line">2.能快速过滤到自己要的图片数据</span><br></pre></td></tr></table></figure><p>二：技巧与问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.如果目标类别在已有的预训练模型中有，并且业务逻辑也是伴随着目标类别来做的，那么可以使用预训练模型检测作为提取的第一步（这里conf阈值可以调高，更好的定位目标图片）</span><br><span class="line"></span><br><span class="line">2.问题：抽取的第一步会出现连续多帧都会被采集到，如何过滤？</span><br><span class="line">方案①：将提取比例作为超参数，随机提取此比例的图片</span><br><span class="line">方案②：间隔n张提取一张（适用于类别稳定出现的情况）</span><br><span class="line"></span><br><span class="line">3.问题：本人遇到的情形是，目标类别一般会均匀出现（3s出现一次，一次被抽取的第一步抽取到一张），但是偶尔会有特例出现（一次被抽取的第一步提取到100张）？</span><br><span class="line">使用上述方案①和方案②都不合适，会过多的采用同样的图片，或者有很多样本没有采用；</span><br><span class="line">解决方案为：视频流中有时间戳，通过时间戳的间隔来过滤（获取时间戳，保存得到连续时间戳的中位数图片，前后的图片对象都是刚出现或者已经消失，对象不全）</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;关于制作视频抽帧数据集这件事&quot;&gt;&lt;a href=&quot;#关于制作视频抽帧数据集这件事&quot; class=&quot;headerlink&quot; title=&quot;关于制作视频抽帧数据集这件事&quot;&gt;&lt;/a&gt;关于制作视频抽帧数据集这件事&lt;/h1&gt;&lt;p&gt;一：制作视频数据集的原则&lt;/p&gt;
&lt;figu
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>10-目标跟踪</title>
    <link href="https://yanyubing.xyz/2020/11/17/10-%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/"/>
    <id>https://yanyubing.xyz/2020/11/17/10-%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/</id>
    <published>2020-11-17T08:08:39.273Z</published>
    <updated>2020-11-17T08:08:39.273Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>09-场景文字识别</title>
    <link href="https://yanyubing.xyz/2020/11/17/09-%E5%9C%BA%E6%99%AF%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB/"/>
    <id>https://yanyubing.xyz/2020/11/17/09-%E5%9C%BA%E6%99%AF%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB/</id>
    <published>2020-11-17T08:08:24.208Z</published>
    <updated>2020-11-17T08:08:24.208Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>08-人体关键点检测</title>
    <link href="https://yanyubing.xyz/2020/11/17/08-%E4%BA%BA%E4%BD%93%E5%85%B3%E9%94%AE%E7%82%B9%E6%A3%80%E6%B5%8B/"/>
    <id>https://yanyubing.xyz/2020/11/17/08-%E4%BA%BA%E4%BD%93%E5%85%B3%E9%94%AE%E7%82%B9%E6%A3%80%E6%B5%8B/</id>
    <published>2020-11-17T08:08:11.615Z</published>
    <updated>2020-11-17T08:08:11.615Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>07-视频分类</title>
    <link href="https://yanyubing.xyz/2020/11/17/07-%E8%A7%86%E9%A2%91%E5%88%86%E7%B1%BB/"/>
    <id>https://yanyubing.xyz/2020/11/17/07-%E8%A7%86%E9%A2%91%E5%88%86%E7%B1%BB/</id>
    <published>2020-11-17T08:07:59.237Z</published>
    <updated>2020-11-17T08:07:59.237Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
</feed>
