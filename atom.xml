<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>鄢玉兵的博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://yanyubing.xyz/"/>
  <updated>2021-01-09T05:59:22.360Z</updated>
  <id>https://yanyubing.xyz/</id>
  
  <author>
    <name>鄢玉兵</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>opencv实战20</title>
    <link href="https://yanyubing.xyz/2021/01/09/opencv%E5%AE%9E%E6%88%9820/"/>
    <id>https://yanyubing.xyz/2021/01/09/opencv%E5%AE%9E%E6%88%9820/</id>
    <published>2021-01-09T03:45:40.011Z</published>
    <updated>2021-01-09T05:59:22.360Z</updated>
    
    <content type="html"><![CDATA[<h1 id="opencv实战20讲"><a href="#opencv实战20讲" class="headerlink" title="opencv实战20讲"></a>opencv实战20讲</h1><p>一：颜色分割</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 颜色分割</span><br><span class="line"></span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line"># 1.读取图片</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">image = cv2.imread(&apos;bird.jpg&apos;)</span><br><span class="line"># 2.滤波操作，减少图片中的细微差异</span><br><span class="line">blur2 = cv2.bilateralFilter(image, 9, 75, 75)</span><br><span class="line"># 3.bgr转换为hsv，因为HSV空间中，三者相对独立，可以准确描述像素的亮度，饱和度和色度</span><br><span class="line">hsv = cv2.cvtColor(blur2, cv2.COLOR_BGR2HSV)</span><br><span class="line"># 4.查找范围</span><br><span class="line">low_blue = np.array([55, 0, 0])</span><br><span class="line">high_blue = np.array([118, 255, 255])</span><br><span class="line"># 5.mask</span><br><span class="line">mask = cv2.inRange(hsv, low_blue, high_blue)</span><br><span class="line"># 6.提取最终图片</span><br><span class="line">res = cv2.bitwise_and(image, image, mask=mask)</span><br><span class="line">cv2.imshow(&apos;image.jpg&apos;, res)</span><br><span class="line">cv2.waitKey(0)</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;opencv实战20讲&quot;&gt;&lt;a href=&quot;#opencv实战20讲&quot; class=&quot;headerlink&quot; title=&quot;opencv实战20讲&quot;&gt;&lt;/a&gt;opencv实战20讲&lt;/h1&gt;&lt;p&gt;一：颜色分割&lt;/p&gt;
&lt;figure class=&quot;highligh
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>greedAi</title>
    <link href="https://yanyubing.xyz/2021/01/06/greedAi/"/>
    <id>https://yanyubing.xyz/2021/01/06/greedAi/</id>
    <published>2021-01-06T02:08:38.611Z</published>
    <updated>2021-01-06T04:25:31.802Z</updated>
    
    <content type="html"><![CDATA[<h3 id="贪心学院代码"><a href="#贪心学院代码" class="headerlink" title="贪心学院代码"></a>贪心学院代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#https://www.youtube.com/playlist?list=PLt2F7ir0KONp5cx8qXWUz18eSDZP1erGr</span><br></pre></td></tr></table></figure><p>demo15</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># 线性回归,逻辑回归</span><br><span class="line">from sklearn import linear_model</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 创建逻辑回归模型</span><br><span class="line">reg = linear_model.LogisticRegression()</span><br><span class="line"># 创建线性回归模型</span><br><span class="line">leg = linear_model.LinearRegression()</span><br><span class="line"></span><br><span class="line">x1 = [20, 23, 31, 42, 50, 60]</span><br><span class="line">x2 = [3, 7, 10, 13, 7, 5]</span><br><span class="line">y = np.array([0, 1, 1, 1, 0, 0])</span><br><span class="line"># 创建x</span><br><span class="line">x = np.array([[x1[index], x2[index]] for index in range(len(x1))])</span><br><span class="line">print(x)</span><br><span class="line"># 训练</span><br><span class="line">reg.fit(x, y)</span><br><span class="line">leg.fit(x, y)</span><br><span class="line"># 预测</span><br><span class="line">res1 = reg.predict(np.array([[28, 8]]))</span><br><span class="line"># 概率</span><br><span class="line">res1_1 = reg.predict_proba(np.array([[28, 8]]))</span><br><span class="line"></span><br><span class="line">res2 = leg.predict(np.array([[28, 8]]))</span><br><span class="line">print(res1)</span><br><span class="line">print(res1_1)</span><br><span class="line"></span><br><span class="line">print(res2)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;贪心学院代码&quot;&gt;&lt;a href=&quot;#贪心学院代码&quot; class=&quot;headerlink&quot; title=&quot;贪心学院代码&quot;&gt;&lt;/a&gt;贪心学院代码&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gut
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>学习</title>
    <link href="https://yanyubing.xyz/2020/12/25/%E5%AD%A6%E4%B9%A0/"/>
    <id>https://yanyubing.xyz/2020/12/25/%E5%AD%A6%E4%B9%A0/</id>
    <published>2020-12-25T06:14:55.394Z</published>
    <updated>2021-01-06T02:08:24.781Z</updated>
    
    <content type="html"><![CDATA[<p>学习路线</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">course课程：</span><br><span class="line">1.Neural Networks and Deep Learning</span><br><span class="line"></span><br><span class="line">2.Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization</span><br><span class="line"></span><br><span class="line">3.Convolutional Neural Networks</span><br><span class="line"></span><br><span class="line">4.AI for everyone</span><br><span class="line"></span><br><span class="line">5.Machine Learning</span><br><span class="line"></span><br><span class="line">斯坦福大学公开课：</span><br><span class="line">https://www.youtube.com/watch?v=vT1JzLTH4G4&amp;list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv</span><br><span class="line"></span><br><span class="line">贪心学员：</span><br><span class="line">计算机视觉：</span><br><span class="line">https://www.youtube.com/watch?v=gyR_2KxFXC0&amp;list=PLt2F7ir0KONp5cx8qXWUz18eSDZP1erGr&amp;index=1</span><br><span class="line">NLP：</span><br><span class="line">https://www.youtube.com/watch?v=1dQnPCKMaCY&amp;list=PLt2F7ir0KONoH2HXXlKpBSmUKkokOgOvr</span><br><span class="line"></span><br><span class="line">微软：</span><br><span class="line">https://www.youtube.com/playlist?list=PLlrxD0HtieHhS8VzuMCfQD4uJ9yne1mE6</span><br><span class="line">https://github.com/microsoft/c9-python-getting-started</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;学习路线&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>疑虑汇总</title>
    <link href="https://yanyubing.xyz/2020/12/14/%E7%96%91%E8%99%91%E6%B1%87%E6%80%BB/"/>
    <id>https://yanyubing.xyz/2020/12/14/%E7%96%91%E8%99%91%E6%B1%87%E6%80%BB/</id>
    <published>2020-12-14T07:34:04.311Z</published>
    <updated>2020-12-14T07:49:46.187Z</updated>
    
    <content type="html"><![CDATA[<h1 id="疑虑汇总"><a href="#疑虑汇总" class="headerlink" title="疑虑汇总"></a>疑虑汇总</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">一：抽帧的时候一秒内多次抽帧采样是否会造成过拟合</span><br><span class="line">答：是</span><br><span class="line"></span><br><span class="line">二：如果确定事件的发生基于一定的前提，例如：需要判断人是否在丢垃圾，只需要获取人的正面图片作为人的样本标签（因为人只有正面的时候才会产生我们所需要的识别的业务），只标注正面的人是否可行？</span><br><span class="line">答：可行，只是同时需要增加人体其他状态的类别</span><br><span class="line"></span><br><span class="line">三：对于使用Box位置关系来判断人行为是否发生的情况，可能二维上相交，但是三维上不想交，例如人是否佩戴安全帽？</span><br><span class="line">答：还未得到理想答案</span><br><span class="line"></span><br><span class="line">四：相交的关系会影响到物体的完整类别（例如人佩戴安全帽，如果类别分开则需要人脑，安全帽两个类别，但是佩戴了安全帽的人脑会显示不全），是采用多个物体的形式还是整体作为一个状态（或者把佩戴了安全帽的人作为一个类别）？</span><br><span class="line">答：应该根据实际业务来看，此种形式（人佩戴了安全帽）还是保留了人和安全帽的部分特征，那么作为一个类别也可行；但是某种情况下会被完全遮挡的时候作为一个类别就不可行，例如人手拿某个物体的时候。</span><br><span class="line"></span><br><span class="line">五：对于不同角度的固定摄像头(a,b)采集的视频，使用一个模型训练和应用还是每个摄像头的视频使用一个模型？如果是一个视频，那么a,b采集的数据的比例是否要保持1:1左右。</span><br><span class="line">答：还未得到理想答案</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;疑虑汇总&quot;&gt;&lt;a href=&quot;#疑虑汇总&quot; class=&quot;headerlink&quot; title=&quot;疑虑汇总&quot;&gt;&lt;/a&gt;疑虑汇总&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pr
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>论文解读hog-cvpr2005</title>
    <link href="https://yanyubing.xyz/2020/12/02/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BBhog-cvpr2005/"/>
    <id>https://yanyubing.xyz/2020/12/02/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BBhog-cvpr2005/</id>
    <published>2020-12-02T06:58:34.002Z</published>
    <updated>2020-12-02T07:40:57.609Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Histograms-of-Oriented-Gradients-for-Human-Detection"><a href="#Histograms-of-Oriented-Gradients-for-Human-Detection" class="headerlink" title="Histograms of Oriented Gradients for Human Detection"></a><strong>Histograms of Oriented Gradients for Human Detection</strong></h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">思想：在一副图像中，局部目标的表象和形状（appearance and shape）能够被梯度或边缘的方向密度分布很好地描述。（本质：梯度的统计信息，而梯度主要存在于边缘的地方）。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">给我的感觉是HOG+SVM适用于分类，并不适用于定位（对于尺度变化很大的目标），主要原因是HOG特征的维度是固定的</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">提取Hog特征的过程：</span><br><span class="line">1.灰度化</span><br><span class="line">2.Gamma校正</span><br><span class="line">3.计算图像每个像素的梯度（包括大小和方向，梯度的大小即为梯度值）；主要是为了捕获轮廓信息，同时进一步弱化光照的干扰。</span><br><span class="line">4.将图像划分成小cells（例如6*6像素/cell）</span><br><span class="line">5.统计每个cell的梯度直方图（不同梯度的个数）</span><br><span class="line">6.将每几个cell组成一个block（例如3*3个cell/block），一个block内所有cell的特征descriptor串联起来便得到该block的HOG特征descriptor</span><br><span class="line">7.将图像image内的所有block的HOG特征descriptor串联起来就可以得到该image（你要检测的目标）的HOG特征descriptor了。这个就是最终的可供分类使用的特征向量了。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">总结：Dalal提出的Hog特征提取的过程：把样本图像分割为若干个像素的单元（cell），把梯度方向平均划分为9个区间（bin），在每个单元里面对所有像素的梯度方向在各个方向区间进行直方图统计，得到一个9维的特征向量，每相邻的4个单元构成一个块（block），把一个块内的特征向量联起来得到36维的特征向量，用块对样本图像进行扫描，扫描步长为一个单元。最后将所有块的特征串联起来，就得到了人体的特征。例如，对于64*128的图像而言，每8*8的像素组成一个cell，每2*2个cell组成一个块，因为每个cell有9个特征，所以每个块内有4*9=36个特征，以8个像素为步长，那么，水平方向将有7个扫描窗口，垂直方向将有15个扫描窗口。也就是说，64*128的图片，总共有36*7*15=3780个特征。</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Histograms-of-Oriented-Gradients-for-Human-Detection&quot;&gt;&lt;a href=&quot;#Histograms-of-Oriented-Gradients-for-Human-Detection&quot; class=&quot;headerl
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>python高级</title>
    <link href="https://yanyubing.xyz/2020/12/02/python%E9%AB%98%E7%BA%A7/"/>
    <id>https://yanyubing.xyz/2020/12/02/python%E9%AB%98%E7%BA%A7/</id>
    <published>2020-12-02T02:36:46.602Z</published>
    <updated>2020-12-02T03:30:29.087Z</updated>
    
    <content type="html"><![CDATA[<h1 id="python高级用法"><a href="#python高级用法" class="headerlink" title="python高级用法"></a>python高级用法</h1><p>一：数据库中的name age对，需要建立连接，把age赋值给name变量；如zs=18；可以解决造变量的问题（一般情况下尽量不使用，会造成变量过多，必须要多个变量的时候使用）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 获取数据库中年龄赋值给姓名变量</span><br><span class="line">a = &apos;zhangsan&apos;</span><br><span class="line">globals()[a] = &apos;18&apos;</span><br><span class="line">print(zhangsan)</span><br></pre></td></tr></table></figure><p>二：字典求交集并集</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 字典的操作</span><br><span class="line">d1 = dict(a=1, b=2)</span><br><span class="line">d2 = dict(b=2, c=3)</span><br><span class="line">v1 = d1.items()</span><br><span class="line">v2 = d2.items()</span><br><span class="line">print(type(v1 &amp; v2))#返回的set集合</span><br><span class="line">print(dict(v1 | v2))</span><br></pre></td></tr></table></figure><p>三：模块itertools</p><p>四：模块collections</p><p>五：模块operator</p><p>六：模块functools</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;python高级用法&quot;&gt;&lt;a href=&quot;#python高级用法&quot; class=&quot;headerlink&quot; title=&quot;python高级用法&quot;&gt;&lt;/a&gt;python高级用法&lt;/h1&gt;&lt;p&gt;一：数据库中的name age对，需要建立连接，把age赋值给name变量；
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>论文解读viola-cvpr</title>
    <link href="https://yanyubing.xyz/2020/12/01/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BBviola-cvpr/"/>
    <id>https://yanyubing.xyz/2020/12/01/%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BBviola-cvpr/</id>
    <published>2020-12-01T08:31:37.236Z</published>
    <updated>2020-12-02T06:40:54.747Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Rapid-Object-Detection-using-a-Boosted-Cascade-of-Simple-Features"><a href="#Rapid-Object-Detection-using-a-Boosted-Cascade-of-Simple-Features" class="headerlink" title="*Rapid Object Detection using a Boosted Cascade of Simple *Features"></a>*<em>Rapid Object Detection using a Boosted Cascade of Simple *</em>Features</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">论文描述：使用boosted进行简单特征的级联达到快速的目标检测</span><br><span class="line">①使用了积分图的方式描述图片，更加快速的计算</span><br><span class="line">②使用了AdaBoost，从大量特征中选取少量特征</span><br><span class="line">③使用了级联结构：快速剔除背景区域，把算力用在目标区域上（focus-of-attention）</span><br></pre></td></tr></table></figure><p>1.环境条件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">图片像素大小：384*288像素，灰度图</span><br><span class="line">检测器大小：24*24像素</span><br><span class="line">应用于人脸检测的框架</span><br></pre></td></tr></table></figure><p>2.技术特点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">①Integral Image</span><br><span class="line">②AdaBoost cascade（有点像决策树）</span><br><span class="line">③Haar特征</span><br></pre></td></tr></table></figure><p>3.工作流程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">灰度图像计算积分图，利用积分图可以快速计算haar-like特征（一个正放的矩形区域只需要4次积分图上点的值，使得每个窗口的计算复杂度和窗口大小无关）</span><br><span class="line">训练AdaBoost cascade：从180k特征池中选择一组最有利于人脸检测的小特征</span><br><span class="line">每个sub_windows进行级联判断（可以快速舍去背景区域）</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Rapid-Object-Detection-using-a-Boosted-Cascade-of-Simple-Features&quot;&gt;&lt;a href=&quot;#Rapid-Object-Detection-using-a-Boosted-Cascade-of-Simpl
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>track</title>
    <link href="https://yanyubing.xyz/2020/11/27/track/"/>
    <id>https://yanyubing.xyz/2020/11/27/track/</id>
    <published>2020-11-27T08:35:44.977Z</published>
    <updated>2020-12-18T09:16:53.622Z</updated>
    
    <content type="html"><![CDATA[<h1 id="cv-track"><a href="#cv-track" class="headerlink" title="cv-track"></a>cv-track</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">1.box大小限制</span><br><span class="line">2.conf值的限定</span><br><span class="line">3.误识别的反喂https://www.pythonf.cn/read/70211；误识别的根本原因就是训练数据不够，对于hard negative的采样不全</span><br><span class="line">4.如果要识别人的正面，一定要标注人的侧面作为另一个类别</span><br><span class="line">5.视频流中对类别的位置判断，一般而言会同时出现多帧，如果只出现一帧，则很可能是识别错误，排除掉</span><br><span class="line">6.不要显示的使用for循环，可以使用向量化的时候使用numpy向量化；或者使用内建函数完成，有SIMD单元（优化）</span><br><span class="line">7.日志中不要打印时间的时候要看着时间的打印频率！文件大小爆掉</span><br><span class="line">8.提醒方式有，HTML界面监控，邮件提醒，短信提醒（紧急最优）</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;cv-track&quot;&gt;&lt;a href=&quot;#cv-track&quot; class=&quot;headerlink&quot; title=&quot;cv-track&quot;&gt;&lt;/a&gt;cv-track&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td cl
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>目标检测20年</title>
    <link href="https://yanyubing.xyz/2020/11/24/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B20%E5%B9%B4/"/>
    <id>https://yanyubing.xyz/2020/11/24/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B20%E5%B9%B4/</id>
    <published>2020-11-24T09:10:26.472Z</published>
    <updated>2020-12-01T08:14:09.351Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目标检测20年"><a href="#目标检测20年" class="headerlink" title="目标检测20年"></a>目标检测20年</h1><p>一：应用方向</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">instance segmentation</span><br><span class="line">image captioning</span><br><span class="line">object tracking</span><br><span class="line">such as autonomous driving, robot vision, video surveillance, etc. Fig</span><br></pre></td></tr></table></figure><p>二：研究方向</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">From the application point of view, object detection can be grouped into two research topics “general object detection&quot; and “detection applications”, where the former one aims to explore the methods of detecting different types of objects under a unified framework to simulate the human vision and cognition, and the later one refers to the detection under specific application scenarios, such as pedestrian detection, face detection, text detection, etc.</span><br></pre></td></tr></table></figure><p>三：阶段</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~-2012年：传统方式</span><br><span class="line">2012-~：深度学习阶段（分为one stage 与two stage）GPU技术美学</span><br></pre></td></tr></table></figure><p>四：速度优化</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">detection pipeline：cascaded detection, feature map shared computation</span><br><span class="line">detection backbone：network compression, lightweight network design</span><br><span class="line">numerical computation：integral image, vector quantization</span><br></pre></td></tr></table></figure><p>五：目标检测的困难和挑战</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">object rotation and scale changes </span><br><span class="line">accurate object localization</span><br><span class="line">dense and occluded object detection</span><br><span class="line">speed up of detection</span><br></pre></td></tr></table></figure><p>六：发展史</p><p>6.1：VJ detector（2001）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">特点：速度快</span><br><span class="line">技术：“integral image”，“feature selection”, and “detection cascades”</span><br><span class="line">主要用于人脸检测，这个方法在OpenCV中被实现为cvHaarDetectObjects()。</span><br></pre></td></tr></table></figure><p>6.2： HOG Detector（2005）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">特点：多尺度</span><br><span class="line">出发点用于行人检测</span><br></pre></td></tr></table></figure><p>6.3：DPM（ Deformable Part-based Model ）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">特点：For example, the problem of detecting a “car” can be considered as the detection of its window, body, and wheels. This part of the work, a.k.a. “star-model”, was completed by P. Felzenszwalb et al. </span><br><span class="line">技术： mixture models, hard negative mining, bounding box regression</span><br><span class="line">传统检测的最高点</span><br></pre></td></tr></table></figure><p>6.4：RCNN（Regions with CNN features 2014年）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RCNN原理：它首先通过选择性搜索[42]提取一组对象提案(对象候选框。 然后将每个建议重新缩放到一个固定大小的图像，并将其输入在Image Net(例如AlexNet[40]上训练的CNN模型，以提取特征。 最后，线性SVM分类器用于预测每个区域内存在一个对象，并识别对象类别</span><br><span class="line">特点：速度慢，尺度固定（224x224 image for AlexNet）。the redundant feature computations on a large number of overlapped proposals (over 2000 boxes from one image) leads to an extremely slow detection speed (14s per image with GPU).</span><br></pre></td></tr></table></figure><p>6.5：SPPNet</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">When using SPPNet for object detection, the feature maps can be computed from the entire image only once, and then fixed- length representations of arbitrary regions can be generated for training the detectors, which avoids repeatedly computing the convolutional features</span><br><span class="line">特点：SPPNet is more than 20 times faster than R-CNN without</span><br><span class="line">问题：first, the training is still multi-stage, second, SPPNet only fine-tunes its fully connected layers while simply ignores all previous layers.</span><br></pre></td></tr></table></figure><p>6.6：Fast RCNN（2015）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Fast RCNN increased the mAP from 58.5% (RCNN) to 70.0% while with a detection speed over 200 times faster than R-CNN.</span><br></pre></td></tr></table></figure><p>6.6：Faster RCNN（2015）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">第一个接近实时的深度学习检测器</span><br><span class="line">技术：Region Proposal Network(RPN)，proposal detection, feature extraction, bounding box regression, etc,</span><br></pre></td></tr></table></figure><p>6.7：Feature Pyramid Networks</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">特征金字塔，多尺度</span><br></pre></td></tr></table></figure><p>6.8：YOLO</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">特点：使用单层神经将整个图片划分为区域，并同时预测每个区域的边界框和概率</span><br><span class="line">问题：在检测小目标物体上定位不准确</span><br><span class="line">It was the first one-stage detector in deep learning era</span><br><span class="line">放弃了检验范式：proposal detection + verification</span><br></pre></td></tr></table></figure><p>6.9：Single Shot MultiBox Detector (SSD)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">The main contribution of SSD is the introduction of the multi-reference and multi-resolution detection techniques。</span><br><span class="line">It was the second one-stage detector in deep learning era</span><br></pre></td></tr></table></figure><p>6.10：RetinaNet</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">引入了focal loss</span><br></pre></td></tr></table></figure><p>七：数据集</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">•Pascal VOC</span><br><span class="line">•ILSVRC</span><br><span class="line">•MS-COCO</span><br><span class="line">•Open Images</span><br><span class="line"></span><br><span class="line">•Datasets of Other Detection Tasks：</span><br><span class="line">In addition to general object detection, the past 20 years also witness the prosperity of detection applications in specific areas, such as pedestrian detection, face detection, text detection, traffic sign/light detection, and remote sensing target detection. Tables 2-6 list some of the popular datasets of these detection tasks[ The #Cites shows statistics as of Feb. 2019.]. A detailed introduction of the detection methods of these tasks can be found in Section</span><br></pre></td></tr></table></figure><p>八：评判标准</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">早期为：漏检率和假阳性</span><br><span class="line">近期：近年来，最常用的目标检测评价是“平均精度(AP)”，最初是在VOC2007中引入的。 AP被定义为不同召回下的平均检测精度，通常以特定类别的方式进行评估。 为了比较所有对象类别的性能，通常使用所有对象类别上平均AP(MAP)作为性能的最终度量。 为了测量对象的定位精度，使用(IoU)检查预测框和地面真相框之间的IoU是否大于预定义的阈值，例如0.5。 如果是，对象将被标识为“成功检测到”，否则将被标识为“错过”。 基于0.5-IoU的mAP已经成为目标检测问题的事实度量多年。</span><br><span class="line">Map0.5-0.95被引入（IOU为0.5-0.95之间的精度）</span><br></pre></td></tr></table></figure><p>九：检测技术的演变</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Components, shapes and edges（before2000）：基于特征的，使得机器学习的兴起</span><br><span class="line">Early time&apos;s CNN for object detection（Y.LeCun）：全卷积网络的提出，相当于全连接层</span><br></pre></td></tr></table></figure><p>十：多尺度检测技术的演变</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">feature pyramids and sliding windows (before 2014)：</span><br><span class="line">可以解决长宽比固定的物体</span><br><span class="line">detection with object proposals (2010-2015)：</span><br><span class="line">deep regression (2013-2016)</span><br><span class="line">multi-reference detection (after 2015)</span><br><span class="line">multi-resolution detection (after 2016)</span><br></pre></td></tr></table></figure><p>十一：非极大值抑制技术的演变</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">贪婪的选择：</span><br><span class="line">贪婪选择是一种老式的，但最流行的方法来执行NMS在对象检测。 这个过程背后的思想是简单和直观的：对于一组重叠检测，选择具有最大检测分数的包围框，而其相邻框则根据预定义的重叠阈值（例如0.5)删除）。 上述处理是以贪婪的方式迭代执行的。（现在基本在使用此种方式）</span><br><span class="line">Bbox聚合：</span><br><span class="line">BB聚合是NMS[10,103,156,157]的另一组技术，其思想是将多个重叠包围盒组合或聚类成一个最终检测。 这种方法的优点是它充分考虑了对象关系及其空间布局。 有一些著名的检测器使用这种方法，如VJ检测器[10]和Overfeat[103]。</span><br><span class="line">Learning to NMS：</span><br></pre></td></tr></table></figure><p>十二：Technical Evolution of Hard Negative Mining</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">假设给你一堆包含一个或多个人物的图片，并且每一个人都给你一个bounding box做标记，如果要训练一个分类器去做分类的话，你的分类器需要既包含正训练样本（人）和负训练样本（背景）。</span><br><span class="line">你通过观察bounding box去创建一个有用的正训练样本，那么怎么做才能创建一个有用的负训练样本呢？</span><br><span class="line">一个很好的方式就是去在开始时随机创建一堆的bounding box候选框，并且不能与你的正样本有任何的重叠，把这些未与正样本重叠的新的bounding box作为你的负样本。</span><br><span class="line">好了，这样你的正负样本都有了，可以训练可以用的分类器了，你用滑动窗口在你的训练图片上进行运行，但是你会发现你的分类器并不是很好用，分类的效果并不是很好，因为它会抛出一堆的错误的正样本（当检测到人时实际上却并不是实际的人），这就问题来了，你训练了一个用于分类的分类器，然而这个分类器却并不能达到你想要的效果，那么应该怎么办呢？</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">使用滑动窗口的时候，出现的问题是：负样本/正样本的比例可能高达10^5以上，严重导致数据不平衡</span><br><span class="line"></span><br><span class="line">Bootstrap：</span><br><span class="line">当你得到错误的检测patch时，会明确的从这个patch中创建一个负样本，并把这个负样本添加到你的训练集中去。当你重新训练你的分类器后，分类器会表现的更好，并且不会像之前那样产生多的错误的正样本。</span><br><span class="line"></span><br><span class="line">HNM in deep learning based detectors：</span><br><span class="line">例如，在SSD[21]和OHEM[166]中，只有极小部分样本（损失值最大的样本）的梯度才会反向传播。 在细化细节[55]中，设计了一个“锚精化模块”来过滤容易的底片。 另一个改进是[23,169,170]设计新的损失函数，通过重塑标准的交叉熵损失，使其更多地关注硬的、错误分类的示例</span><br></pre></td></tr></table></figure><p>十三：检测速度</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">分为：“加快探测管道”、“加快探测引擎”和“加快数值计算”</span><br><span class="line">“speed up of detection pipeline”，“speed up of detection engine”，and “speed up of numerical computation”</span><br><span class="line"></span><br><span class="line">13.1Feature Map Shared Computation（特征图共享计算）</span><br><span class="line">13.2Speed up of Classifiers</span><br><span class="line">13.3Cascaded Detection</span><br><span class="line">13.4Network Pruning and Quantification and Network Distillation:</span><br><span class="line">网络蒸馏：使用大网络来训练小网络</span><br></pre></td></tr></table></figure><p>十四：主干网</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">AlexNet: AlexNet [40], an eight-layer deep network, was the first CNN model that started the deep learning revolution in computer vision. AlexNet famously won the 2012 ImageNet LSVRC-2012 competition by a large margin [15.3% VS 26.2% (second place) error rates]. As of Feb. 2019, the Alexnet paper has been cited over 30,000 times.</span><br><span class="line"></span><br><span class="line">VGG: VGG was proposed by Oxford&apos;s Visual Geometry Group (VGG) in 2014 [230]. VGG increased the model&apos;s depth to 16-19 layers and used very small (3x3) convolution filters instead of 5x5 and 7x7 those were previously used in AlexNet. VGG has achieved the state of the art performance on the ImageNet dataset of its time.</span><br><span class="line"></span><br><span class="line">GoogLeNet: GoogLeNet, a.k.a Inception [198, 231-233], is a big family of CNN models proposed by Google Inc. since 2014. GoogLeNet increased both of a CNN&apos;s width and depth (up to 22 layers). The main contribution of the Inception family is the introduction of factorizing convolution and batch normalization.</span><br><span class="line"></span><br><span class="line">ResNet: The Deep Residual Networks (ResNet) [234], proposed by K. He et al. in 2015, is a new type of convolutional network architecture that is substantially deeper (up to 152 layers) than those used previously. ResNet aims to ease the training of networks by reformulating its layers as learning residual functions with reference to the layer inputs. ResNet won multiple computer vision competitions in 2015, including ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.</span><br><span class="line"></span><br><span class="line">DenseNet: DenseNet [235] was proposed by G. Huang and Z. Liu et al. in 2017. The success of ResNet suggested that the short cut connection in CNN enables us to train deeper and more accurate models. The authors embraced this observation and introduced a densely connected block, which connects each layer to every other layer in a feedforward fashion.</span><br><span class="line"></span><br><span class="line">SENet: Squeeze and Excitation Networks (SENet) was proposed by J. Hu and L. Shen et al. in 2018 [236]. Its main contribution is the integration of global pooling and shuffling to learn channel-wise importance of the feature map. SENet won the 1st place in ILSVRC 2017 classification competition.</span><br><span class="line"></span><br><span class="line">• Object detectors with new engines</span><br><span class="line">In recent three years, many of the latest engines have been applied to object detection. For example, some latest object detection models such as STDN [237], DSOD [238], TinyDSOD [207], and Pelee [209] choose DenseNet [235] as their detection engine. The Mask RCNN [4], as the state of the art model for instance segmentation, applied the next generation of ResNet: ResNeXt [239] as its detection engine. Besides, to speed up detection, the depth-wise separable convolution operation, which was introduced by Xception [204], an improved version of Incepion, has also been used in detectors such as MobileNet [205] and LightHead RCNN [47].</span><br></pre></td></tr></table></figure><p>十五：特征</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.Feature Fusion特征融合</span><br><span class="line">Invariance and equivariance are two important properties in image feature representations</span><br><span class="line">①不变性和等变性（分类过程需要不变性，定位过程需要等变性）</span><br><span class="line">②卷积层越深，特征的不变性越强，但是等变性较差；有利于目标识别</span><br><span class="line">③卷积层越浅，特征的等变性较好，轮廓等特征易于学习</span><br><span class="line">④综上，特征融合很重要</span><br><span class="line"></span><br><span class="line">2.learning high-resolution features with large receptive fields学习具有大接收场的高分辨率特征。</span><br></pre></td></tr></table></figure><p>十六：定位方式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.Sliding Window</span><br><span class="line">2.Detection as sub-region search</span><br><span class="line">3.Detection as key points localization</span><br></pre></td></tr></table></figure><p>十七：提高定位准确度</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.Bounding Box Refinement</span><br><span class="line">2.Improving Loss Functions forAccurate Localization</span><br></pre></td></tr></table></figure><p>十八：语义分割semantic segmentation</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.Segmentation helps category recognition</span><br><span class="line">2.Segmentation helps accurate localization</span><br><span class="line">3.Segmentation can be embedded as context（飞机可能在天上，而不是在水中）</span><br></pre></td></tr></table></figure><p>十九：旋转和尺度改变的鲁棒性检测</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.旋转鲁棒性检测</span><br><span class="line">•Rotation invariant loss functions</span><br><span class="line">•Rotation calibration</span><br><span class="line">•Rotation Rol Pooling</span><br><span class="line">2.尺度鲁棒性检测</span><br><span class="line">•Scale adaptive training</span><br><span class="line">•Scale adaptive detection</span><br></pre></td></tr></table></figure><p>二十：应用</p><p>1.Pedestrian Detection行人检测</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.挑战：</span><br><span class="line">①小像素（远处相机）</span><br><span class="line">②困难负样本（类似的物体）</span><br><span class="line">③遮挡的行人</span><br><span class="line">④实时检测</span><br><span class="line"></span><br><span class="line">2.发展历史</span><br><span class="line">①传统方式：haar</span><br><span class="line">②深度学习：fast-Rcnn</span><br></pre></td></tr></table></figure><p>2.Face Detection脸部检测</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.挑战</span><br><span class="line">①Intra-class variation人脸形变</span><br><span class="line">②遮挡</span><br><span class="line">③Multi-scale detection</span><br><span class="line">④实时检测</span><br></pre></td></tr></table></figure><p>3.Text Detection文本检测</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.挑战</span><br><span class="line">Different fonts and languages</span><br><span class="line">Text rotation and perspective distortion</span><br><span class="line">Densely arranged text localization</span><br><span class="line">Broken and blurred characters</span><br></pre></td></tr></table></figure><p>4.Traffic Sign and Traffic Light Detection交通标志和交通灯检测（自动驾驶）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.挑战</span><br><span class="line">照明变换</span><br><span class="line">运动模糊</span><br><span class="line">雨雪天气</span><br><span class="line">实时检测</span><br></pre></td></tr></table></figure><p>5.Remote Sensing Target Detection遥感目标检测</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.大数据检测</span><br><span class="line">2.遮挡（云层）</span><br><span class="line">3.不同遥感分辨率差异</span><br></pre></td></tr></table></figure><p>二十一：未来发展</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.轻量级网络</span><br><span class="line">2.自动化ML</span><br><span class="line">3.自适应环境</span><br><span class="line">4.弱监督检测</span><br><span class="line">5.小目标检测</span><br><span class="line">6.视频中检测</span><br><span class="line">7.检测与信息融合</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;目标检测20年&quot;&gt;&lt;a href=&quot;#目标检测20年&quot; class=&quot;headerlink&quot; title=&quot;目标检测20年&quot;&gt;&lt;/a&gt;目标检测20年&lt;/h1&gt;&lt;p&gt;一：应用方向&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>数据采集流程（全）</title>
    <link href="https://yanyubing.xyz/2020/11/24/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E6%B5%81%E7%A8%8B%EF%BC%88%E5%85%A8%EF%BC%89/"/>
    <id>https://yanyubing.xyz/2020/11/24/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E6%B5%81%E7%A8%8B%EF%BC%88%E5%85%A8%EF%BC%89/</id>
    <published>2020-11-24T05:42:59.863Z</published>
    <updated>2020-11-24T07:46:53.521Z</updated>
    
    <content type="html"><![CDATA[<p><strong><em>\</em>数据采集工作流程解决方案（全）**</strong></p><p><strong>1.</strong> <strong><em>\</em>硬件准备**</strong></p><p>①工业主机：</p><p>参数：主机 Intel双核-j1800         8G内存  64G固态硬盘</p><p>链接：<a href="https://item.jd.com/63906155297.html" target="_blank" rel="noopener">https://item.jd.com/63906155297.html</a></p><p>②U盘：</p><p>Ubuntu20.04lts启动盘</p><p>③网络摄像头</p><p>④虚拟显卡</p><p>链接：<a href="https://item.jd.com/100006564772.html" target="_blank" rel="noopener">https://item.jd.com/100006564772.html</a></p><p><strong>2.</strong> <strong><em>\</em>流程**</strong></p><p>①工业主机系统重装</p><p>②安装向日葵，设置开机自启动</p><p>安装依赖包需参考：</p><p><a href="https://zhuanlan.zhihu.com/p/144426017" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/144426017</a></p><p>③安装pycharm和conda（如果对环境熟悉，可以选择不安装，建议安装便于程序的调试）</p><p>④代码拷贝（包含储存检测的代码和触发器传输文件代码）</p><p>⑤环境准备：</p><p>在pycharm中创建conda环境</p><p><a href="https://blog.csdn.net/weixin_30486037/article/details/97982277" target="_blank" rel="noopener">https://blog.csdn.net/weixin_30486037/article/details/97982277</a></p><p>清华源安装opencv</p><p>安装转码包ffmpeg：</p><p>最优方式参考<a href="https://blog.csdn.net/lwgkzl/article/details/77836207" target="_blank" rel="noopener">https://blog.csdn.net/lwgkzl/article/details/77836207</a></p><p><strong>3.</strong> <strong><em>\</em>需要调整的地方**</strong></p><p>网络摄像头：</p><p>①设置好网络摄像头参数为720p，10fps，设置时间水印为黄色</p><p>②记录网络摄像头ip</p><p>③设置网络摄像头账号和密码为yan  a18171458196</p><p>④调整网络摄像头的可视范围</p><p>代码：</p><p>①保存视频的时长，设置保存对象的box大小和比例，设置视频大小的阈值（每个场景都会有差异）</p><p>②保存视频以区域名前缀+时间构成</p><p>（例如：汉阳区政府区域</p><p>hyqzf_202011111110）</p><p><strong>4.</strong> <strong><em>\</em>最后**</strong></p><p>采集通道完成之后，观察上传的视频存在的问题，进行调整；最终达到该上传的就上传，不该上传的就不上传的平衡。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;&lt;em&gt;\&lt;/em&gt;数据采集工作流程解决方案（全）**&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;\&lt;/em&gt;硬件准备**&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;①工业主机：&lt;/p&gt;
&lt;p&gt;参数：主机 Inte
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>关于制作视频抽帧数据集这件事</title>
    <link href="https://yanyubing.xyz/2020/11/21/%E5%85%B3%E4%BA%8E%E5%88%B6%E4%BD%9C%E8%A7%86%E9%A2%91%E6%8A%BD%E5%B8%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BF%99%E4%BB%B6%E4%BA%8B/"/>
    <id>https://yanyubing.xyz/2020/11/21/%E5%85%B3%E4%BA%8E%E5%88%B6%E4%BD%9C%E8%A7%86%E9%A2%91%E6%8A%BD%E5%B8%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BF%99%E4%BB%B6%E4%BA%8B/</id>
    <published>2020-11-21T07:10:14.506Z</published>
    <updated>2020-11-23T02:13:53.829Z</updated>
    
    <content type="html"><![CDATA[<h1 id="关于制作视频抽帧数据集这件事"><a href="#关于制作视频抽帧数据集这件事" class="headerlink" title="关于制作视频抽帧数据集这件事"></a>关于制作视频抽帧数据集这件事</h1><p>一：制作视频数据集的原则</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.减少相同样本重复性（避免过拟合）</span><br><span class="line">2.能快速过滤到自己要的图片数据</span><br></pre></td></tr></table></figure><p>二：技巧与问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.如果目标类别在已有的预训练模型中有，并且业务逻辑也是伴随着目标类别来做的，那么可以使用预训练模型检测作为提取的第一步（这里conf阈值可以调高，更好的定位目标图片）</span><br><span class="line"></span><br><span class="line">2.问题：抽取的第一步会出现连续多帧都会被采集到，如何过滤？</span><br><span class="line">方案①：将提取比例作为超参数，随机提取此比例的图片</span><br><span class="line">方案②：间隔n张提取一张（适用于类别稳定出现的情况）</span><br><span class="line"></span><br><span class="line">3.问题：本人遇到的情形是，目标类别一般会均匀出现（3s出现一次，一次被抽取的第一步抽取到一张），但是偶尔会有特例出现（一次被抽取的第一步提取到100张）？</span><br><span class="line">使用上述方案①和方案②都不合适，会过多的采用同样的图片，或者有很多样本没有采用；</span><br><span class="line">解决方案为：视频流中有时间戳，通过时间戳的间隔来过滤（获取时间戳，保存得到连续时间戳的中位数图片，前后的图片对象都是刚出现或者已经消失，对象不全）</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;关于制作视频抽帧数据集这件事&quot;&gt;&lt;a href=&quot;#关于制作视频抽帧数据集这件事&quot; class=&quot;headerlink&quot; title=&quot;关于制作视频抽帧数据集这件事&quot;&gt;&lt;/a&gt;关于制作视频抽帧数据集这件事&lt;/h1&gt;&lt;p&gt;一：制作视频数据集的原则&lt;/p&gt;
&lt;figu
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>10-目标跟踪</title>
    <link href="https://yanyubing.xyz/2020/11/17/10-%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/"/>
    <id>https://yanyubing.xyz/2020/11/17/10-%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/</id>
    <published>2020-11-17T08:08:39.273Z</published>
    <updated>2020-11-17T08:08:39.273Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>09-场景文字识别</title>
    <link href="https://yanyubing.xyz/2020/11/17/09-%E5%9C%BA%E6%99%AF%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB/"/>
    <id>https://yanyubing.xyz/2020/11/17/09-%E5%9C%BA%E6%99%AF%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB/</id>
    <published>2020-11-17T08:08:24.208Z</published>
    <updated>2020-11-17T08:08:24.208Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>08-人体关键点检测</title>
    <link href="https://yanyubing.xyz/2020/11/17/08-%E4%BA%BA%E4%BD%93%E5%85%B3%E9%94%AE%E7%82%B9%E6%A3%80%E6%B5%8B/"/>
    <id>https://yanyubing.xyz/2020/11/17/08-%E4%BA%BA%E4%BD%93%E5%85%B3%E9%94%AE%E7%82%B9%E6%A3%80%E6%B5%8B/</id>
    <published>2020-11-17T08:08:11.615Z</published>
    <updated>2020-11-17T08:08:11.615Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>07-视频分类</title>
    <link href="https://yanyubing.xyz/2020/11/17/07-%E8%A7%86%E9%A2%91%E5%88%86%E7%B1%BB/"/>
    <id>https://yanyubing.xyz/2020/11/17/07-%E8%A7%86%E9%A2%91%E5%88%86%E7%B1%BB/</id>
    <published>2020-11-17T08:07:59.237Z</published>
    <updated>2020-11-17T08:07:59.237Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>06-实例分割</title>
    <link href="https://yanyubing.xyz/2020/11/17/06-%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2/"/>
    <id>https://yanyubing.xyz/2020/11/17/06-%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2/</id>
    <published>2020-11-17T08:07:38.004Z</published>
    <updated>2020-11-17T08:07:38.004Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>05-语义分割</title>
    <link href="https://yanyubing.xyz/2020/11/17/05-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>https://yanyubing.xyz/2020/11/17/05-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/</id>
    <published>2020-11-17T08:07:25.808Z</published>
    <updated>2020-11-17T08:07:25.808Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>04-目标检测</title>
    <link href="https://yanyubing.xyz/2020/11/17/04-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"/>
    <id>https://yanyubing.xyz/2020/11/17/04-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/</id>
    <published>2020-11-17T08:07:14.280Z</published>
    <updated>2020-11-17T08:07:14.280Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>03-图像分类</title>
    <link href="https://yanyubing.xyz/2020/11/17/03-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
    <id>https://yanyubing.xyz/2020/11/17/03-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/</id>
    <published>2020-11-17T08:06:58.308Z</published>
    <updated>2020-12-01T08:14:49.269Z</updated>
    
    <content type="html"><![CDATA[<h2 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h2><p>1：KNN</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"># 实现方法</span><br><span class="line"># 1）给定测试对象，计算它与训练集中每个对象的距离。</span><br><span class="line"># 将图片resize成固定大小，计算灰度图的每个像素的欧氏距离</span><br><span class="line"># 2）圈定距离最近的k个训练对象，作为测试对象的邻居。</span><br><span class="line"># 3）根据这k个近邻对象所属的类别，找到占比最高的那个类别作为测试对象的预测类别。</span><br><span class="line">import glob</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 欧式距离</span><br><span class="line">def get_EuclideanDistance(x, y):</span><br><span class="line">    myx = np.array(x)</span><br><span class="line">    myy = np.array(y)</span><br><span class="line">    return np.sqrt(np.sum((myx - myy) * (myx - myy)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取数据集，返回 [class,image]</span><br><span class="line">def getDataSet(path):</span><br><span class="line">    if not path.endswith(&apos;.jpg&apos;):</span><br><span class="line">        # 获取路径下的图片</span><br><span class="line">        files = glob.glob(path + &apos;*.jpg&apos;)</span><br><span class="line">    else:</span><br><span class="line">        files = [path]</span><br><span class="line">    # 读取图片储存类别和对应的像素值</span><br><span class="line">    dataset = []</span><br><span class="line">    for file in files:</span><br><span class="line">        print(file)</span><br><span class="line">        image = cv2.imread(file, 0)</span><br><span class="line">        image = cv2.resize(image, (400, 400), interpolation=cv2.INTER_CUBIC)</span><br><span class="line">        class_ = file.split(&quot;\\&quot;)[-1].split(&apos;_&apos;)[0]</span><br><span class="line">        data = [class_, image]</span><br><span class="line">        dataset.append(data)</span><br><span class="line">    return dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    # 训练集的数据集</span><br><span class="line">    cat_train_path = &apos;D:/File_yan/study/ImageClassification/dataSet/train/cat/&apos;</span><br><span class="line">    dog_train_path = &apos;D:/File_yan/study/ImageClassification/dataSet/train/dog/&apos;</span><br><span class="line">    cat_data_set = getDataSet(cat_train_path)</span><br><span class="line">    dog_data_set = getDataSet(dog_train_path)</span><br><span class="line"></span><br><span class="line">    testFiles = glob.glob(&apos;D:/File_yan/study/ImageClassification/dataSet/test/cat/&apos; + &apos;*.jpg&apos;)</span><br><span class="line">    for file in testFiles:</span><br><span class="line">        EuclideanDistances = []</span><br><span class="line">        testData = getDataSet(file)</span><br><span class="line">        for test in testData:</span><br><span class="line">            for cat_data in cat_data_set:</span><br><span class="line">                EuclideanDistance = [cat_data[0], cat_data[1], get_EuclideanDistance(test[1], cat_data[1])]</span><br><span class="line">                EuclideanDistances.append(EuclideanDistance)</span><br><span class="line"></span><br><span class="line">            for dog_data in dog_data_set:</span><br><span class="line">                EuclideanDistance = [dog_data[0], dog_data[1], get_EuclideanDistance(test[1], dog_data[1])]</span><br><span class="line">                EuclideanDistances.append(EuclideanDistance)</span><br><span class="line">        testimage = cv2.imread(file)</span><br><span class="line">        cv2.imshow(&apos;test&apos;, testimage)</span><br><span class="line">        cv2.waitKey(0)</span><br><span class="line">        cv2.destroyAllWindows()</span><br><span class="line">        EuclideanDistances.sort(key=lambda x: int(x[2]))</span><br><span class="line">        EuclideanDistances = np.array(EuclideanDistances)</span><br><span class="line">        for e in EuclideanDistances:</span><br><span class="line">            print(e[0])</span><br><span class="line">            cv2.imshow(&apos;target&apos;,e[1])</span><br><span class="line">            cv2.waitKey(0)</span><br><span class="line">            cv2.destroyAllWindows()</span><br><span class="line">            print(e[2])</span><br><span class="line"></span><br><span class="line">#问题</span><br><span class="line">#把每个像素作为特征输入，并不能很好的拟合实际图片的特征；并且数据量大的时候，匹配过程耗时长</span><br></pre></td></tr></table></figure><p>2：SVM</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#实现方法</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">from sklearn import datasets</span><br><span class="line">from sklearn import svm</span><br><span class="line"></span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line">clf = svm.SVC(gamma=0.0001, C=100)</span><br><span class="line"></span><br><span class="line">x, y = digits.data[:-10], digits.target[:-10]</span><br><span class="line">clf.fit(x, y)</span><br><span class="line"></span><br><span class="line">print(&apos;prediction:&apos;, clf.predict([digits.data[-2]]))</span><br><span class="line">plt.imshow(digits.images[-2], interpolation=&apos;nearest&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>3：BPNN</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#反向传播网络</span><br><span class="line">问题在于：全连接层导致参数过多，过拟合</span><br></pre></td></tr></table></figure><p>4：CNN</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">卷积神经网络，主要在于卷积运算</span><br><span class="line">特点：参数得到了控制，即使我们使用简单神经网络模型（BPNN）的最大验证准确性约为97％，但CNN模型仅需一个卷积层就能够获得98％+的收益！</span><br><span class="line">1 LeNet：</span><br><span class="line">2 AlexNet：</span><br><span class="line">3 VGG-Net：</span><br><span class="line">4 GoogLeNet：</span><br><span class="line">5 Resnet：</span><br></pre></td></tr></table></figure><p>5：迁移学习</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;图像分类&quot;&gt;&lt;a href=&quot;#图像分类&quot; class=&quot;headerlink&quot; title=&quot;图像分类&quot;&gt;&lt;/a&gt;图像分类&lt;/h2&gt;&lt;p&gt;1：KNN&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>02-opencv</title>
    <link href="https://yanyubing.xyz/2020/11/17/02-opencv/"/>
    <id>https://yanyubing.xyz/2020/11/17/02-opencv/</id>
    <published>2020-11-17T01:54:47.343Z</published>
    <updated>2020-11-17T03:43:50.625Z</updated>
    
    <content type="html"><![CDATA[<h1 id="opencv"><a href="#opencv" class="headerlink" title="opencv"></a>opencv</h1><p>一：安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">清华源安装</span><br></pre></td></tr></table></figure><p>二：图像入门</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.imread()，cv.imshow()，cv.imwrite()</span><br></pre></td></tr></table></figure><p>三：视频入门</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cv.VideoCapture()，cv.VideoWriter()</span><br><span class="line">涉及到视频的编码，根据储存视频大小的需求定</span><br></pre></td></tr></table></figure><p>四：opencv绘图功能</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.line()，cv.circle()，cv.rectangle()，cv.ellipse()，cv.putText()等。</span><br></pre></td></tr></table></figure><p>五：鼠标作为画笔</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.setMouseCallback()</span><br></pre></td></tr></table></figure><p>六：调色板</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.getTrackbarPos，**cv.createTrackbar**等。</span><br></pre></td></tr></table></figure><p>七：图像基本操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">访问像素值并修改它们 - 访问图像属性 - 设置感兴趣区域(ROI) - 分割和合并图像</span><br></pre></td></tr></table></figure><p>八：图像上的算术运算</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">加法，减法，按位运算，融合</span><br></pre></td></tr></table></figure><p>九：改变颜色空间</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">BGR↔灰色，BGR↔HSV等xxxxxxxxxx 改变颜色空间BGR↔灰色，BGR↔HSV等</span><br><span class="line">cv.cvtColor，cv.inRange</span><br></pre></td></tr></table></figure><p>十：图像的几何变换</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">平移、旋转、仿射变换等</span><br><span class="line">OpenCV提供了两个转换函数**cv.warpAffine**和**cv.warpPerspective**，您可以使用它们进行各种转换。**cv.warpAffine**采用2x3转换矩阵，而**cv.warpPerspective**采用3x3转换矩阵作为输入。</span><br></pre></td></tr></table></figure><p>十一：图像阈值</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">简单阈值，自适应阈值和Otsu阈值。</span><br></pre></td></tr></table></figure><p>十二：图像平滑</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">使用各种低通滤镜模糊图像 - 将定制的滤镜应用于图像</span><br></pre></td></tr></table></figure><p>十三：形态学转换</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">侵蚀，膨胀，开运算，闭运算等</span><br></pre></td></tr></table></figure><p>十四：图像梯度</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cv.Sobel()，cv.Scharr()，cv.Laplacian()等</span><br></pre></td></tr></table></figure><p>十五：边缘检测</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Canny边缘检测的概念 - OpenCV函数: cv.Canny()</span><br></pre></td></tr></table></figure><p>十六：图像金字塔</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">学习图像金字塔 - 我们将看到以下功能：cv.pyrUp()，cv.pyrDown()</span><br></pre></td></tr></table></figure><p>十七：轮廓</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">①cv.findContours()，cv.drawContours()</span><br><span class="line">②轮廓特征：面积，周长，质心，边界框，轮廓凸包。。。</span><br><span class="line">③轮廓属性：长宽比，范围，坚实度。。。</span><br><span class="line">④更多属性：凸性缺陷，点多边形测试，形状匹配。。。</span><br><span class="line">⑤轮廓分层</span><br></pre></td></tr></table></figure><p>十八：直方图</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">①使用OpenCV和Matplotlib函数绘制直方图 - 你将看到以下函数：cv.calcHist()，np.histogram()等。</span><br><span class="line">②直方图均衡</span><br></pre></td></tr></table></figure><p>十九：模板匹配</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">①cv.matchTemplate()，cv.minMaxLoc()</span><br><span class="line">②多尺度模板匹配</span><br></pre></td></tr></table></figure><p>二十：霍夫曼</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">霍夫曼直线，霍夫曼圆</span><br></pre></td></tr></table></figure><p>二十一：特征检测与描述</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Shi-Tomasi拐角</span><br><span class="line">SIFT尺度不变特征</span><br><span class="line">SURF加速</span><br><span class="line">FAST角点检测</span><br><span class="line">BRIEF二进制鲁棒基本特征</span><br><span class="line">ORB定向快速和旋转简要</span><br><span class="line">特征匹配</span><br></pre></td></tr></table></figure><p>二十二：视频分析</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">背景分离</span><br><span class="line">运动检测</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;opencv&quot;&gt;&lt;a href=&quot;#opencv&quot; class=&quot;headerlink&quot; title=&quot;opencv&quot;&gt;&lt;/a&gt;opencv&lt;/h1&gt;&lt;p&gt;一：安装&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;t
      
    
    </summary>
    
    
    
  </entry>
  
</feed>
