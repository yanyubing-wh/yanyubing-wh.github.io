<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>鄢玉兵的博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://yanyubing.xyz/"/>
  <updated>2020-10-19T09:28:50.072Z</updated>
  <id>https://yanyubing.xyz/</id>
  
  <author>
    <name>鄢玉兵</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>torch环境准备</title>
    <link href="https://yanyubing.xyz/2020/10/19/torch%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/"/>
    <id>https://yanyubing.xyz/2020/10/19/torch%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87/</id>
    <published>2020-10-19T09:28:17.185Z</published>
    <updated>2020-10-19T09:28:50.072Z</updated>
    
    <content type="html"><![CDATA[<h1 id="torch环境准备"><a href="#torch环境准备" class="headerlink" title="torch环境准备"></a>torch环境准备</h1><p>1.重装系统</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;torch环境准备&quot;&gt;&lt;a href=&quot;#torch环境准备&quot; class=&quot;headerlink&quot; title=&quot;torch环境准备&quot;&gt;&lt;/a&gt;torch环境准备&lt;/h1&gt;&lt;p&gt;1.重装系统&lt;/p&gt;

      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>course.fast.ai</title>
    <link href="https://yanyubing.xyz/2020/10/19/course.fast.ai/"/>
    <id>https://yanyubing.xyz/2020/10/19/course.fast.ai/</id>
    <published>2020-10-19T08:13:12.180Z</published>
    <updated>2020-10-19T09:10:46.658Z</updated>
    
    <content type="html"><![CDATA[<h1 id="course-fast-ai"><a href="#course-fast-ai" class="headerlink" title="course.fast.ai"></a>course.fast.ai</h1><p><a href="https://course.fast.ai" target="_blank" rel="noopener">https://course.fast.ai</a></p><p>1.Mac不支持英伟达GPU</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;course-fast-ai&quot;&gt;&lt;a href=&quot;#course-fast-ai&quot; class=&quot;headerlink&quot; title=&quot;course.fast.ai&quot;&gt;&lt;/a&gt;course.fast.ai&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://cours
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>瑕疵检测</title>
    <link href="https://yanyubing.xyz/2020/10/19/%E7%91%95%E7%96%B5%E6%A3%80%E6%B5%8B/"/>
    <id>https://yanyubing.xyz/2020/10/19/%E7%91%95%E7%96%B5%E6%A3%80%E6%B5%8B/</id>
    <published>2020-10-19T05:54:04.809Z</published>
    <updated>2020-10-19T05:57:13.674Z</updated>
    
    <content type="html"><![CDATA[<p>​                                                                   瓦片裂痕检测</p><h2 id="传统算法方向的选择"><a href="#传统算法方向的选择" class="headerlink" title="传统算法方向的选择"></a>传统算法方向的选择</h2><p>最近做图像处理与识别相关的事情，先从OpenCV/Matlab入手，看传统算法在瑕疵检测方向能做到什么程度。</p><p>因之前并没有相关的经验，乍开始生怕闭门造车，遂多方搜寻，相关的会议与论述很多，不乏深度学习或者深度学习与传统算法相结合的，以有限的资源来看，深度学习并没有特别大的优势：表现在</p><ol><li><p>深度学习对训练图库的要求很高，很难得到很好的训练结果</p></li><li><p>深度学习的灵活度较低，若适用场景有些许改变，均需要重新训练，这在商用时会是很大的问题</p></li><li><p>深度学习的部署成本较高，同时对部署场景有较高要求（光线/摄像效果等）*<br>当然，深度学习大势所趋，也不必因噎废食，万一是一时的浅见呢。后续也会投身到这个方向去。</p></li></ol><h2 id="瑕疵检测关注的两个问题"><a href="#瑕疵检测关注的两个问题" class="headerlink" title="瑕疵检测关注的两个问题"></a>瑕疵检测关注的两个问题</h2><h3 id="瑕疵的标注"><a href="#瑕疵的标注" class="headerlink" title="瑕疵的标注"></a>瑕疵的标注</h3><p>对瑕疵的标注是为了更直观的展示，主要是给人看的</p><h3 id="瑕疵的量化"><a href="#瑕疵的量化" class="headerlink" title="瑕疵的量化"></a>瑕疵的量化</h3><p>真正机器关心的是怎么量化，是用数量表示还是百分比是个值得考虑的问题</p><h2 id="历程"><a href="#历程" class="headerlink" title="历程"></a>历程</h2><h3 id="1-图像去噪-gt-灰度化-gt-二值化"><a href="#1-图像去噪-gt-灰度化-gt-二值化" class="headerlink" title="1.图像去噪-&gt;灰度化-&gt;二值化"></a>1.图像去噪-&gt;灰度化-&gt;二值化</h3><p>二值化之后就可以看到绝大部分的瑕疵点已经凸显出来了，但是有三个问题：</p><ol><li>黑点瑕疵与白点瑕疵是二值化的两个极端，故无法同时出现。</li><li>量化如何去除Logo与其他印刷的干扰<br>问题1后续用边缘检测替代<br>问题2采用像素点计数的方法，计算百分比，然后与无瑕疵的百分比作比较，准确度不高，也显得 low的。</li></ol><h3 id="2-图像去噪-gt-灰度化-gt-canny-gt-形态学（闭运算）-gt-连通域"><a href="#2-图像去噪-gt-灰度化-gt-canny-gt-形态学（闭运算）-gt-连通域" class="headerlink" title="2.图像去噪-&gt;灰度化-&gt;canny-&gt;形态学（闭运算）-&gt;连通域"></a>2.图像去噪-&gt;灰度化-&gt;canny-&gt;形态学（闭运算）-&gt;连通域</h3><p>边缘检测后进行闭运算，瑕疵会形成大大小小的连通域，可以统计连通域的个数，然后与无瑕疵logo与其他印刷形成的连通域个数作比较，这种情况几乎不会漏掉。这是感觉可行的选择之一。</p><h3 id="3-OpenCV-matchTemplate"><a href="#3-OpenCV-matchTemplate" class="headerlink" title="3.OpenCV matchTemplate"></a>3.OpenCV matchTemplate</h3><p>实验室条件下，可以营造比较理想的条件，所以考虑了OpenCV的模板匹配，同时也测试了模板匹配在不理想情况下的表现。<br>结果证明因为手机瑕疵检测的需求目标较低，模板匹配是比较能够胜任的一个办法。只要模板与识别目标的拍摄角度差别不是太大，都可以很好的识别瑕疵。图片的轻微缩放大多也可以应付。</p><h2 id="其他处理"><a href="#其他处理" class="headerlink" title="其他处理"></a>其他处理</h2><p>前面都是软件方面处理的流程，在如何获得更加理想的图片方面也做了一些尝试：</p><ol><li>采用各种不同颜色的光源，如蓝光/红光，区别不大</li><li>对图片进行白平衡调整，有改善</li><li>摄像头加偏振镜防止图像反光，有改善但不明显</li><li>图片浮雕处理，肉眼看上去瑕疵显著了，但对机器而言并没有区别，故没有采纳</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;​                                                                   瓦片裂痕检测&lt;/p&gt;
&lt;h2 id=&quot;传统算法方向的选择&quot;&gt;&lt;a href=&quot;#传统算法方向的选择&quot; class=&quot;headerlink&quot;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>数据集</title>
    <link href="https://yanyubing.xyz/2020/08/28/%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    <id>https://yanyubing.xyz/2020/08/28/%E6%95%B0%E6%8D%AE%E9%9B%86/</id>
    <published>2020-08-28T02:10:47.267Z</published>
    <updated>2020-08-28T02:33:26.869Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><p>1.数据是算法的粮食，没有好的数据，算法再优秀，也生产不出来好的模型；作为AI工程师，最开始就要了解公司数据的产生过程，才可以很好的把控模型的优劣</p><p>2.目标检测/分类、数据集制作过程应该有详细的生成流程，包括如下：</p><p>①数据集产生的基本要求（应当与模型实际工作环境尽量保持一致或者，同时需要包含到工作环境中的一切可能性，例如图片的输入大小。。。）</p><p>②数据集的产生，采样过程（如无人机飞行录制视频、拍照等形式）</p><p>③定标注种类，定标注要求（与实际业务挂钩）</p><p>④组织标注人员，审查人员（对工作量的预估，每天可以生产多少数据，费用计算。。。）</p><p>⑤数据集合格之后进行模型训练，对比训练效果，进行微调来增加精度</p><p>⑥精度达到一定程度的时候，开始直接使用模型来标注数据集，标注错误的地方人工修改</p><p>3.补充</p><p>①数据的生成过程中需要大量的人工操作，其中部分可以使用代码处理可以节约大量的时间</p><p>如：</p><p>数据标注文本规范的检查（yolo对应的box字段为5个，如果哪一行出现了10个字段，则会导致代码报错）</p><p>类别的检测（裁剪出box保存到对应类别目录下，box文件名中包含原始图片的文件名，检测标注类别是否准确，修改），同时也做了类别的统计</p><p>②数据生产过程应当作为一个流水线的工作形态，直到完成最优模型之前，一直需要；标注的数据出问题，会导致耗费大量的精力来修改，更正，得不偿失!</p><p>③为了达到最优的模型，数据集上面不能掉链子</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;数据集&quot;&gt;&lt;a href=&quot;#数据集&quot; class=&quot;headerlink&quot; title=&quot;数据集&quot;&gt;&lt;/a&gt;数据集&lt;/h1&gt;&lt;p&gt;1.数据是算法的粮食，没有好的数据，算法再优秀，也生产不出来好的模型；作为AI工程师，最开始就要了解公司数据的产生过程，才可以很好的
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>wordpress搭建</title>
    <link href="https://yanyubing.xyz/2020/08/13/wordpress%E6%90%AD%E5%BB%BA/"/>
    <id>https://yanyubing.xyz/2020/08/13/wordpress%E6%90%AD%E5%BB%BA/</id>
    <published>2020-08-13T02:47:04.590Z</published>
    <updated>2020-08-13T02:48:18.180Z</updated>
    
    <content type="html"><![CDATA[<h2 id="—————-环境安装————–"><a href="#—————-环境安装————–" class="headerlink" title="—————-环境安装————–"></a>—————-环境安装————–</h2><p>——–数据库（无法安装成功）<br>sudo apt install mariadb-server mariadb-client -y</p><p>启动mariadb<br>sudo systemctl start mariadb</p><p>查看状态<br>sudo systemctl status mariadb</p><p>######apache2安装<br>sudo apt install apache</p><p>———-php安装<br>sudo apt install php</p><h2 id="—————环境安装—————"><a href="#—————环境安装—————" class="headerlink" title="—————环境安装—————-"></a>—————环境安装—————-</h2><p>参考：<br>注意ubutun18.04LTS直接安装mariadb无法成功：<br><a href="https://computingforgeeks.com/install-mariadb-10-on-ubuntu-18-04-and-centos-7/" target="_blank" rel="noopener">https://computingforgeeks.com/install-mariadb-10-on-ubuntu-18-04-and-centos-7/</a></p><p>主要流程的参考：<br><a href="https://www.youtube.com/watch?v=na-fT9ZgWPM" target="_blank" rel="noopener">https://www.youtube.com/watch?v=na-fT9ZgWPM</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;—————-环境安装————–&quot;&gt;&lt;a href=&quot;#—————-环境安装————–&quot; class=&quot;headerlink&quot; title=&quot;—————-环境安装————–&quot;&gt;&lt;/a&gt;—————-环境安装————–&lt;/h2&gt;&lt;p&gt;——–数据库（无法安装成功）&lt;br&gt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>svn服务器的搭建</title>
    <link href="https://yanyubing.xyz/2020/08/12/svn%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%90%AD%E5%BB%BA/"/>
    <id>https://yanyubing.xyz/2020/08/12/svn%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%90%AD%E5%BB%BA/</id>
    <published>2020-08-12T03:31:41.371Z</published>
    <updated>2020-08-12T03:32:42.361Z</updated>
    
    <content type="html"><![CDATA[<h4 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤:"></a>操作步骤:</h4><p>1.<br>sudo apt-get update</p><p>2.<br>./home/yanyubing/ubuntu-svn-script/setupSVN.sh</p><p>svn仓库地址:<br>/var/lib/svn</p><p>链接地址:<br><a href="http://192.168.16.56/svn/repository/" target="_blank" rel="noopener">http://192.168.16.56/svn/repository/</a></p><p>账号：<br>admin</p><p>密码：<br>123456</p><p>####创建仓库<br>sudo svnadmin create /var/lib/svn/repository2</p><p>####创建仓库之后修改仓库的所有者和所有者的组为www-data<br>sudo chown -R  www-data.www-data /var/lib/svn/repository2</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;操作步骤&quot;&gt;&lt;a href=&quot;#操作步骤&quot; class=&quot;headerlink&quot; title=&quot;操作步骤:&quot;&gt;&lt;/a&gt;操作步骤:&lt;/h4&gt;&lt;p&gt;1.&lt;br&gt;sudo apt-get update&lt;/p&gt;
&lt;p&gt;2.&lt;br&gt;./home/yanyubing/ubun
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>PythonWebCrawler</title>
    <link href="https://yanyubing.xyz/2020/07/12/PythonWebCrawler/"/>
    <id>https://yanyubing.xyz/2020/07/12/PythonWebCrawler/</id>
    <published>2020-07-12T03:28:32.954Z</published>
    <updated>2020-07-12T03:29:07.005Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Python-Web-Crawler"><a href="#Python-Web-Crawler" class="headerlink" title="Python Web Crawler"></a>Python Web Crawler</h1><p>1：</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Python-Web-Crawler&quot;&gt;&lt;a href=&quot;#Python-Web-Crawler&quot; class=&quot;headerlink&quot; title=&quot;Python Web Crawler&quot;&gt;&lt;/a&gt;Python Web Crawler&lt;/h1&gt;&lt;p&gt;1：&lt;/p&gt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>python数据结构和算法</title>
    <link href="https://yanyubing.xyz/2020/07/10/python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    <id>https://yanyubing.xyz/2020/07/10/python%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/</id>
    <published>2020-07-10T12:29:46.756Z</published>
    <updated>2020-07-10T13:00:25.462Z</updated>
    
    <content type="html"><![CDATA[<p>一：栈</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># stack</span><br><span class="line"></span><br><span class="line">class Stack():</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.items = []</span><br><span class="line"></span><br><span class="line">    def push(self, item):</span><br><span class="line">        self.items.append(item)</span><br><span class="line"></span><br><span class="line">    def pop(self):</span><br><span class="line">        return self.items.pop()</span><br><span class="line"></span><br><span class="line">    def is_empty(self):</span><br><span class="line">        return self.items == []</span><br><span class="line"></span><br><span class="line">    def peek(self):</span><br><span class="line">        if not self.is_empty():</span><br><span class="line">            return self.items[0]</span><br><span class="line">        else:</span><br><span class="line">            return []</span><br><span class="line"></span><br><span class="line">    def get_stacks(self):</span><br><span class="line">        return self.items</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">s = Stack()</span><br><span class="line">s.push(&apos;a&apos;)</span><br><span class="line">s.push(&apos;b&apos;)</span><br><span class="line">s.push(&apos;c&apos;)</span><br><span class="line">print(s.get_stacks())</span><br><span class="line">s.pop()</span><br><span class="line">print(s.get_stacks())</span><br><span class="line">print(s.peek())</span><br></pre></td></tr></table></figure><p>二：stack_balanced_parens</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># stack_balanced_parens</span><br><span class="line"># 用于ide的括号查全(),[],&#123;&#125;</span><br><span class="line">import sys</span><br><span class="line"></span><br><span class="line">sys.path.append(&apos;D:/yan/python/data_structures_and_algorithms_in_python/&apos;)</span><br><span class="line">from demo01 import Stack_demo</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def is_paren_balanced(paren_string):</span><br><span class="line">    s = Stack_demo()</span><br><span class="line">    for paren in paren_string:</span><br><span class="line">        if is_paren(s.peek(), paren):</span><br><span class="line">            # 匹配则弹出</span><br><span class="line">            s.pop()</span><br><span class="line">        else:  # 不匹配则加入</span><br><span class="line">            s.push(paren)</span><br><span class="line">    if s.is_empty():</span><br><span class="line">        return True</span><br><span class="line">    else:</span><br><span class="line">        return False</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def is_paren(pa1, pa2):</span><br><span class="line">    if pa1 == &apos;(&apos; and pa2 == &apos;)&apos;:</span><br><span class="line">        return True</span><br><span class="line">    if pa1 == &apos;[&apos; and pa2 == &apos;]&apos;:</span><br><span class="line">        return True</span><br><span class="line">    if pa1 == &apos;&#123;&apos; and pa2 == &apos;&#125;&apos;:</span><br><span class="line">        return True</span><br><span class="line">    else:</span><br><span class="line">        return False</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if &apos;__name__&apos; == &apos;__main__&apos;:</span><br><span class="line">    string = &apos;(([]))&apos;</span><br><span class="line">    flag = is_paren_balanced(string)</span><br><span class="line">    print(flag)</span><br></pre></td></tr></table></figure><p>三：</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一：栈&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>leetcode</title>
    <link href="https://yanyubing.xyz/2020/07/05/leetcode/"/>
    <id>https://yanyubing.xyz/2020/07/05/leetcode/</id>
    <published>2020-07-05T12:20:52.390Z</published>
    <updated>2020-07-06T07:52:44.291Z</updated>
    
    <content type="html"><![CDATA[<p>leetcode刷题与总结</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1.</span><br><span class="line">https://leetcode-cn.com/problems/add-two-numbers/</span><br><span class="line"></span><br><span class="line">总结:能够用一个循环解决的不要使用多个循环</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2. </span><br><span class="line">https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/</span><br><span class="line"></span><br><span class="line">总结:少写循环，最小子串问题，可以找到临时最小值之后步伐加大</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">3</span><br><span class="line"># https://leetcode-cn.com/problems/longest-common-prefix/</span><br><span class="line"></span><br><span class="line">总结：①找到最短的字符串②然后从最短字符串第一位开始依次增加</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;leetcode刷题与总结&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>feature_matching总结</title>
    <link href="https://yanyubing.xyz/2020/06/16/feature_matching%E6%80%BB%E7%BB%93/"/>
    <id>https://yanyubing.xyz/2020/06/16/feature_matching%E6%80%BB%E7%BB%93/</id>
    <published>2020-06-15T16:42:36.218Z</published>
    <updated>2020-06-17T06:45:44.272Z</updated>
    
    <content type="html"><![CDATA[<pre><code>feature_matching总结</code></pre><p>1：一般特征提取的方法有</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">harris corner detector</span><br><span class="line">SIFT</span><br><span class="line">SURF</span><br><span class="line">FAST</span><br><span class="line">BRIEF</span><br><span class="line">ORB</span><br><span class="line">BRISK</span><br></pre></td></tr></table></figure><p>2：一般特征匹配的方法有</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Brute-Force Matcher</span><br><span class="line">FLANN(Fast Library for Approximate Nearest Neighbors) Matcher</span><br></pre></td></tr></table></figure><p>3：什么是特征点(Feature detection)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Edges：强梯度变换</span><br><span class="line">Corners / interest points：两个边缘的交点</span><br><span class="line">Blobs / regions of interest points：LoG和DoH 斑点检测器</span><br><span class="line">Ridges：从灰度图像计算的脊线描述符可以看作是中间轴的概括（一般不会使用，算法复杂，航空和医学）</span><br></pre></td></tr></table></figure><p>4：什么是特征描述符(Feature description)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">描述特征点周围的向量</span><br></pre></td></tr></table></figure><p>5：什么是特征匹配(Feature matching)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;ratio test&quot; or &quot;nearest neighbor distance ratio test&quot;</span><br><span class="line">匹配两个图片特征点之间的差异性</span><br></pre></td></tr></table></figure><p>6：harris corner detector</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">拐角是一个点，其局部邻域位于两个主要且不同的边缘方向。换句话说，一个角可以解释为两个边缘的交点，其中边缘是图像亮度的突然变化。</span><br></pre></td></tr></table></figure><p>7：SIFT</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">尺度不变特征变换，特点：</span><br><span class="line">局部性：特征是局部性的，因此对遮挡和混乱都很健壮（没有事先分割）</span><br><span class="line">独特性：单个特征可以与大型对象数据库匹配</span><br><span class="line">数量：即使是很小的物体也可以生成许多特征</span><br><span class="line">效率：接近实时性能</span><br><span class="line">可扩展性：可以轻松扩展到各种不同的功能类型，每种功能都增加了鲁棒性</span><br><span class="line"></span><br><span class="line">比例空间峰选择：查找特征的潜在位置，使得尺度不变</span><br><span class="line">比例空间分为八度，八度的数量和比例取决于原始图像的大小。因此，我们生成原始图像的几个八度。每个八度的图像大小是前一个图像的一半。</span><br><span class="line"></span><br><span class="line">模糊化：在一个八度音程中，使用高斯模糊运算符逐渐模糊图像</span><br><span class="line"></span><br><span class="line">DOG：（高斯核的差）</span><br><span class="line">我们使用那些模糊的图像来生成另一组图像，即高斯差分（DoG）；这些DoG图像非常适合找出图像中有趣的关键点。</span><br><span class="line"></span><br><span class="line">寻找关键点：</span><br><span class="line">将图像中的一个像素与其8个邻居，下一个比例的9个像素和先前比例的9个像素进行比较。这样，总共进行了26次检查。如果是局部极值，则可能是关键点。从根本上说，关键点是最好的代表。</span><br><span class="line"></span><br><span class="line">关键点本地化：准确定位功能关键点。</span><br><span class="line">他们使用了尺度空间的泰勒级数展开来获得更精确的极值位置，并且如果该极值处的强度小于阈值（根据论文为0.03），则将其拒绝。DoG对边缘的响应较高，因此也需要删除边缘。</span><br><span class="line">主要是去除边缘特性</span><br><span class="line"></span><br><span class="line">方向分配：为关键点分配方向，目的是使得旋转不变</span><br><span class="line">取360°分为36份，每份分为10°；如果该点（在“方向收集区域”中）的渐变方向为18.759度。则那么它将进入10–19度的bin（直方图）中。</span><br><span class="line">提取直方图中的最高峰，并且将其超过80％的任何峰也视为计算方向。它创建的位置和比例相同但方向不同的关键点。它有助于匹配的稳定性。</span><br><span class="line"></span><br><span class="line">关键点描述符：将关键点描述为高维向量。</span><br><span class="line">到此为止，每个店都有位置，比例和方向。接下来是为每个关键点周围的局部图像区域计算一个描述符，该描述符对于诸如视点和照明的变化之类的变化具有高度的独特性和不变性。为此，将在关键点周围使用一个16x16的窗口。它分为16个4x4大小的子块。</span><br><span class="line">对于每个子块，创建8 bin方向直方图。</span><br><span class="line">①旋转相关性特征向量使用梯度方向。显然，如果旋转图像，一切都会改变。所有的梯度方向也会改变。为了实现旋转独立性，从每个方向减去关键点的旋转。因此，每个梯度方向都相对于关键点的方向。</span><br><span class="line">②照明依赖性如果我们将较大的阈值设为阈值，则可以实现照明依赖性。因此，任何大于0.2的数（128个数）都将更改为0.2。再次将该结果特征向量归一化。现在，您有了一个与照明无关的特征向量！</span><br><span class="line"></span><br><span class="line">关键点匹配：</span><br><span class="line">通过识别两个图像之间的关键点来匹配它们之间的关键点。但是在某些情况下，第二个最接近的匹配可能非常接近第一个。它可能是由于噪音或其他原因而发生的。在那种情况下，采用最接近距离与第二最接近距离之比。如果大于0.8，将被拒绝。根据论文，它可以消除大约90％的错误匹配，而只丢弃5％的正确匹配。</span><br></pre></td></tr></table></figure><p>8：SURF</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">快</span><br></pre></td></tr></table></figure><p>9：FAST</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">快，拐角检测器：</span><br><span class="line">由于检测到的角必须在包括角的两个边缘的中心周围具有较暗或较亮的像素值环，因此清晰的图像效果不佳。</span><br></pre></td></tr></table></figure><p>10：BRIEF</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Binary Robust Independent Elementary Features：二进制独立鲁棒特征描述符</span><br></pre></td></tr></table></figure><p>11： ORB</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Oriented FAST and Rotated BRIEF</span><br><span class="line">在特征检测任务上，ORB的性能与SIFT一样好（并且比SURF更好），而速度却快了两个数量级。ORB基于著名的FAST关键点检测器和Brief描述符。</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;feature_matching总结&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;1：一般特征提取的方法有&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>paper-summary</title>
    <link href="https://yanyubing.xyz/2020/06/13/paper-summary/"/>
    <id>https://yanyubing.xyz/2020/06/13/paper-summary/</id>
    <published>2020-06-13T02:26:00.570Z</published>
    <updated>2020-06-19T02:08:36.678Z</updated>
    
    <content type="html"><![CDATA[<h3 id="paper"><a href="#paper" class="headerlink" title="paper"></a>paper</h3><p>1：<strong>Pyramid Mask Text Detector</strong> (2019)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">1:pixel-level regression  代替传统Mask R-CNN的  binary text mask</span><br><span class="line">①二进制掩码定义原始图像的关注区域（ROI）。mask像素值 1表示图像像素属于ROI。mask像素值0表示图像像素是背景的一部分。</span><br><span class="line">②2D空间转换为3D空间的思想</span><br><span class="line"></span><br><span class="line">2: 传统方式没有解决的问题</span><br><span class="line">①监督简化：场景基本上基于不同的背景，但是没有特别的形状</span><br><span class="line">②错误的分割方式：会导致不属于RIO区域的背景会被识别进RIO区域</span><br><span class="line">③错误传播：二进制mask的区域基于Mask R-CNN的预测框，当预测框不准确时，mask也会错误</span><br><span class="line"></span><br><span class="line">3： “soft” semantic segmentation</span><br><span class="line">①根据距离文本框的距离编码0-1；</span><br><span class="line"></span><br><span class="line">4： plane clustering algorithm</span><br><span class="line">平面聚类算法：</span><br><span class="line">①找到四边形的中心0</span><br><span class="line">②向量计算0P=a*OM+b*OM;得到a,b</span><br><span class="line">③根据a,b的值范围，判断P属于哪个区域</span><br><span class="line"></span><br><span class="line">5：使用到的数据增强方式:</span><br><span class="line">①. Random horizon flip with a probability of 0.5.</span><br><span class="line">②. Random resize the height and width of images to 640-</span><br><span class="line">2560 individually, without keeping the original aspect</span><br><span class="line">ratio.</span><br><span class="line">③Random select one 640 × 640 crop region from the</span><br><span class="line">resized image.</span><br><span class="line"></span><br><span class="line">6：使用二进制差值上采样替代反卷积</span><br><span class="line">①因为反卷积之后会产生过多的棋盘纹，不利于后续回归</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;paper&quot;&gt;&lt;a href=&quot;#paper&quot; class=&quot;headerlink&quot; title=&quot;paper&quot;&gt;&lt;/a&gt;paper&lt;/h3&gt;&lt;p&gt;1：&lt;strong&gt;Pyramid Mask Text Detector&lt;/strong&gt; (2019)&lt;/p&gt;
&lt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>PyTorch</title>
    <link href="https://yanyubing.xyz/2020/05/31/PyTorch/"/>
    <id>https://yanyubing.xyz/2020/05/31/PyTorch/</id>
    <published>2020-05-31T13:01:12.594Z</published>
    <updated>2020-05-31T13:28:51.882Z</updated>
    
    <content type="html"><![CDATA[<p>PyTorch官方书籍deep-learning-with-pytorch</p><p>1:深度学习框架对比</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Theano是最早的深度学习框架之一，已停止积极发展。</span><br><span class="line">TensorFlow：</span><br><span class="line"></span><br><span class="line">完全消耗Keras，将其升级为一流的API</span><br><span class="line">提供了立即执行的“渴望模式”</span><br><span class="line">宣布TF 2.0将默认启用eager模式</span><br><span class="line">PyTorch：</span><br><span class="line"></span><br><span class="line">消耗了Caffe2作为后端</span><br><span class="line">替换了基于Lua的Torch项目中重复使用的大多数低级代码</span><br><span class="line">增加了对ONNX的支持，这是一种与供应商无关的模型描述和交换格式</span><br><span class="line">添加了名为TorchScript的延迟执行“图形模式”运行时</span><br><span class="line">发行版本1.0</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;PyTorch官方书籍deep-learning-with-pytorch&lt;/p&gt;
&lt;p&gt;1:深度学习框架对比&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span clas
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>机器学习记录(已掌握)</title>
    <link href="https://yanyubing.xyz/2020/05/31/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E5%B7%B2%E6%8E%8C%E6%8F%A1)/"/>
    <id>https://yanyubing.xyz/2020/05/31/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95(%E5%B7%B2%E6%8E%8C%E6%8F%A1)/</id>
    <published>2020-05-31T11:30:27.688Z</published>
    <updated>2020-05-31T12:36:55.738Z</updated>
    
    <content type="html"><![CDATA[<p>1：一元线性回归</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">适用于一个特征：x对应的标签y的数据集</span><br><span class="line"></span><br><span class="line">y=wx+b：找到最优的w和b使得代价函数最小</span><br></pre></td></tr></table></figure><p>2：损失函数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">最小二乘法</span><br><span class="line">代价函数j=预测值h减去真实值y的平方求和，除以2倍的样本个数m</span><br><span class="line"></span><br><span class="line">常见的损失函数种类：https://zhuanlan.zhihu.com/p/47202768</span><br></pre></td></tr></table></figure><p>3： 梯度下降（优化算法）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">对损失函数求导，往斜率反方向更新值，得到局部最优解。</span><br><span class="line">1：为什么不直接对损失函数求导取倒数为0的点？倒数为0只能说明斜率为0，不能说明是最小值，或者极小值</span><br><span class="line"></span><br><span class="line">2：带动量的梯度下降可以越过鞍部</span><br><span class="line"></span><br><span class="line">3:问题点是，非凸函数难以找到全局最小值</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1：一元线性回归&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>得到ROI区域总结</title>
    <link href="https://yanyubing.xyz/2020/05/25/%E5%BE%97%E5%88%B0ROI%E5%8C%BA%E5%9F%9F%E6%80%BB%E7%BB%93/"/>
    <id>https://yanyubing.xyz/2020/05/25/%E5%BE%97%E5%88%B0ROI%E5%8C%BA%E5%9F%9F%E6%80%BB%E7%BB%93/</id>
    <published>2020-05-25T09:42:37.290Z</published>
    <updated>2020-05-25T09:43:20.898Z</updated>
    
    <content type="html"><![CDATA[<p>1：基于颜色值不同的ROI区域</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"># 检测答案区域,根据颜色判断,并且保存区域</span><br><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 判断像素是不是红色</span><br><span class="line">def isRed(pixel):</span><br><span class="line">    # 纯红色</span><br><span class="line">    if pixel[2] &gt; pixel[0] + 100 and pixel[2] &gt; pixel[1] + 100 and (pixel[2] &gt; 200):</span><br><span class="line">        return &apos;t&apos;</span><br><span class="line">    else:</span><br><span class="line">        return &apos;f&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># ①除了红色区域的所有区域转为白色</span><br><span class="line">def getRedPicture(path):</span><br><span class="line">    image = cv2.imread(path)</span><br><span class="line">    h, w, c = image.shape</span><br><span class="line"></span><br><span class="line">    for i in range(w):</span><br><span class="line">        for j in range(h):</span><br><span class="line">            pixel = image[j][i]</span><br><span class="line">            if isRed(pixel) == &apos;f&apos;:</span><br><span class="line">                pixel[:] = 255</span><br><span class="line">    print(path, &apos;finished---getRedPicture&apos;)</span><br><span class="line">    # 图片的下方一行需要手动去除</span><br><span class="line">    image[3100:, :] = 255</span><br><span class="line">    return image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取轮廓的最上下两个点，只需要根据上下两个点的距离过滤</span><br><span class="line">def getContours_XY_dots(cnt):</span><br><span class="line">    # 储存x坐标</span><br><span class="line">    xs = []</span><br><span class="line">    # 储存y坐标</span><br><span class="line">    ys = []</span><br><span class="line">    for c in cnt:</span><br><span class="line">        ys.append(c[0][1])</span><br><span class="line">        xs.append(c[0][0])</span><br><span class="line">    xs.sort(key=int)</span><br><span class="line">    ys.sort(key=int)</span><br><span class="line"></span><br><span class="line">    min_x = xs[0]</span><br><span class="line">    max_x = xs[-1]</span><br><span class="line">    max_y = ys[-1]</span><br><span class="line">    min_y = ys[0]</span><br><span class="line">    return min_x, max_x, min_y, max_y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取红色区域的定位</span><br><span class="line">def getRedLocation(path):</span><br><span class="line">    # 获取红色图片</span><br><span class="line">    img = getRedPicture(path)</span><br><span class="line"></span><br><span class="line">    # 转换为灰度</span><br><span class="line">    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)</span><br><span class="line"></span><br><span class="line">    # 二值化</span><br><span class="line">    _, thresh1 = cv2.threshold(img_gray, 200, 255, cv2.THRESH_BINARY)</span><br><span class="line">    # 黑色和白色对调，因为膨胀或者腐蚀的前景都是白色</span><br><span class="line">    dst = 255 - thresh1</span><br><span class="line">    # 膨胀核</span><br><span class="line">    kernel = np.ones((5, 5), np.uint8)</span><br><span class="line">    # 膨胀之后的图片</span><br><span class="line">    dilation = cv2.dilate(dst, kernel, iterations=5)  # 膨胀</span><br><span class="line">    # 查找轮廓</span><br><span class="line">    _, contours, hierarchy = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)</span><br><span class="line">    # 对轮廓进行判断,①轮廓的高取值范围，②轮廓的面积取值范围，最后添加到最终的轮廓中</span><br><span class="line">    res_contours = []  # 储存需要的轮廓</span><br><span class="line">    for index, cnt in enumerate(contours):</span><br><span class="line">        area = cv2.contourArea(cnt)</span><br><span class="line">        print(index, &apos;--------&apos;, area)</span><br><span class="line">        min_x, max_x, min_y, max_y = getContours_XY_dots(cnt)</span><br><span class="line">        yLength = max_y - min_y</span><br><span class="line">        print(yLength)</span><br><span class="line">        # 这里范围可调</span><br><span class="line">        if area &gt; 500 and area &lt; 20000 and yLength &gt; 10 and yLength &lt; 70:</span><br><span class="line">            res_contours.append(cnt)</span><br><span class="line"></span><br><span class="line">    res = cv2.drawContours(img, res_contours, -1, (0, 255, 0), 10)</span><br><span class="line"></span><br><span class="line">    # 遍历最终的轮廓，得到最小x,y,最大x,y的坐标</span><br><span class="line">    # 储存一张图片的所有box</span><br><span class="line">    bboxes = []</span><br><span class="line">    for res in res_contours:</span><br><span class="line">        min_x, max_x, min_y, max_y = getContours_XY_dots(res)</span><br><span class="line">        box = min_x, max_x, min_y, max_y</span><br><span class="line">        bboxes.append(box)</span><br><span class="line">    return bboxes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 图片地址</span><br><span class="line">def saveAllRedLocation(path):</span><br><span class="line">    image = cv2.imread(path)</span><br><span class="line">    bboxes = getRedLocation(path)</span><br><span class="line">    # bboxes排序，根据纵坐标</span><br><span class="line">    bboxes.sort(key=lambda x: int(x[2]))</span><br><span class="line">    index = 0</span><br><span class="line">    # 储存每个box的图片</span><br><span class="line">    for box in bboxes:</span><br><span class="line">        index += 1</span><br><span class="line">        path_out = &apos;red/&apos; + path.split(&apos;/&apos;)[1].split(&apos;.&apos;)[0] + &apos;_&apos; + str(index) + &apos;.jpg&apos;</span><br><span class="line">        print(path_out)</span><br><span class="line">        cv2.imwrite(path_out, image[box[2]:box[3], box[0]:box[1]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">path = &apos;books&apos;</span><br><span class="line">files = os.listdir(path)</span><br><span class="line"># 储存整本书的所有红色区域</span><br><span class="line">for file in files:</span><br><span class="line">    pathname = path + &apos;/&apos; + file</span><br><span class="line">    saveAllRedLocation(pathname)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1：基于颜色值不同的ROI区域&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>倾斜校正相关总结对比</title>
    <link href="https://yanyubing.xyz/2020/05/22/%E5%80%BE%E6%96%9C%E6%A0%A1%E6%AD%A3%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%E5%AF%B9%E6%AF%94/"/>
    <id>https://yanyubing.xyz/2020/05/22/%E5%80%BE%E6%96%9C%E6%A0%A1%E6%AD%A3%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%E5%AF%B9%E6%AF%94/</id>
    <published>2020-05-22T02:30:15.814Z</published>
    <updated>2020-06-28T11:44:48.173Z</updated>
    
    <content type="html"><![CDATA[<h3 id="倾斜校正相关总结对比"><a href="#倾斜校正相关总结对比" class="headerlink" title="倾斜校正相关总结对比"></a>倾斜校正相关总结对比</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">以下一种方式即可：核心逻辑都是找到倾斜角度，然后校正；根据最小外接矩形得到的图形，可能会得到误差较大（四边形的选取很重要，思路有①横向膨胀②ocr定位文字区域获取）；找到多个角度之后取直方图最优区间的平均值，</span><br></pre></td></tr></table></figure><p>方案1：最小外接矩形→倾斜角度→得到变换矩阵→纺射变换得到校正图</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">地址：https://www.pyimagesearch.com/2017/02/20/text-skew-correction-opencv-python/</span><br><span class="line"></span><br><span class="line">效果：书本的校正效果95分</span><br><span class="line">困难点：通过局部图片得到倾斜角度，这个局部图片的确定，如果杂点过多，很难得到角度</span><br><span class="line">困难点的解决方案：找到高度的h1,h2；h1整行为白色（往下一个像素就会有黑色）,h2整行也为白色（往上一行就会有黑色），然后截取；</span><br></pre></td></tr></table></figure><p>代码:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"># import the necessary packages</span><br><span class="line">import numpy as np</span><br><span class="line">import argparse</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 得到目标区域,num为起始位置的区域得分&lt;30</span><br><span class="line">def getLocation(image, n):</span><br><span class="line">    h, w, c = image.shape</span><br><span class="line">    # 转成灰度和二值图</span><br><span class="line">    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    thresh = cv2.threshold(gray, 127, 255,</span><br><span class="line">                           cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]</span><br><span class="line">    # 定义两个高度，第一个和最后一个就是高度起始和结束</span><br><span class="line">    h_temp = []</span><br><span class="line">    # 找到高度的h1,h2；h1整行为白色（往下一个像素就会有黑色）,h2整行也为白色（往上一行就会有黑色），然后截取</span><br><span class="line">    start = 0</span><br><span class="line">    # h/5开始，找到黑色区域起始位置</span><br><span class="line">    for i in range(int(n * h / 30), h, 2):</span><br><span class="line">        # 每一条初始化像素值个数</span><br><span class="line">        global num</span><br><span class="line">        num = 0</span><br><span class="line">        for j in range(w):</span><br><span class="line">            if thresh[i][j] &lt; 100:</span><br><span class="line">                # 开始有黑色点</span><br><span class="line">                # 像素值个数+1</span><br><span class="line">                num += 1</span><br><span class="line">        # 黑点个数为10</span><br><span class="line">        if 0 &lt; num &lt; 10:</span><br><span class="line">            start = i</span><br><span class="line">            break</span><br><span class="line"></span><br><span class="line">    # 已经没有黑色区域的时候，遍历到全白</span><br><span class="line">    if num == 0:</span><br><span class="line">        start = int(n * h / 30)</span><br><span class="line"></span><br><span class="line">    # 白色区域开始遍历</span><br><span class="line">    for i in range(start, h, 2):</span><br><span class="line">        # 每一条初始化像素值个数</span><br><span class="line">        num = 0</span><br><span class="line">        for j in range(w):</span><br><span class="line">            if thresh[i][j] &lt; 100:</span><br><span class="line">                # 开始有黑色点</span><br><span class="line">                # 像素值个数+1</span><br><span class="line">                num += 1</span><br><span class="line">        if num &gt; 0:</span><br><span class="line">            h_temp.append(i)</span><br><span class="line"></span><br><span class="line">        if num == 0 and len(h_temp) &gt; 0:</span><br><span class="line">            # 证明已经经过了黑色区域，结束循环</span><br><span class="line">            break</span><br><span class="line">    if len(h_temp) &gt; 0:</span><br><span class="line">        h_temp.sort(key=int)</span><br><span class="line"></span><br><span class="line">        h1 = h_temp[0]</span><br><span class="line">        h2 = h_temp[-1]</span><br><span class="line">        # 取值</span><br><span class="line">        imagenew = image[h1:h2, :]</span><br><span class="line">        # 纵向上下拼接20个像素的白色区域</span><br><span class="line">        image_temp = np.zeros((10, imagenew.shape[1], 3), np.uint8)</span><br><span class="line">        image_temp[:] = 255</span><br><span class="line">        # 拼接结果</span><br><span class="line">        result = np.vstack([image_temp, imagenew, image_temp])</span><br><span class="line">    else:</span><br><span class="line">        result = np.zeros((10, 10, 3), np.uint8)</span><br><span class="line">    return result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 传入图片地址，获取角度</span><br><span class="line">def getAngle(image, n):</span><br><span class="line">    # 获取目标区域</span><br><span class="line">    location = getLocation(image, n)</span><br><span class="line"></span><br><span class="line">    # location转成灰度，得到角度</span><br><span class="line">    gray = cv2.cvtColor(location, cv2.COLOR_BGR2GRAY)</span><br><span class="line">    gray = cv2.bitwise_not(gray)</span><br><span class="line">    # 二值化</span><br><span class="line">    thresh = cv2.threshold(gray, 0, 255,</span><br><span class="line">                           cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]</span><br><span class="line"></span><br><span class="line">    coords = np.column_stack(np.where(thresh &gt; 0))</span><br><span class="line">    angle = cv2.minAreaRect(coords)[-1]</span><br><span class="line">    if angle &lt; -45:</span><br><span class="line">        angle = -(90 + angle)</span><br><span class="line">    else:</span><br><span class="line">        angle = -angle</span><br><span class="line">    print(&apos;angle:&apos;, angle)</span><br><span class="line"></span><br><span class="line">    return angle</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取最终的角度</span><br><span class="line">def getResAngle(image):</span><br><span class="line">    angles = []</span><br><span class="line">    for n in range(30):</span><br><span class="line">        angle_temp = getAngle(image, n)</span><br><span class="line">        angles.append(angle_temp)</span><br><span class="line"></span><br><span class="line">    # 角度排序</span><br><span class="line">    angles.sort()</span><br><span class="line">    # 计算大于0和小于0的倾斜角度</span><br><span class="line">    Asum = 0</span><br><span class="line">    asum = 0</span><br><span class="line">    for a in angles:</span><br><span class="line">        # 判断角度大于0和小于0的个数:用来确定最终的偏斜角度</span><br><span class="line">        if a &gt; 0:</span><br><span class="line">            Asum += 1</span><br><span class="line">        if a &lt; 0:</span><br><span class="line">            asum += 1</span><br><span class="line">        # 去除异常值的点</span><br><span class="line">        if a &gt; 15 or a &lt; -15:</span><br><span class="line">            angles.remove(a)</span><br><span class="line">    # 获取最终角度的值</span><br><span class="line">    if Asum &gt; asum:</span><br><span class="line">        angleRes = angles[-1]</span><br><span class="line">    else:</span><br><span class="line">        angleRes = angles[0]</span><br><span class="line">    print(&apos;最后取得的角度为&apos;, angleRes)</span><br><span class="line">    return angleRes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 校正图片</span><br><span class="line">def correctSkew(image, angle):</span><br><span class="line">    # rotate the image to deskew it</span><br><span class="line">    (h, w) = image.shape[:2]</span><br><span class="line">    center = (w // 2, h // 2)</span><br><span class="line">    M = cv2.getRotationMatrix2D(center, angle, 1.0)</span><br><span class="line">    rotated = cv2.warpAffine(image, M, (w, h),</span><br><span class="line">                             flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)</span><br><span class="line"></span><br><span class="line">    return rotated</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">imagepath = &apos;image/2.jpg&apos;</span><br><span class="line">image = cv2.imread(imagepath)</span><br><span class="line">angleRes = getResAngle(image)</span><br><span class="line"></span><br><span class="line"># 校正</span><br><span class="line">rotated = correctSkew(image, angleRes)</span><br><span class="line">cv2.imwrite(&apos;rotate.jpg&apos;, rotated)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;倾斜校正相关总结对比&quot;&gt;&lt;a href=&quot;#倾斜校正相关总结对比&quot; class=&quot;headerlink&quot; title=&quot;倾斜校正相关总结对比&quot;&gt;&lt;/a&gt;倾斜校正相关总结对比&lt;/h3&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;t
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>OCR相关总结对比</title>
    <link href="https://yanyubing.xyz/2020/05/13/OCR%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%E5%AF%B9%E6%AF%94/"/>
    <id>https://yanyubing.xyz/2020/05/13/OCR%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%E5%AF%B9%E6%AF%94/</id>
    <published>2020-05-13T03:01:04.332Z</published>
    <updated>2020-06-23T08:09:23.712Z</updated>
    
    <content type="html"><![CDATA[<p>OCR总结和对比；实现书本的题干提取</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">总结：OCR对于识别的准确率基本可以满足要求，只是前提是定位的准确和一些预处理操作以及对应不同场景的不同处理方案的搭配（如中英文不同，特殊字符的处理等等）</span><br></pre></td></tr></table></figure><p>1：百度ocr</p><p>1.1:特点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1：付费</span><br><span class="line">2：偶尔报错</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;C:/Users/yanyubing/Desktop/zex/010_GUI/ocr/ocr_Topic.py&quot;, line 112, in &lt;module&gt;</span><br><span class="line">    results = client.general(image)[&quot;words_result&quot;]</span><br><span class="line">KeyError: &apos;words_result&apos;</span><br><span class="line">3：网络请求</span><br><span class="line">4：准确率基本满足要求</span><br><span class="line">5：识别数字很烂</span><br><span class="line"></span><br><span class="line">总结：可以满足生产需求</span><br></pre></td></tr></table></figure><p>1.2:代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"># 题干的ocr</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import cv2</span><br><span class="line">from aip import AipOcr</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot; 你的 APPID AK SK &quot;&quot;&quot;</span><br><span class="line">#这里有更改</span><br><span class="line">APP_ID = &apos;198605*&apos;</span><br><span class="line">API_KEY = &apos;R7fGy5Yh900UQKXmlppPc69d&apos;</span><br><span class="line">SECRET_KEY = &apos;v2OKtKnslZq34qNQKQ4dZCGwjONxK9xY&apos;</span><br><span class="line"></span><br><span class="line">client = AipOcr(APP_ID, API_KEY, SECRET_KEY)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_file_content(filePath):</span><br><span class="line">    with open(filePath, &apos;rb&apos;) as fp:</span><br><span class="line">        return fp.read()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># step1：获取定位框的最左排序个数</span><br><span class="line"># num:输入获取的个数</span><br><span class="line">def getTopic(num):</span><br><span class="line">    # 没有题干的提前结束</span><br><span class="line">    if num == 0:</span><br><span class="line">        return</span><br><span class="line">    global str_temp</span><br><span class="line"></span><br><span class="line">    # 获取所有识别的集合</span><br><span class="line">    left_temp = []</span><br><span class="line"></span><br><span class="line">    for result in results:</span><br><span class="line">        # 文本</span><br><span class="line">        text = result[&quot;words&quot;]</span><br><span class="line"></span><br><span class="line">        # 定位</span><br><span class="line">        location = result[&quot;location&quot;]</span><br><span class="line"></span><br><span class="line">        # 得到字段：最左边，高度定位，和文本信息</span><br><span class="line">        strtemp = str(location[&apos;left&apos;]) + &apos;,&apos; + str(location[&apos;top&apos;]) + &apos;,&apos; + text</span><br><span class="line"></span><br><span class="line">        # 添加</span><br><span class="line">        left_temp.append(strtemp)</span><br><span class="line"></span><br><span class="line">    # 获取需要的集合,根据左边的位置排序</span><br><span class="line">    lefts = []</span><br><span class="line">    while 1:</span><br><span class="line">        # 获取最小的x值</span><br><span class="line">        min_x = 10000</span><br><span class="line">        for temp in left_temp:</span><br><span class="line">            if int(temp.split(&apos;,&apos;)[0]) &lt; min_x:</span><br><span class="line">                min_x = int(temp.split(&apos;,&apos;)[0])</span><br><span class="line">                str_temp = temp</span><br><span class="line"></span><br><span class="line">        lefts.append(str_temp)</span><br><span class="line">        # print(str_temp)</span><br><span class="line">        left_temp.remove(str_temp)</span><br><span class="line"></span><br><span class="line">        if len(lefts) == num:</span><br><span class="line">            break</span><br><span class="line">    # 左边位置排序之后再根据上下位置排序</span><br><span class="line">    result = []</span><br><span class="line"></span><br><span class="line">    while 1:</span><br><span class="line">        # 获取最小的x值</span><br><span class="line">        min_y = 10000</span><br><span class="line">        for temp in lefts:</span><br><span class="line">            if int(temp.split(&apos;,&apos;)[1]) &lt; min_y:</span><br><span class="line">                min_y = int(temp.split(&apos;,&apos;)[1])</span><br><span class="line">                str_temp = temp</span><br><span class="line"></span><br><span class="line">        result.append(str_temp)</span><br><span class="line">        # print(str_temp)</span><br><span class="line">        lefts.remove(str_temp)</span><br><span class="line"></span><br><span class="line">        if len(lefts) == 0:</span><br><span class="line">            # 过滤完全结束</span><br><span class="line">            break</span><br><span class="line"></span><br><span class="line">    return result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取所有书名，按照顺序排序</span><br><span class="line">def getBookNames(path):</span><br><span class="line">    booknames = []</span><br><span class="line">    filesname = os.listdir(path)</span><br><span class="line">    for i in range(len(filesname)):</span><br><span class="line">        name = path + &apos;/&apos; + str(i + 1) + &apos;.jpg&apos;</span><br><span class="line">        booknames.append(name)</span><br><span class="line">    return booknames</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 输入图片所在目录</span><br><span class="line">dir = input(&apos;输入图片所在文件夹:\n&apos;)</span><br><span class="line"></span><br><span class="line"># 获取所有的书名</span><br><span class="line">booknames = getBookNames(dir)</span><br><span class="line"></span><br><span class="line"># 输入对应要获取题干的个数，</span><br><span class="line"># nums = []</span><br><span class="line">nums = input(&apos;连续输入页码题干个数\n&apos;)</span><br><span class="line"># for bookname in booknames:</span><br><span class="line">#     num = int(input(&apos;输入需要获取页面:&apos; + bookname + &apos;的题干的个数:\n&apos;))</span><br><span class="line">#     nums.append(num)</span><br><span class="line"></span><br><span class="line"># 整本书的结果</span><br><span class="line">allResults = []</span><br><span class="line"># 遍历所有书</span><br><span class="line">for index in range(len(booknames)):</span><br><span class="line">    image = get_file_content(booknames[index])</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot; 调用通用文字识别, 图片参数为本地图片 &quot;&quot;&quot;</span><br><span class="line">    results = client.general(image)[&quot;words_result&quot;]</span><br><span class="line"></span><br><span class="line">    # 一页书的结果</span><br><span class="line">    result = getTopic(int(nums[index]))</span><br><span class="line">    print(&quot;----&quot;, index, &quot;----&quot;)</span><br><span class="line">    for re in result:</span><br><span class="line">        # 添加页码信息</span><br><span class="line">        r = re + &apos;,&apos; + booknames[index]</span><br><span class="line">        # 整本书的结果</span><br><span class="line">        allResults.append(result)</span><br><span class="line"></span><br><span class="line"># 查看整本书的结果</span><br><span class="line">for result in allResults:</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure><p>2：pse+rcnn</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1：免费</span><br><span class="line">2：需要编译：本人使用vs2017+python3.7编译</span><br><span class="line">3：可以识别竖向文字，斜向文字也可以</span><br><span class="line">4：识别通用文字效果不太好:</span><br><span class="line">5：对于英文识别错误率高</span><br><span class="line">对于英文：误识，漏识严重</span><br><span class="line">对于中文:也存在一定的误识和漏识</span><br><span class="line">github地址：https://github.com/ouyanghuiyu/chineseocr_lite</span><br><span class="line"></span><br><span class="line">总结：无法满足生产需求。①定位有尺寸压缩，并且定位有偏差；②识别有误识</span><br><span class="line"></span><br><span class="line">解决方案：总体而言是因为pse定位存在误差，导致识别上的错误；使用自己的mark去定位，然后识别，准确率可以达到99%</span><br><span class="line">①取mark一定100%准确</span><br><span class="line">②根据mark去location一定100%准确</span><br><span class="line">③识别准确率才能到达极限</span><br><span class="line">④识别数字可以，识别英文很烂</span><br></pre></td></tr></table></figure><p>3：ocr.space</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">特点：</span><br><span class="line">①需要翻墙</span><br><span class="line">②多种语言和特殊字符的支持</span><br><span class="line">③使用简洁：但是有限制</span><br></pre></td></tr></table></figure><p>4： CRAFT(英文字符识别)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">地址：https://github.com/clovaai/CRAFT-pytorch+https://github.com/clovaai/deep-text-recognition-benchmark</span><br><span class="line">原理：CRAFT+deep-text-recognition(检测+识别)</span><br><span class="line">特点：</span><br><span class="line">①英文识别能力强，单个单词准确率达到99%</span><br><span class="line">②定位准确：切割单个单词准确率高99%</span><br><span class="line">③需要自己糅合</span><br></pre></td></tr></table></figure><p>4.1：定位</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"># 定位和识别一体</span><br><span class="line">import argparse</span><br><span class="line">import os</span><br><span class="line">import shutil</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">from getLocations import getLocation</span><br><span class="line"></span><br><span class="line"># 存放txt的文件夹</span><br><span class="line">result_folder = &apos;txtResult/&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取txt文件</span><br><span class="line">def getTextFile(path):</span><br><span class="line">    # 存放定位之后的文件路径</span><br><span class="line"></span><br><span class="line">    # 存在结果文件夹</span><br><span class="line">    if os.path.exists(result_folder):</span><br><span class="line">        # 删除文件夹(非空)</span><br><span class="line">        shutil.rmtree(result_folder)</span><br><span class="line">    # 运行，会产生位置信息的txt文件</span><br><span class="line">    getLocation(path, result_folder)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取整个文件夹识别之后的集合</span><br><span class="line"># 格式为： &apos;&apos;&apos;文件路径：value&apos;&apos;&apos;</span><br><span class="line">def saveLocation(pathin, pathout):</span><br><span class="line">    if not os.path.exists(pathout):</span><br><span class="line">        os.mkdir(pathout)</span><br><span class="line">    # 获取原文件夹底下的文件列表</span><br><span class="line">    files = os.listdir(pathin)</span><br><span class="line">    # 遍历列表</span><br><span class="line">    for file in files:</span><br><span class="line">        # 获取不带后缀的文件名</span><br><span class="line">        filename = file.split(&apos;.&apos;)[0]</span><br><span class="line">        # 图片文件路径</span><br><span class="line">        ImgFilepath = pathin + &apos;/&apos; + file</span><br><span class="line">        # 读取图片</span><br><span class="line">        image = cv2.imread(ImgFilepath)</span><br><span class="line">        # 构建lines集合储存txt文件的lines</span><br><span class="line">        lines = []</span><br><span class="line">        # txt文件路径</span><br><span class="line">        TxtFilepath = result_folder + &apos;/&apos; + filename + &apos;.txt&apos;</span><br><span class="line">        # 读取txt文件</span><br><span class="line">        f = open(TxtFilepath)</span><br><span class="line">        line = f.readlines()</span><br><span class="line">        for li in line:</span><br><span class="line">            lines.append(li)</span><br><span class="line">        # 记录第几条数据</span><br><span class="line">        index = 0</span><br><span class="line">        # 去除多条数据中的空格</span><br><span class="line">        lines = [x.strip() for x in lines if x.strip() != &apos;&apos;]</span><br><span class="line">        # 根据横坐标位置排序，为了后面便于拼接</span><br><span class="line">        lines.sort(key=lambda x: int(x.split(&apos;,&apos;)[0]))</span><br><span class="line">        # 遍历lines，得到坐标位置</span><br><span class="line">        for line in lines:</span><br><span class="line">            # 除去每条数据中的空格</span><br><span class="line">            line = line[:-1]</span><br><span class="line">            index += 1</span><br><span class="line">            ls = line.split(&apos;,&apos;)</span><br><span class="line">            # 判断坐标位置的大小，得到左上和右下坐标的矩形框</span><br><span class="line">            # 左上</span><br><span class="line">            lt = (min(ls[0], ls[6]), min(ls[1], ls[3]))</span><br><span class="line"></span><br><span class="line">            # 右下</span><br><span class="line">            rd = (max(ls[4], ls[2]), max(ls[5], ls[7]))</span><br><span class="line">            # 得到定位之后的单个单词位置</span><br><span class="line">            imagetemp = image[int(lt[1]):int(rd[1]), int(lt[0]):int(rd[0])]</span><br><span class="line">            # 文件路径名，如1_1，则是第一个图的第一个单词</span><br><span class="line">            path_new = pathout + &apos;/&apos; + filename + &apos;_&apos; + str(index) + &apos;.jpg&apos;</span><br><span class="line">            cv2.imwrite(path_new, imagetemp)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 预处理文件处理,修改path</span><br><span class="line">path = &apos;two&apos;</span><br><span class="line">pathin = path</span><br><span class="line">pathout = path + &apos;out&apos;</span><br><span class="line">getTextFile(path)</span><br><span class="line"></span><br><span class="line">saveLocation(pathin, pathout)</span><br></pre></td></tr></table></figure><p>4.2:识别</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br></pre></td><td class="code"><pre><span class="line">import string</span><br><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torch.backends.cudnn as cudnn</span><br><span class="line">import torch.utils.data</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line">from utils import CTCLabelConverter, AttnLabelConverter</span><br><span class="line">from dataset import RawDataset, AlignCollate</span><br><span class="line">from model import Model</span><br><span class="line"></span><br><span class="line">device = torch.device(&apos;cuda&apos; if torch.cuda.is_available() else &apos;cpu&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def demo(opt):</span><br><span class="line">    # 储存所有的文本信息</span><br><span class="line">    # 格式：图片名称：值</span><br><span class="line">    values = []</span><br><span class="line">    # 临时存储，需要变换</span><br><span class="line">    valuetemp = []</span><br><span class="line">    &quot;&quot;&quot; model configuration &quot;&quot;&quot;</span><br><span class="line">    # CTC模型</span><br><span class="line">    if &apos;CTC&apos; in opt.Prediction:</span><br><span class="line">        converter = CTCLabelConverter(opt.character)</span><br><span class="line">    else:</span><br><span class="line">        converter = AttnLabelConverter(opt.character)</span><br><span class="line">    opt.num_class = len(converter.character)</span><br><span class="line"></span><br><span class="line">    if opt.rgb:</span><br><span class="line">        opt.input_channel = 3</span><br><span class="line">    model = Model(opt)</span><br><span class="line">    print(&apos;model input parameters&apos;, opt.imgH, opt.imgW, opt.num_fiducial, opt.input_channel, opt.output_channel,</span><br><span class="line">          opt.hidden_size, opt.num_class, opt.batch_max_length, opt.Transformation, opt.FeatureExtraction,</span><br><span class="line">          opt.SequenceModeling, opt.Prediction)</span><br><span class="line">    model = torch.nn.DataParallel(model).to(device)</span><br><span class="line"></span><br><span class="line">    # load model</span><br><span class="line">    print(&apos;loading pretrained model from %s&apos; % opt.saved_model)</span><br><span class="line">    model.load_state_dict(torch.load(opt.saved_model, map_location=device))</span><br><span class="line"></span><br><span class="line">    # prepare data. two demo images from https://github.com/bgshih/crnn#run-demo</span><br><span class="line">    AlignCollate_demo = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD)</span><br><span class="line">    # 加载数据目录</span><br><span class="line">    demo_data = RawDataset(root=opt.image_folder, opt=opt)  # use RawDataset</span><br><span class="line">    #</span><br><span class="line">    demo_loader = torch.utils.data.DataLoader(</span><br><span class="line">        demo_data, batch_size=opt.batch_size,</span><br><span class="line">        shuffle=False,</span><br><span class="line">        num_workers=int(opt.workers),</span><br><span class="line">        collate_fn=AlignCollate_demo, pin_memory=True)</span><br><span class="line"></span><br><span class="line">    # predict</span><br><span class="line">    model.eval()</span><br><span class="line"></span><br><span class="line">    with torch.no_grad():</span><br><span class="line"></span><br><span class="line">        # image_path_list为文件夹列表</span><br><span class="line">        for image_tensors, image_path_list in demo_loader:</span><br><span class="line"></span><br><span class="line">            batch_size = image_tensors.size(0)</span><br><span class="line"></span><br><span class="line">            image = image_tensors.to(device)</span><br><span class="line"></span><br><span class="line">            # For max length prediction</span><br><span class="line">            length_for_pred = torch.IntTensor([opt.batch_max_length] * batch_size).to(device)</span><br><span class="line"></span><br><span class="line">            text_for_pred = torch.LongTensor(batch_size, opt.batch_max_length + 1).fill_(0).to(device)</span><br><span class="line"></span><br><span class="line">            if &apos;CTC&apos; in opt.Prediction:</span><br><span class="line">                preds = model(image, text_for_pred)</span><br><span class="line"></span><br><span class="line">                # Select max probabilty (greedy decoding) then decode index to character</span><br><span class="line">                preds_size = torch.IntTensor([preds.size(1)] * batch_size)</span><br><span class="line">                _, preds_index = preds.max(2)</span><br><span class="line">                preds_index = preds_index.view(-1)</span><br><span class="line">                preds_str = converter.decode(preds_index.data, preds_size.data)</span><br><span class="line"></span><br><span class="line">            else:</span><br><span class="line">                preds = model(image, text_for_pred, is_train=False)</span><br><span class="line"></span><br><span class="line">                # select max probabilty (greedy decoding) then decode index to character</span><br><span class="line">                _, preds_index = preds.max(2)</span><br><span class="line"></span><br><span class="line">                preds_str = converter.decode(preds_index, length_for_pred)</span><br><span class="line"></span><br><span class="line">            log = open(f&apos;./log_demo_result.txt&apos;, &apos;a&apos;)</span><br><span class="line"></span><br><span class="line">            dashed_line = &apos;-&apos; * 80</span><br><span class="line"></span><br><span class="line">            head = f&apos;&#123;&quot;image_path&quot;:25s&#125;\t&#123;&quot;predicted_labels&quot;:25s&#125;\tconfidence score&apos;</span><br><span class="line"></span><br><span class="line">            print(f&apos;&#123;dashed_line&#125;\n&#123;head&#125;\n&#123;dashed_line&#125;&apos;)</span><br><span class="line"></span><br><span class="line">            log.write(f&apos;&#123;dashed_line&#125;\n&#123;head&#125;\n&#123;dashed_line&#125;\n&apos;)</span><br><span class="line"></span><br><span class="line">            preds_prob = F.softmax(preds, dim=2)</span><br><span class="line"></span><br><span class="line">            preds_max_prob, _ = preds_prob.max(dim=2)</span><br><span class="line"></span><br><span class="line">            for img_name, pred, pred_max_prob in zip(image_path_list, preds_str, preds_max_prob):</span><br><span class="line"></span><br><span class="line">                if &apos;Attn&apos; in opt.Prediction:</span><br><span class="line">                    pred_EOS = pred.find(&apos;[s]&apos;)</span><br><span class="line"></span><br><span class="line">                    pred = pred[:pred_EOS]  # prune after &quot;end of sentence&quot; token ([s])</span><br><span class="line"></span><br><span class="line">                    pred_max_prob = pred_max_prob[:pred_EOS]</span><br><span class="line"></span><br><span class="line">                # calculate confidence score (= multiply of pred_max_prob)</span><br><span class="line">                confidence_score = pred_max_prob.cumprod(dim=0)[-1]</span><br><span class="line">                #</span><br><span class="line">                # print(f&apos;&#123;img_name:25s&#125;\t&#123;pred:25s&#125;\t&#123;confidence_score:0.4f&#125;&apos;)</span><br><span class="line">                # 拼接：文件名称:值</span><br><span class="line">                value = img_name + &quot;:&quot; + pred</span><br><span class="line">                valuetemp.append(value)</span><br><span class="line">                log.write(f&apos;&#123;img_name:25s&#125;\t&#123;pred:25s&#125;\t&#123;confidence_score:0.4f&#125;\n&apos;)</span><br><span class="line"></span><br><span class="line">            log.close()</span><br><span class="line"></span><br><span class="line">    # 遍历image_path_list</span><br><span class="line">    for i in image_path_list:</span><br><span class="line">        image_path = i.split(&apos;/&apos;)[1].split(&apos;_&apos;)[0]</span><br><span class="line">        # 开始处理临时储存</span><br><span class="line">        # 用于储存同一种的文件</span><br><span class="line">        onePicture = []</span><br><span class="line">        # 遍历添加</span><br><span class="line">        for v in valuetemp:</span><br><span class="line">            if v.split(&apos;/&apos;)[1].split(&apos;_&apos;)[0] == image_path:</span><br><span class="line">                # 得到一张图片的所有信息</span><br><span class="line">                onePicture.append(v)</span><br><span class="line">        # 根据.jpg的最后一个字符排序</span><br><span class="line">        onePicture.sort(key=lambda x: int(x.split(&apos;.&apos;)[0].split(&apos;_&apos;)[1]))</span><br><span class="line">        # 拼接每张图片</span><br><span class="line">        text = i.split(&apos;/&apos;)[0][:-3] + &apos;/&apos; + i.split(&apos;/&apos;)[1].split(&apos;_&apos;)[0] + &apos;.jpg&apos; + &apos;:&apos;</span><br><span class="line">        # 遍历onePicture</span><br><span class="line">        for o in onePicture:</span><br><span class="line">            text = text + o.split(&apos;:&apos;)[1] + &apos; &apos;</span><br><span class="line">        # 除去尾部空格</span><br><span class="line">        text = text.strip()</span><br><span class="line">        # 拼接完成之后添加</span><br><span class="line">        values.append(text)</span><br><span class="line">    return values</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 识别主程序</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(&apos;--image_folder&apos;, help=&apos;path to image_folder which contains text images&apos;)</span><br><span class="line">    parser.add_argument(&apos;--workers&apos;, type=int, help=&apos;number of data loading workers&apos;, default=4)</span><br><span class="line">    parser.add_argument(&apos;--batch_size&apos;, type=int, default=192, help=&apos;input batch size&apos;)</span><br><span class="line">    parser.add_argument(&apos;--saved_model&apos;, help=&quot;path to saved_model to evaluation&quot;)</span><br><span class="line">    &quot;&quot;&quot; Data processing &quot;&quot;&quot;</span><br><span class="line">    parser.add_argument(&apos;--batch_max_length&apos;, type=int, default=25, help=&apos;maximum-label-length&apos;)</span><br><span class="line">    parser.add_argument(&apos;--imgH&apos;, type=int, default=32, help=&apos;the height of the input image&apos;)</span><br><span class="line">    parser.add_argument(&apos;--imgW&apos;, type=int, default=100, help=&apos;the width of the input image&apos;)</span><br><span class="line">    parser.add_argument(&apos;--rgb&apos;, action=&apos;store_true&apos;, help=&apos;use rgb input&apos;)</span><br><span class="line">    parser.add_argument(&apos;--character&apos;, type=str, default=&apos;0123456789abcdefghijklmnopqrstuvwxyz&apos;, help=&apos;character label&apos;)</span><br><span class="line">    parser.add_argument(&apos;--sensitive&apos;, action=&apos;store_true&apos;, help=&apos;for sensitive character mode&apos;)</span><br><span class="line">    parser.add_argument(&apos;--PAD&apos;, action=&apos;store_true&apos;, help=&apos;whether to keep ratio then pad for image resize&apos;)</span><br><span class="line">    &quot;&quot;&quot; Model Architecture &quot;&quot;&quot;</span><br><span class="line">    parser.add_argument(&apos;--Transformation&apos;, type=str, help=&apos;Transformation stage. None|TPS&apos;)</span><br><span class="line">    parser.add_argument(&apos;--FeatureExtraction&apos;, type=str, help=&apos;FeatureExtraction stage. VGG|RCNN|ResNet&apos;)</span><br><span class="line">    parser.add_argument(&apos;--SequenceModeling&apos;, type=str, help=&apos;SequenceModeling stage. None|BiLSTM&apos;)</span><br><span class="line">    parser.add_argument(&apos;--Prediction&apos;, type=str, help=&apos;Prediction stage. CTC|Attn&apos;)</span><br><span class="line">    parser.add_argument(&apos;--num_fiducial&apos;, type=int, default=20, help=&apos;number of fiducial points of TPS-STN&apos;)</span><br><span class="line">    parser.add_argument(&apos;--input_channel&apos;, type=int, default=1, help=&apos;the number of input channel of Feature extractor&apos;)</span><br><span class="line">    parser.add_argument(&apos;--output_channel&apos;, type=int, default=512,</span><br><span class="line">                        help=&apos;the number of output channel of Feature extractor&apos;)</span><br><span class="line">    parser.add_argument(&apos;--hidden_size&apos;, type=int, default=256, help=&apos;the size of the LSTM hidden state&apos;)</span><br><span class="line"></span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line">    # 更改这里的位置</span><br><span class="line">    opt.image_folder = &apos;twoout/&apos;</span><br><span class="line">    &quot;&quot;&quot; vocab / character number configuration &quot;&quot;&quot;</span><br><span class="line">    if opt.sensitive:</span><br><span class="line">        opt.character = string.printable[:-6]  # same with ASTER setting (use 94 char).</span><br><span class="line"></span><br><span class="line">    cudnn.benchmark = True</span><br><span class="line">    cudnn.deterministic = True</span><br><span class="line">    opt.num_gpu = torch.cuda.device_count()</span><br><span class="line"></span><br><span class="line">    print(opt)</span><br><span class="line">    demo(opt)</span><br><span class="line"></span><br><span class="line">    values = demo(opt)</span><br><span class="line">    # 除去重复元素</span><br><span class="line">    values = list(set(values))</span><br><span class="line">    # 排序</span><br><span class="line">    values.sort(key=lambda x: int(x.split(&apos;/&apos;)[1].split(&apos;.&apos;)[0]))</span><br><span class="line">    for v in values:</span><br><span class="line">        print(v)</span><br></pre></td></tr></table></figure><p>5：paddle_ocr（微型模型，中英文混用，效果略优；通用模型也可以）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1：优势在于部署的时候有微型模型，中英文混用，速度快。</span><br><span class="line">2：适用于对精度要求不是特别高的场合</span><br><span class="line">3：免费</span><br><span class="line">4：部署简单</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;OCR总结和对比；实现书本的题干提取&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td c
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>阿里云函数计算</title>
    <link href="https://yanyubing.xyz/2020/05/06/%E9%98%BF%E9%87%8C%E4%BA%91%E5%87%BD%E6%95%B0%E8%AE%A1%E7%AE%97/"/>
    <id>https://yanyubing.xyz/2020/05/06/%E9%98%BF%E9%87%8C%E4%BA%91%E5%87%BD%E6%95%B0%E8%AE%A1%E7%AE%97/</id>
    <published>2020-05-06T07:06:55.455Z</published>
    <updated>2020-05-07T03:26:05.197Z</updated>
    
    <content type="html"><![CDATA[<p>阿里云函数计算流程总结：基于flask框架的http触发器，完成模板的匹配功能</p><p>1：安装docker，设置开启自启</p><p>2：下载fun <a href="https://github.com/alibaba/funcraft/releases?spm=a2c4g.11186623.2.15.6a3a66een3mFgU" target="_blank" rel="noopener">https://github.com/alibaba/funcraft/releases?spm=a2c4g.11186623.2.15.6a3a66een3mFgU</a> </p><p>3： 在本地创建一个目录test(作为临时目录存放依赖),  然后终端进入到该目录下，把自己配置的yml文件放在该目录下</p><p>4：test目录下运行fun install init    初始化环境为python3，会出现funfile文件</p><p>5：在funfile文件中编写安装的依赖</p><p>6： 执行sudo fun install安装依赖 ，会在test目录下出现.fun文件(拉取镜像过程很慢)</p><p>7：因为torch无法使用funfile安装， 在本地重新创建一个目录，在该目录下执行fun install sbox –runtime python3  –interactive进入沙箱环境 </p><p>8： 执行pip install -t . torch 安装</p><p>9： 安装成功后，把安装的内容复制到项目的.fun/python/lib/python3.6/site-packages 目录下 )</p><p>10：更改flaskapp的入口函数，将test目录底下的所有内容复制放到项目根目录</p><p>11：执行fun deploy -y部署 </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;阿里云函数计算流程总结：基于flask框架的http触发器，完成模板的匹配功能&lt;/p&gt;
&lt;p&gt;1：安装docker，设置开启自启&lt;/p&gt;
&lt;p&gt;2：下载fun &lt;a href=&quot;https://github.com/alibaba/funcraft/releases?spm
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>python_gui</title>
    <link href="https://yanyubing.xyz/2020/05/01/python_gui/"/>
    <id>https://yanyubing.xyz/2020/05/01/python_gui/</id>
    <published>2020-05-01T15:31:31.016Z</published>
    <updated>2020-05-05T07:46:43.407Z</updated>
    
    <content type="html"><![CDATA[<h3 id="PythonGUI-Tkinter"><a href="#PythonGUI-Tkinter" class="headerlink" title="PythonGUI-Tkinter"></a>PythonGUI-Tkinter</h3><p>为了做出可以提供给其他人使用的AI(CV方向)算法程序—实现切割纸张可视化（或者是制作label）</p><p>1：实现图片的切割，储存，检查，目录的创建</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br></pre></td><td class="code"><pre><span class="line"># Radio Buttons:单选框,创建多个单选框</span><br><span class="line">import os</span><br><span class="line">import time</span><br><span class="line">from tkinter import *</span><br><span class="line"></span><br><span class="line"># 初始化窗口</span><br><span class="line">import cv2</span><br><span class="line">from PIL import ImageTk, Image</span><br><span class="line"></span><br><span class="line">root = Tk()</span><br><span class="line">root.title(&apos;GUI_cutPaper&apos;)</span><br><span class="line"></span><br><span class="line"># 创建目录</span><br><span class="line">Label(root, text=&apos;输入要创建的目录路径，如：‘勤学早/Unit1/第一课时/第一大题’&apos;).grid(row=1, column=0)</span><br><span class="line">e_Dir = Entry(root)</span><br><span class="line">e_Dir.grid(row=2, column=0)</span><br><span class="line"></span><br><span class="line"># 输入图片，用来切割</span><br><span class="line">Label(root, text=&apos;输入要切割的图片路径，如：‘book/1.jpg’&apos;).grid(row=3, column=0)</span><br><span class="line">e_book = Entry(root)</span><br><span class="line">e_book.grid(row=4, column=0)</span><br><span class="line"></span><br><span class="line"># 保存图片</span><br><span class="line">Label(root, text=&apos;输入图片的保存路径,如：‘勤学早/Unit1/第一课时/第一大题/1.jpg’&apos;).grid(row=5, column=0)</span><br><span class="line">e_saveImage = Entry(root)</span><br><span class="line">e_saveImage.grid(row=6, column=0)</span><br><span class="line"></span><br><span class="line"># 检测图片</span><br><span class="line">Label(root, text=&apos;输入要检测的目录路径，如：‘勤学早’&apos;).grid(row=7, column=0)</span><br><span class="line">e_check = Entry(root)</span><br><span class="line">e_check.grid(row=8, column=0)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 鼠标事件，获取需要切割点的y坐标</span><br><span class="line">def on_EVENT_LBUTTONDOWN(event, x, y, flags, param):</span><br><span class="line">    if event == cv2.EVENT_LBUTTONDOWN:</span><br><span class="line">        xy = &quot;%d,%d&quot; % (x, y)</span><br><span class="line">        print(xy)</span><br><span class="line">        # cv2.circle(img, (x, y), 1, (255, 0, 0), thickness=-1)</span><br><span class="line">        # cv2.putText(img, xy, (x, y), cv2.FONT_HERSHEY_PLAIN,</span><br><span class="line">        #             1.0, (0, 0, 0), thickness=1)</span><br><span class="line">        dotsY.append(y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 创建目录</span><br><span class="line">def createDir():</span><br><span class="line">    path = e_Dir.get()</span><br><span class="line">    if os.path.exists(path):</span><br><span class="line">        # 提示信息</span><br><span class="line">        Label(root, text=&apos;文件路径已存在，请重新输入&apos;).grid(row=0, column=3)</span><br><span class="line">    else:</span><br><span class="line">        os.makedirs(path)</span><br><span class="line">        Label(root, text=path + &apos; ：创建成功&apos;).grid(row=0, column=3)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 存储切割的图片</span><br><span class="line">def saveImage():</span><br><span class="line">    # 遍历所有的file进行切割</span><br><span class="line">    global dotsY</span><br><span class="line">    dotsY = []</span><br><span class="line">    file_path_in = e_book.get()</span><br><span class="line">    global img</span><br><span class="line"></span><br><span class="line">    if not os.path.exists(file_path_in):</span><br><span class="line">        Label(root, text=file_path_in + &apos;输入的文件路径不存在，请重新输入&apos;).grid(row=0, column=3)</span><br><span class="line">    else:</span><br><span class="line">        img = cv2.imread(file_path_in)</span><br><span class="line">        cv2.namedWindow(&quot;image&quot;, 0)</span><br><span class="line">        cv2.resizeWindow(&apos;image&apos;, 600, 800)</span><br><span class="line">        cv2.imshow(&apos;image&apos;, img)</span><br><span class="line">        cv2.setMouseCallback(&quot;image&quot;, on_EVENT_LBUTTONDOWN)</span><br><span class="line">        cv2.waitKey(0)</span><br><span class="line">        cv2.destroyAllWindows()</span><br><span class="line">    print(&apos;得到的y坐标点为&apos;, dotsY)</span><br><span class="line">    file_path_out = e_saveImage.get()</span><br><span class="line">    if os.path.exists(file_path_out):</span><br><span class="line">        Label(root, text=file_path_in + &apos;输出的文件路径已经存在，请检查&apos;).grid(row=0, column=3)</span><br><span class="line">        return</span><br><span class="line">    image = img[dotsY[0]:dotsY[1], :]</span><br><span class="line">    # 处理带有中文的目录结构</span><br><span class="line">    cv2.imencode(&apos;.jpg&apos;, image)[1].tofile(file_path_out)</span><br><span class="line">    Label(root, text=file_path_out + &apos;文件保存成功&apos;).grid(row=0, column=3)</span><br><span class="line">    time.sleep(1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">index = 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取所有的文件名</span><br><span class="line">def listdir(path, list_name):</span><br><span class="line">    for file in os.listdir(path):</span><br><span class="line">        file_path = os.path.join(path, file)</span><br><span class="line">        if os.path.isdir(file_path):</span><br><span class="line">            listdir(file_path, list_name)</span><br><span class="line">        elif os.path.splitext(file_path)[1] == &apos;.jpg&apos;:</span><br><span class="line">            list_name.append(file_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 储存列表名</span><br><span class="line">listName = []</span><br><span class="line"># 储存所有转换之后的图片</span><br><span class="line">my_images = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 检查图片</span><br><span class="line">def checkImage():</span><br><span class="line">    # 前进，后退，退出按钮</span><br><span class="line">    button_back = Button(root, text=&apos;&lt;&lt;&apos;, command=back)</span><br><span class="line">    button_quit = Button(root, text=&apos;Exit&apos;, command=root.quit)</span><br><span class="line">    button_forward = Button(root, text=&apos;&gt;&gt;&apos;, command=forward)</span><br><span class="line">    button_back.grid(row=11, column=2)</span><br><span class="line">    button_quit.grid(row=11, column=3)</span><br><span class="line">    button_forward.grid(row=11, column=4)</span><br><span class="line"></span><br><span class="line">    global listName</span><br><span class="line"></span><br><span class="line">    path = e_check.get()</span><br><span class="line">    listdir(path, listName)</span><br><span class="line">    print(len(listName))</span><br><span class="line">    global my_images</span><br><span class="line"></span><br><span class="line">    for i in range(len(listName)):</span><br><span class="line">        # 打开图片，图片放入对象，对象再放入screen</span><br><span class="line">        my_img = ImageTk.PhotoImage(Image.open(listName[i]).resize((600, 300)))</span><br><span class="line">        my_images.append(my_img)</span><br><span class="line">    Label(root, image=my_images[0]).grid(row=10, column=3)</span><br><span class="line">    mainloop()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def showImage(index):</span><br><span class="line">    my_label = Label(root, image=my_images[index])</span><br><span class="line">    my_label.grid(row=10, column=3)</span><br><span class="line"></span><br><span class="line">    message = &apos;路径:&apos; + listName[index] + &apos;  Image &apos; + str(index + 1) + &apos; of&apos; + str(len(listName))</span><br><span class="line">    # 添加状态栏(多少张图片，多少个)</span><br><span class="line"></span><br><span class="line">    Label(root, text=message).grid(row=9, column=3)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def back():</span><br><span class="line">    # 申明全局变量</span><br><span class="line">    global index</span><br><span class="line">    index = (index - 1) % len(listName)</span><br><span class="line">    showImage(index)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def forward():</span><br><span class="line">    # 申明全局变量</span><br><span class="line">    global index</span><br><span class="line">    index = (index + 1) % len(listName)</span><br><span class="line">    showImage(index)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 三大组件位置</span><br><span class="line">button_CreateFile = Button(root, text=&quot;createDir&quot;, command=createDir)</span><br><span class="line">button_saveImage = Button(root, text=&quot;saveImage&quot;, command=saveImage)</span><br><span class="line">button_CheckImage = Button(root, text=&quot;checkImage&quot;, command=checkImage)</span><br><span class="line"></span><br><span class="line">button_CreateFile.grid(row=15, column=15, padx=2)</span><br><span class="line">button_saveImage.grid(row=16, column=15, padx=2)</span><br><span class="line">button_CheckImage.grid(row=17, column=15, padx=2)</span><br><span class="line"></span><br><span class="line">Label(root, text=&apos;使用步骤：&apos;).grid(row=12, column=0)</span><br><span class="line">Label(root, text=&apos;1、创建目录:输入需要创建的目录，点击createDir&apos;).grid(row=13, column=0)</span><br><span class="line">Label(root, text=&apos;2、切割图片:&apos;).grid(row=14, column=0)</span><br><span class="line">Label(root, text=&apos;①输入要切割的输入图片路径，以.jpg结尾&apos;).grid(row=15, column=0)</span><br><span class="line">Label(root, text=&apos;②输入需要保存的路径，以.jpg结尾&apos;).grid(row=16, column=0)</span><br><span class="line">Label(root, text=&apos;③点击saveImage进行切割操作&apos;).grid(row=17, column=0)</span><br><span class="line">Label(root, text=&apos;3、检测图片：输入需要检测图片的根目录，点击checkImage&apos;).grid(row=18, column=0)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">root.mainloop()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;PythonGUI-Tkinter&quot;&gt;&lt;a href=&quot;#PythonGUI-Tkinter&quot; class=&quot;headerlink&quot; title=&quot;PythonGUI-Tkinter&quot;&gt;&lt;/a&gt;PythonGUI-Tkinter&lt;/h3&gt;&lt;p&gt;为了做出可以提供给其
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>神经网络学习记录（已掌握）</title>
    <link href="https://yanyubing.xyz/2020/04/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%EF%BC%88%E5%B7%B2%E6%8E%8C%E6%8F%A1%EF%BC%89/"/>
    <id>https://yanyubing.xyz/2020/04/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%EF%BC%88%E5%B7%B2%E6%8E%8C%E6%8F%A1%EF%BC%89/</id>
    <published>2020-04-19T17:02:14.752Z</published>
    <updated>2020-05-15T17:20:51.864Z</updated>
    
    <content type="html"><![CDATA[<p>1：神经元</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">构建：包含初始化[w]，b；激活函数，前馈网络</span><br><span class="line"></span><br><span class="line">完成inputs→outputs的功能</span><br></pre></td></tr></table></figure><p>2：神经网络</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">构建：多个神经元构成，初始化[w],[b]；前馈网络</span><br><span class="line"></span><br><span class="line">完成inputs→outputs的功能</span><br></pre></td></tr></table></figure><p>3：神经网络的训练</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">构建：定义损失函数，随机初始化[w],[b];前向传播;训练方法（通过随机梯度下降更新权重和偏置的过程，包含学习率，偏导，和批次数）;每10个epoch打印一次准确率或者损失值等，方便可视化</span><br></pre></td></tr></table></figure><p>4：神经网络的预测</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">就是神经网络的前向传播</span><br></pre></td></tr></table></figure><p>5：计算机视觉发展史</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如何让计算机理解视觉(圆柱表示法,直线表示法)→人脸识别（2000年）→SIFT（对象识别，基于特征（因为匹配整个物体非常困难（有很多干扰因素））））→图像金字塔，不同的分辨率带有同样的特征（2006）→梯度直方图（HoG，用来描述特征，表示向量机）→（2006-2012数据集的发展）开始对象识别（发展基于标准数据集的产生,PASCAL;imageNet(最大的数据集项目)）→大赛中卷积神经网络展现身手（2012年，使得错误率下降了10%，前五类识别）</span><br></pre></td></tr></table></figure><p>6：数据增强</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">1：文字扭曲（贝塞尔曲线实现）</span><br><span class="line">2：背景噪声（椒盐）</span><br><span class="line">椒盐噪声 = 椒噪声 + 盐噪声 ，椒盐噪声的值为0(黑色)或者255(白色)</span><br><span class="line">3：笔画粘连（膨胀）</span><br><span class="line">4：笔画断裂（腐蚀）</span><br><span class="line">5：风格迁移</span><br><span class="line">6：ImageEnhance（增强亮度，色泽等）</span><br><span class="line">7：滤镜</span><br><span class="line">8：加下划线（适用于下划线上面是答案的情况）</span><br><span class="line">9：底色加数字（适用于答案会写在数字上的情况）</span><br><span class="line">10：左右镜像</span><br><span class="line">11：随机裁剪</span><br><span class="line">12：随机擦除</span><br><span class="line">13:旋转</span><br><span class="line">14：剪切（shearing）</span><br><span class="line">15：局部扭曲变换（Local warping）</span><br><span class="line">16：color shifting(调整rgb的值，保持失真)</span><br><span class="line">17:PCA主成分分析（颜色增强），使得RGB相对一致</span><br><span class="line"></span><br><span class="line">一般不做本地数据增强，在代码中动态增强，数据增强过程中使用的到参数，也可以作为超参数来调整</span><br></pre></td></tr></table></figure><p>7：物体识别的问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1：物体相机位置不一样，像素不一样</span><br><span class="line">2：物体光照，阴影等不一样</span><br><span class="line">3：物体只有部分可视</span><br><span class="line">4：背景和物体颜色类似</span><br><span class="line">5：物体的品种不一样（猫）</span><br></pre></td></tr></table></figure><p>8：数据驱动方法(Data-driver method)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1:收集数据</span><br><span class="line">2:训练模型</span><br><span class="line">3：使用模型预测</span><br><span class="line"></span><br><span class="line">def train(images,labels):</span><br><span class="line">#meching learning</span><br><span class="line">return model</span><br><span class="line"></span><br><span class="line">def predict(test_image,model):</span><br><span class="line">return test_labels</span><br></pre></td></tr></table></figure><p>9：第一个分类器(nearest neighbor)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">数据集使用CIFAR10</span><br><span class="line">原理就是对图片进行对比</span><br><span class="line">两个图片的对比第一种方式：L1曼哈顿距离(围成了矩形，会随着坐标旋转改变)</span><br><span class="line">sum(|Test[:]-train[:]|)，两个对应坐标像素的绝对值的和</span><br><span class="line">两个图片的对比第二种方式：L2欧几里得距离（围成的是圆，坐标不变）</span><br><span class="line">sum((Test[:]-train[:])的平方开根号）</span><br><span class="line"></span><br><span class="line">对于knn，你需要决策的是k取值和距离的取值，距离的标识L1或者L2（超参数）</span><br></pre></td></tr></table></figure><p>10：对于超参数的选择</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">对于knn：</span><br><span class="line">K=1的时候训练更好（错误，需要多调整）</span><br><span class="line">超参数在测试集上更好就选择（错误，需要均衡）</span><br><span class="line">数据分为训练集，验证集和测试集：在验证集上选择超参数，测试集上测试（？暂时不理解）</span><br><span class="line">交叉验证是一个很好的设置超参数方式(但是不适合大型数据集，时间昂贵)</span><br></pre></td></tr></table></figure><p>11:SVM损失函数（Loss function）hinge loss(铰接损失)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">在训练集上，通过得分来衡量不准确率。对于不同给定的权值w，来衡量不同w的优劣。</span><br><span class="line">label:标签，用来定义输出类型,数据类型为Interage</span><br><span class="line">score</span><br><span class="line">label   True cat  carfrog</span><br><span class="line">cat 3.21.32.2</span><br><span class="line">car5.14.92.5</span><br><span class="line">frog-1.72.0-3.1</span><br><span class="line"></span><br><span class="line">(每一类：如frog)Loss=max(2.2-(-3.1)+1,0)+max(2.5-(-3.1)+1,0)（True得分减去其他类得分&gt;1则置0，小于0取实际值）</span><br><span class="line">Li=∑max(Sj-syi+1,0)(j≠i)</span><br><span class="line">(Sj为预测的类别得分，Syi为预测为实际类别的得分):目的是让我们通过权值w得到的准确分类，真实类别的得分要比错误类别的得分大于1;继而损失函数=0的时候，刚好等于1。</span><br><span class="line">平均损失：sum/N</span><br><span class="line"></span><br><span class="line">1:如果car的得分改变一点，对损失函数是否有影响？</span><br><span class="line">没有影响，因为car的分数已经超过了其他的分数，改变一点之后，损失函数还是0</span><br><span class="line"></span><br><span class="line">2:损失函数的取值范围</span><br><span class="line">0~+∞</span><br><span class="line"></span><br><span class="line">3:如果使用的是平方损失？意义是什么</span><br><span class="line">平方损失的意义在于，我们改变不同的w，看看到底那个地方对于损失的影响更大</span><br><span class="line"></span><br><span class="line">4:这种损失函数在numpy中的表示</span><br><span class="line"></span><br><span class="line">5:得到损失函数为0的权值并不唯一</span><br><span class="line">w得到的损失为0，那么2W同样得到损失函数也为0</span><br><span class="line"></span><br><span class="line">6:我们并不关心在训练集上的损失函数，而是在测试集上面的分类准确情况</span><br><span class="line"></span><br><span class="line">7:hinge loss(铰接损失)有时候又被称为最大边界损失（max-margin loss）</span><br></pre></td></tr></table></figure><p>12:Regularization(损失函数的正则化)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">正则化是为了使得事情变得简单化:</span><br><span class="line">L1 regularization</span><br><span class="line">L2 regularization</span><br><span class="line">Dropout regularization:常用,防止过拟合，可以区别共同特征;但是会增加训练时间，因为每次会丢弃一部分的权重更新</span><br><span class="line">Max-Norm Regularization</span><br><span class="line">随机深度：不属于对损失函数的正则化，（对于很深的网络），思路是在训练的时候舍弃一些层，但是在测试的时候使用原样，效果好</span><br><span class="line">等等...</span><br><span class="line">都是通过调整损失函数来实现正则化的</span><br></pre></td></tr></table></figure><p>13:softmax classifier</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">score取值范围调整为0-1,表达式为:np.exp(a) / np.sum(np.exp(a)) </span><br><span class="line">强调了最大得分，忽略了比较小的得分（通常情况下，并非标量不变）:</span><br><span class="line">例如：</span><br><span class="line">得分为：[1、2、3、4、1、2、3]</span><br><span class="line">softmax之后为：[0.024、0.064、0.175、0.475、0.024、0.064、0.175]</span><br><span class="line">最高值的比例为4/16&lt;0.475</span><br><span class="line"></span><br><span class="line">但是有时候会出现如下情况</span><br><span class="line">得分为：[0.1, 0.2, 0.3, 0.4, 0.1, 0.2, 0.3] </span><br><span class="line">softmax之后为：[0.125, 0.138, 0.153, 0.169, 0.125, 0.138, 0.153]</span><br><span class="line">最大值0.4/1.6&gt;0.169</span><br></pre></td></tr></table></figure><p>14:softMax的lossfunction</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">sofeMax的lossfunction:-logSj   </span><br><span class="line">(sj为softmax之后对应种类的概率)，</span><br><span class="line">例如样本为[0,0,0,0,0,0,1]</span><br><span class="line">softmax之后的概率为[0.125, 0.138, 0.153, 0.169, 0.125, 0.138, 0.153]</span><br><span class="line">则对于该次预测的loss值为-log(0.153)，Sj越大，证明预测性能更好，对应的loss越低，最低趋近于0</span><br><span class="line"></span><br><span class="line">1:lossfunction的取值</span><br><span class="line">lossfunction的取值为0-+∞</span><br><span class="line"></span><br><span class="line">2:初始化权值都很小的时候，lossfunction的值</span><br><span class="line">-log(1/c)  c为类别的个数</span><br><span class="line"></span><br><span class="line">3:所以如果你的概率是通过softmax公式得到的，那么cross entropy就是softmax loss</span><br></pre></td></tr></table></figure><p>15：SVM loss  vs  Softmax loss</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">常用损失函数</span><br><span class="line">常见的损失误差有五种：</span><br><span class="line">1. 铰链损失（Hinge Loss）：主要用于支持向量机（SVM） 中；</span><br><span class="line">2. 互熵损失 （Cross Entropy Loss，Softmax Loss ）：用于Logistic 回归与Softmax 分类中；</span><br><span class="line">3. 平方损失（Square Loss）：主要是最小二乘法（OLS）中；</span><br><span class="line">4. 指数损失（Exponential Loss） ：主要用于Adaboost 集成学习算法中；</span><br><span class="line">5. 其他损失（如0-1损失，绝对值损失）</span><br></pre></td></tr></table></figure><p>16:优化器（optimization）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">方案1:随机搜索,随机化权重，使得损失函数最小（实现困难，并且耗时巨大，准确率低）</span><br><span class="line"></span><br><span class="line">方案2:梯度（但是太过于缓慢，如果w的维度为1000万）</span><br><span class="line">十分类问题，w为1*10的矩阵，loss在固定的W为固定值，那么每一个w（其他w值固定不变）增加为W+h(first dim)，得到对应的loss，∆loss/∆w就为对应的梯度，处理10次就得到每一个的梯度。</span><br><span class="line"></span><br><span class="line">方案3:Calculus（微积分）</span><br><span class="line">直接就可以得到斜率（不需要每个增加微小值h(0.001)）</span><br><span class="line"></span><br><span class="line">总结：使用分析梯度下降（快，但是有错误情况），结合数值梯度来进行检查，称为gradient check(梯度检查,debug可以用到)</span><br><span class="line"></span><br><span class="line">4:step_size(leraning rate)作为超参数</span><br><span class="line"></span><br><span class="line">5:SGD(随机梯度下降)</span><br><span class="line">我们处理图片训练的时候，可能参数有数百万个，随机梯度下降解决的问题是不需要进行一整个循环来得到梯度，而是每个minibatch(32,64,128)就可以得到梯度;代码上多增加了一行采样训练数据</span><br><span class="line"></span><br><span class="line">6:更加优秀的梯度下降</span><br><span class="line">Adaptive Learning Algorithms(自适应学习率算法):Adagrad，Adadelta，RMSprop，Adam，优于SGD（随机梯度下降）算法</span><br><span class="line"></span><br><span class="line">7：具有动量的SGD可以越过局部最小值和鞍点，一般使用Adam</span><br></pre></td></tr></table></figure><p>17:线性分类svm，损失函数的直观了解</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://vision.stanford.edu/teaching/cs231n-demos/linear-classify/</span><br></pre></td></tr></table></figure><p>18:反向传播</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">f(x,y,z)=(x+y)*z</span><br><span class="line">e.g. x=-2 y=5 z=-4</span><br><span class="line"></span><br><span class="line">表达式分解为：</span><br><span class="line">q=x+y</span><br><span class="line">f=q*z</span><br><span class="line"></span><br><span class="line">反向传播的导数遵循链式法则：</span><br><span class="line">∂q/∂x=1</span><br><span class="line">∂q/∂y=1</span><br><span class="line"></span><br><span class="line">∂f/∂q=z</span><br><span class="line">∂f/∂z=q</span><br><span class="line"></span><br><span class="line">即∂f/∂x=∂f/∂q * ∂q/∂x=z*1=z=-4</span><br></pre></td></tr></table></figure><p>19:Patterns in backward flow(反向传播的模式)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">add gate(加法):gradient distributor(梯度分布:两个值梯度一样)</span><br><span class="line">max gate(取最大值):gradient router(梯度路由:其中一个值的梯度置0)</span><br><span class="line">mul gate(乘法):gradient switcher(梯度切换:梯度分别为另一个值)</span><br><span class="line"></span><br><span class="line">Gradient add at branches：分支的时候梯度为求分支求和</span><br><span class="line"></span><br><span class="line">向量计算的梯度：</span><br><span class="line">向量中元素的梯度总是一样的，</span><br></pre></td></tr></table></figure><p>20:Modeularized implementation(模块化)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">框架中：caffe torch TensorFlow 都是在实现正向和方向传播</span><br></pre></td></tr></table></figure><p>21:Convolutional Neural Networks(CNN)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">全连接层：input为32*32*3的图片</span><br><span class="line">那么input展开就为3072*1的矩阵；需要的w就为10*3072的矩阵，最终经过激活函数(可以是sigmod)，得到10个种类的得分</span><br><span class="line">需要的参数为30720个</span><br><span class="line"></span><br><span class="line">卷积层:input是32*32*3的图片</span><br><span class="line">保留原结构，经过5*5*3的卷积，进行运算，得到28*28的特征图;如果有6个过滤器，则可以得到6个特征图，合起来就是28*28*6；再经过10个5*5*6的过滤器，得到10个24*24的特征图</span><br><span class="line"></span><br><span class="line">输出层的大小=（N-F）/stride+1 </span><br><span class="line">N:输入层的大小</span><br><span class="line">F:过滤器的大小</span><br><span class="line">stride：步长</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">输出层的大小=（N+2p-F）/stride+1 </span><br><span class="line">pad:填充，一般使用0像素填充(为了保持输出图像的大小，再深层网络中多个卷积下来之后图片大小会急剧下降)</span><br><span class="line"></span><br><span class="line">练习：input：32*32*3  10个5*5的过滤器 步长为1  pad为2 输出是？参数的个数是？</span><br><span class="line">(32+4-5+1)/1的10个，最终为32*32*10;</span><br><span class="line">参数的个数为（5*5*3+1）*10=760个，每个过滤器都会加一个偏置项Bias</span><br><span class="line"></span><br><span class="line">过滤器的数量一般为2的次方个,32,64,128...</span><br><span class="line"></span><br><span class="line">池化层：也叫下采样层(减小特征图的大小),一般采用最大池化,池化的步长一般也和过滤器大小一致，保证不会有重叠区域被池化；目的是进行下采样</span><br><span class="line"></span><br><span class="line">直观演示地址：</span><br><span class="line">https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html</span><br></pre></td></tr></table></figure><p>22:激活函数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">激活函数一般用在求出了h=w1*x1+w2*x2+b，之后f(h)</span><br><span class="line">有下面的种类f(x)：</span><br><span class="line"></span><br><span class="line">Sigmoid:取值为0~1</span><br><span class="line">问题点:</span><br><span class="line">1：当x=10,或者x=-10的时候，d(f(x))/d(x)梯度≈0；则d(f(x))/d(w)也≈0，会产生梯度消失，不利于参数更新</span><br><span class="line">2：对于向量w而言；输入x为正，梯度始终为正；或者输入x为负，梯度始终为负；这意味着我们需要使用的输入数据是均值为0</span><br><span class="line">3:Sigmoid计算昂贵（并不是很严重的问题）</span><br><span class="line"></span><br><span class="line">tanh:取值为-1~1</span><br><span class="line">问题点：</span><br><span class="line">解决了Sigmoid的第二个问题,但是还是存在第一个问题</span><br><span class="line"></span><br><span class="line">ReLU:取值0~正无穷(第一次使用是在2012 AlexNet)</span><br><span class="line">1：存在负值梯度为0的情况</span><br><span class="line">2：收敛较快（大概是sigmoid的6倍）</span><br><span class="line">3：初始化weight可能存在永远都不更新w的情况，对于所有的输入（w1*x1+w2*x2+b&lt;0），使得f(x)/d(w)=0;部分神经元死掉（不更新，不起作用）</span><br><span class="line"></span><br><span class="line">Leaky ReLu:取值-无穷~正无穷</span><br><span class="line">max(0.01x,x),解决了h的取值为负数，梯度为0的情况</span><br><span class="line"></span><br><span class="line">PRelu:max(αx,x)</span><br><span class="line">α通过超参数给定，更加灵活</span><br><span class="line"></span><br><span class="line">ELU：Rlue的另一个变种</span><br><span class="line"></span><br><span class="line">Maxout:max(w1Tx+b1,w2Tx+b2)</span><br><span class="line">1：需要两组权值</span><br><span class="line"></span><br><span class="line">使用激活函数的经验：</span><br><span class="line">1:不使用sigmoid</span><br><span class="line">2:是要ReLU,注意学习率</span><br><span class="line">3:尝试ReLU的变种</span><br><span class="line">4:尝试tanh（不做期待）</span><br></pre></td></tr></table></figure><p>23:数据预处理（data Preprocess）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">1:zero-mean(0均值):</span><br><span class="line">I=D-Imean</span><br><span class="line">Imean可以是整个图片的均值（3通道）AlexNet，也可以是（每个通道的均值）vgg网络中是这样的</span><br><span class="line"></span><br><span class="line">2:Normalized data:归一化(CNN不常见)</span><br><span class="line">I = Imin + (Imax-Imin)*(D-Dmin)/(Dmax-Dmin)</span><br><span class="line"></span><br><span class="line">3:PCA和白化(CNN不常见)</span><br><span class="line"></span><br><span class="line">注意点：</span><br><span class="line">1:正确做法是计算训练数据的均值，然后分别把它从训练/验证/测试数据中减去。</span><br><span class="line">2:数据预处理不能解决sigmoid的劣势（梯度消失），因为预处理只能处理第一层的输入数据结构</span><br><span class="line">3:数据预处理可以使得数据对损失不太敏感，更好的处理;偏离中心的数据移动到中心</span><br></pre></td></tr></table></figure><p>24：（权值初始化）weight Initalization</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">问题</span><br><span class="line">1：初始化W=0会出现什么?</span><br><span class="line">大部分神经元的梯度相同，做了一样的事情，激活函数一样的时候,w=0，则得到的损失函数一致，反向梯度也一致，即会用同样的方式更新。</span><br><span class="line"></span><br><span class="line">2：W=0.01*np.random.randn(D,N)？</span><br><span class="line">均值为0,标准差为0.01;网络比较小的时候可行，深层网络不可行;网络的深入，所有的梯度都会变为0</span><br><span class="line"></span><br><span class="line">3:W=np.random.randn(fan_in.fan_out)</span><br><span class="line">标准差为1，所有神经元都将处于饱和状态，梯度消失</span><br><span class="line"></span><br><span class="line">4:Xavier初始化(最常用)</span><br><span class="line">W=np.random.randn(fan_in,fan_out)/np.sqrt(fan_in)</span><br><span class="line"></span><br><span class="line">5:note additional/2</span><br><span class="line">W=np.random.randn(fan_in,fan_out)/np.sqrt(fan_in/2)</span><br><span class="line"></span><br><span class="line">6:batch Normalization（批处理归一化）</span><br><span class="line">BN算法在Mini-batch中使用，一般在全连接层或者卷积层之后使用，或者在非线性层之前</span><br></pre></td></tr></table></figure><p>25：怎么做迁移学习</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">以分类问题而言：</span><br><span class="line">一：你的训练集小，类别少</span><br><span class="line">①你要做的是5分类问题</span><br><span class="line">②下载github上面imageNet网络和对应的权重</span><br><span class="line">③思路一：修改最后一层的softmax层(对应自己的输出类别)，同时冻结前面的权重，只需要训练最后一层的权重</span><br><span class="line">④思路二：把输入图片直到最后一层前的激活值储存到硬盘中，然后每次只需要训练一个一层网络即可(读取激活值进行softmax)</span><br><span class="line"></span><br><span class="line">经验而言：你的训练集越大，你需要冻结的层数减少。足够大的时候，可能不需要冻结任何一层</span><br></pre></td></tr></table></figure><p>26：GPU和CPU的比较</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">GPU：内核多，适合做并行运算，例如矩阵</span><br><span class="line">CPU：内核少</span><br><span class="line"></span><br><span class="line">openCL使用英伟达或者AMD的GPU，或者可以在CPU上跑，但是整体而言不行</span><br></pre></td></tr></table></figure><p>17：深度学习框架</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">caffe caffe2:Facebook</span><br><span class="line">PyTorch:Facebook</span><br><span class="line">TensorFlow:Google</span><br><span class="line">Paddle:Baidu</span><br><span class="line">CNTK:Microsoft</span><br><span class="line">MXNet:(Amazon)</span><br><span class="line"></span><br><span class="line">框架的优势：</span><br><span class="line">①简单的构建大型的计算图</span><br><span class="line">②自动计算梯度</span><br><span class="line">③有效的再GPU上运行(numpy无法在GPU上运行)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1：神经元&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;b
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>神经网络相关（卷积）</title>
    <link href="https://yanyubing.xyz/2020/04/17/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%EF%BC%88%E5%8D%B7%E7%A7%AF%EF%BC%89/"/>
    <id>https://yanyubing.xyz/2020/04/17/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9B%B8%E5%85%B3%EF%BC%88%E5%8D%B7%E7%A7%AF%EF%BC%89/</id>
    <published>2020-04-17T08:06:22.003Z</published>
    <updated>2020-04-17T16:06:09.756Z</updated>
    
    <content type="html"><![CDATA[<h3 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h3><p>1：卷积神经网络的发展</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LeNet(1998年)→AlexNet(2012年)→ZFNet(2013年)→VGG（2014年-2月）→GoogleNet(2014年-1月)→ResNet(2015年)→SENet(2017年)→DenseNet（2018年）→efficientnet（2019年）</span><br></pre></td></tr></table></figure><p>2：相关网络介绍</p><p>2.1:LeNet</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">1:网络结构</span><br><span class="line">LeNet-5包含七层，不包括输入，每一层都包含可训练参数（权重），当时使用的输入数据是32*32像素的图像。卷积层Cx，子采样层Sx，完全连接层Fx，其中x是层索引。输入图像大小是32*32</span><br><span class="line"></span><br><span class="line">第1层C1：具有6个5*5卷积核的卷积层，特征映射的大小为28*28（32+1-5），C1包含156个可训练参数和122304个连接。</span><br><span class="line"></span><br><span class="line">第2层S2：6个大小为14*14的特征图的子采样层（subsampling/pooling）。每个特征地图中的每个单元连接到C1中的对应特征地图中的2*2个邻域。S2中单位的四个输入相加，然后乘以可训练系数（权重），然后加到可训练偏差（bias）。结果通过S形函数传递。由于2*2个感受域不重叠，因此S2中的特征图只有C1中的特征图的一半行数和列数。S2层有12个可训练参数和5880个连接。</span><br><span class="line"></span><br><span class="line">第3层C3：具有16个5-5的卷积核的卷积层。前六个C3特征图的输入是S2中的三个特征图的每个连续子集，接下来的六个特征图的输入则来自四个连续子集的输入，接下来的三个特征图的输入来自不连续的四个子集。最后，最后一个特征图的输入来自S2所有特征图。C3层有1516个可训练参数和156000个连接。</span><br><span class="line"></span><br><span class="line">第4层S4：与S2类似，大小为2*2，输出为16个5*5的特征图。S4层有32个可训练参数和2000个连接。</span><br><span class="line"></span><br><span class="line">第5层C5：是具有120个大小为5*5的卷积核的卷积层。每个单元连接到S4的所有16个特征图上的5*5邻域。这里，因为S4的特征图大小也是5*5，所以C5的输出大小是1*1。因此S4和C5之间是完全连接的。C5被标记为卷积层，而不是完全连接的层，是因为如果LeNet-5输入变得更大而其结构保持不变，则其输出大小会大于1*1，即不是完全连接的层了。C5层有48120个可训练连接。</span><br><span class="line"></span><br><span class="line">第6层F6：完全连接到C5，输出84张特征图。它有10164个可训练参数。这里84与输出层的设计有关。</span><br><span class="line"></span><br><span class="line">2:网络结构流程总结</span><br><span class="line">输入32*32→（C1:6个5*5卷积核）→6个28*28的特征图→（S2子采样层）→6个14*14的特征图→（c3:16个5*5的卷积核）→16个10*10的特征图→（s4子采样层）→16个5*5的特征图→（C5:120个5*5的卷积核）→16*120个1*1的特征图→（F6：完全连接层）→输出84张特征图</span><br><span class="line"></span><br><span class="line">3:优缺点</span><br><span class="line">全连接层计算代价过大，而使用全部由卷积层组成的神经网络</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">名词注释：</span><br><span class="line"></span><br><span class="line">1:卷积层</span><br><span class="line">作用：特征提取，由多个卷积核构成;一般卷积核是奇数n*n</span><br><span class="line">如3*3的卷积核</span><br><span class="line">[1 0 -1</span><br><span class="line"> 1 0 -1</span><br><span class="line"> 1 0 -1]可以提取到竖向特征</span><br><span class="line"></span><br><span class="line">2：子采样层（也叫pooling层，池化层）</span><br><span class="line">作用：特征选择</span><br><span class="line">例如：经过卷积层之后得到的特征图为</span><br><span class="line">[1,9</span><br><span class="line"> 2,3]</span><br><span class="line">经过池化层之后只保留9，丢弃掉不满足条件的特征，减少参数，防止过拟合等...</span><br><span class="line">最大池化层和平均池化层：对特征图区域的保留方式不同，一种保留最大值，一种区域求平均然后保存</span><br><span class="line"></span><br><span class="line">3：完全连接层</span><br><span class="line">作用：起到分类器的作用</span><br><span class="line">1*1的特征图出来之后，每个特征经过对应的权值w和偏置b就可以得到不同种类的可能性(sigmod)</span><br><span class="line"></span><br><span class="line">4：特征图</span><br><span class="line">描述二维特征，经过卷积核（或者叫做特征滤波器）得到</span><br><span class="line"></span><br><span class="line">5：感受野</span><br><span class="line">特征对应的输入图像区域的大小</span><br></pre></td></tr></table></figure><p>2.2:AlexNet</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">1：网络结构</span><br><span class="line">AlexNet网络结构共有8层，前面5层是卷积层，后面3层是全连接层，最后一个全连接层的输出传递给一个1000路的softmax层，对应1000个类标签的分布。输入图片大小为224*224*3(RGB)</span><br><span class="line"></span><br><span class="line">第一层:卷积层,训练时会把输入经过预处理变为227×227×3,使用96个11×11×3的卷积核进行卷积计算,两个GPU分别承担48个运算，每次卷积的步长为4个像素， 生成的特征图为(227-11)/4+1=55，即55×55。</span><br><span class="line">ReLU:线性单元处理,得到2组48*55*55</span><br><span class="line">池化：池化尺寸为3*3，步长为2，池化后的像素规模为27*27*96</span><br><span class="line">归一化：运算的尺寸为5*5，归一化之后的像素规模不变</span><br><span class="line"></span><br><span class="line">第二层：卷积层，对输入27*27*48的2组，进行像素填充2(上下左右)，填充之后变为(27+2+2)*(27+2+2)。256个大小为5*5的卷积核，步长为1，卷积后的大小为27*27*128*2组。</span><br><span class="line">ReLU:这些像素层经过ReLU单元的处理，生成激活像素层，尺寸仍为两组27×27×128的像素层。</span><br><span class="line">池化：池化运算的尺寸为3×3，步长为2，池化后图像的尺寸为(57-3)/2+1=13，即池化后像素的规模为2组13×13×128的像素层</span><br><span class="line">归一化:归一化运算的尺度为5×5，归一化后的像素层的规模为2组13×13×128的像素层，分别由2个GPU进行运算。</span><br><span class="line"></span><br><span class="line">第三层：卷积层，第三层输入数据为第二层输出的2组13×13×128的像素层，为便于后续处理，每幅像素层的上下左右边缘都填充1个像素，填充后变为 (13+1+1)×(13+1+1)×128，分布在两个GPU中进行运算。这一层中每个GPU都有192个卷积核，每个卷积核的尺寸是3×3×256。因此，每个GPU中的卷积核都能对2组13×13×128的像素层的所有数据进行卷积运算。两个GPU有通过交叉的虚线连接，也就是说每个GPU要处理来自前一层的所有GPU的输入。</span><br><span class="line">ReLU：卷积后的像素层经过ReLU单元的处理，生成激活像素层，尺寸仍为2组13×13×192的像素层，分配给两组GPU处理。</span><br><span class="line"></span><br><span class="line">第四层：卷积层，第四层输入数据为第三层输出的2组13×13×192的像素层，类似于第三层，为便于后续处理，每幅像素层的上下左右边缘都填充1个像素，填充后的尺寸变为 (13+1+1)×(13+1+1)×192，分布在两个GPU中进行运算。</span><br><span class="line">这一层中每个GPU都有192个卷积核，每个卷积核的尺寸是3×3×192（与第三层不同，第四层的GPU之间没有虚线连接，也即GPU之间没有通信）。卷积的移动步长是1个像素，经卷积运算后的尺寸为 (13+1+1-3)/1+1=13，每个GPU中有13×13×192个卷积核，2个GPU卷积后生成13×13×384的像素层。</span><br><span class="line">ReLU：卷积后的像素层经过ReLU单元处理，生成激活像素层，尺寸仍为2组13×13×192像素层，分配给两个GPU处理。</span><br><span class="line"></span><br><span class="line">第五层：卷积层，第五层输入数据为第四层输出的2组13×13×192的像素层，为便于后续处理，每幅像素层的上下左右边缘都填充1个像素，填充后的尺寸变为 (13+1+1)×(13+1+1) ，2组像素层数据被送至2个不同的GPU中进行运算。</span><br><span class="line">这一层中每个GPU都有128个卷积核，每个卷积核的尺寸是3×3×192，卷积的步长是1个像素，经卷积后的尺寸为 (13+1+1-3)/1+1=13，每个GPU中有13×13×128个卷积核，2个GPU卷积后生成13×13×256的像素层。</span><br><span class="line">ReLU：卷积后的像素层经过ReLU单元处理，生成激活像素层，尺寸仍为2组13×13×128像素层，由两个GPU分别处理。</span><br><span class="line">池化：2组13×13×128像素层分别在2个不同GPU中进行池化运算处理，池化运算的尺寸为3×3，步长为2，池化后图像的尺寸为 (13-3)/2+1=6，即池化后像素的规模为两组6×6×128的像素层数据，共有6×6×256的像素层数据。</span><br><span class="line"></span><br><span class="line">第六层：卷积（全连接层）,第六层输入数据是第五层的输出，尺寸为6×6×256。本层共有4096个卷积核，每个卷积核的尺寸为6×6×256，由于卷积核的尺寸刚好与待处理特征图（输入）的尺寸相同，即卷积核中的每个系数只与特征图（输入）尺寸的一个像素值相乘，一一对应，因此，该层被称为全连接层。由于卷积核与特征图的尺寸相同，卷积运算后只有一个值，因此，卷积后的像素层尺寸为4096×1×1，即有4096个神经元。</span><br><span class="line">ReLU:这4096个运算结果通过ReLU激活函数生成4096个值。</span><br><span class="line">Dropout:然后再通过Dropout运算，输出4096个结果值。</span><br><span class="line"></span><br><span class="line">第七层：全连接层，第六层输出的4096个数据与第七层的4096个神经元进行全连接，然后经ReLU进行处理后生成4096个数据，再经过Dropout处理后输出4096个数据。</span><br><span class="line"></span><br><span class="line">第八层：全连接层，第七层输出的4096个数据与第八层的1000个神经元进行全连接，经过训练后输出1000个float型的值，这就是预测结果。</span><br><span class="line"></span><br><span class="line">2：优缺点</span><br><span class="line">ReLU,多个GPU：提高了训练速度</span><br><span class="line">重叠池化：提高精度</span><br><span class="line">局部归一化：提高精度</span><br><span class="line">数据扩充，dropout：减少过拟合</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">名词注释：</span><br><span class="line"></span><br><span class="line">1:ReLU（激活函数）</span><br><span class="line">线性修正单元</span><br><span class="line">使用线性的堆叠结果还是线性的，使用sigmod函数会出现梯度消失的问题（即在z很大或者很小的时候梯度接近0）</span><br><span class="line"></span><br><span class="line">2:局部归一化(最常用的min-max归一化)</span><br><span class="line">x_new=(x-x_min)/(x_max-x_min)，增强主导特征（1），提取干扰特征（0）</span><br><span class="line"></span><br><span class="line">3：重叠池化</span><br><span class="line">一般池化的步长和池化大小一致，重叠池化的大小要大于步长；例如3*3池化，步长为2;可以增加精度，如</span><br><span class="line">[9 7 8</span><br><span class="line"> 1 2 3</span><br><span class="line"> 4 5 2]</span><br><span class="line">如果是一般最大池化，则8会被舍去，但是可能8是一个有用特征，使用重叠池化后，在第二个池化结构中会被保留</span><br><span class="line"></span><br><span class="line">4：dropout</span><br><span class="line">我们在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征。</span><br><span class="line"></span><br><span class="line">5：梯度消失和梯度爆炸</span><br><span class="line">前言：使用反向传播可以快速的提高学习效率，使用反向传播的过程需要依靠梯度来更新权值参数，那么就会出现梯度消失（梯度接近0）和梯度爆炸（梯度接近正无穷的问题）</span><br><span class="line">梯度消失会影响学习速度</span><br><span class="line">梯度爆炸则无法训练</span><br></pre></td></tr></table></figure><p>2.3:ZFNet</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1：基于AlexNet进行微调，改变了AlexNet的第一层：即将滤波器的大小11*11变为了7*7，并且将步长4变为了2</span><br><span class="line">2：使用Relu激活函数和交叉熵损失函数</span><br><span class="line">3：使用反卷积，可视化feature map</span><br><span class="line">4：与AlexNet相比，前面的层使用了更小的卷积核和更小的步长，保留了更多的特征</span><br><span class="line">5：通过遮挡，找出了决定图像类别的关键部位。通过实验，说明了深度增加时，网络可以学习到更具有区分的特征。</span><br><span class="line">6：网络训练时，底层参数收敛快，越到高层，则需要越长的时间训练，才能收敛</span><br></pre></td></tr></table></figure><p>2.4:VGG</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">VGG16相比AlexNet的一个改进是采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5）。对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。</span><br><span class="line"></span><br><span class="line">简单来说，在VGG中，使用了3个3x3卷积核来代替7x7卷积核，使用了2个3x3卷积核来代替5*5卷积核，这样做的主要目的是在保证具有相同感知野的条件下，提升了网络的深度，在一定程度上提升了神经网络的效果。</span><br><span class="line"></span><br><span class="line">比如，3个步长为1的3x3卷积核的一层层叠加作用可看成一个大小为7的感受野（其实就表示3个3x3连续卷积相当于一个7x7卷积），其参数总量为 3x(9xC^2) ，如果直接使用7x7卷积核，其参数总量为 49xC^2 ，这里 C 指的是输入和输出的通道数。很明显，27xC^2小于49xC^2，即减少了参数；而且3x3卷积核有利于更好地保持图像性质。</span><br><span class="line"></span><br><span class="line">2个3*3可以代替一个5*5；（5-3+1-3+1=1）</span><br><span class="line">3个3*3可以代替一个7*7：（7-3+1-3+1-3+1=1）</span><br><span class="line"></span><br><span class="line">VGGNet的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）。</span><br><span class="line">几个小滤波器（3x3）卷积层的组合比一个大滤波器（5x5或7x7）卷积层好：</span><br><span class="line">验证了通过不断加深网络结构可以提升性能。</span><br></pre></td></tr></table></figure><p>2.5:GoogleNet</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">一般来说，提升网络性能最直接的办法就是增加网络深度和宽度，深度指网络层次数量、宽度指神经元数量。但这种方式存在以下问题：</span><br><span class="line">（1）参数太多，如果训练数据集有限，很容易产生过拟合；</span><br><span class="line">（2）网络越大、参数越多，计算复杂度越大，难以应用；</span><br><span class="line">（3）网络越深，容易出现梯度弥散问题（梯度越往后穿越容易消失），难以优化模型。</span><br><span class="line">因此，GoogLeNet团队提出了Inception网络结构，就是构造一种“基础神经元”结构，来搭建一个稀疏性、高计算性能的网络结构。</span><br><span class="line"></span><br><span class="line">Inception1：</span><br><span class="line">这个Inception原始版本，所有的卷积核都在上一层的所有输出上来做，而那个5x5的卷积核所需的计算量就太大了，造成了特征图的厚度很大，为了避免这种情况，在3x3前、5x5前、max pooling后分别加上了1x1的卷积核，以起到了降低特征图厚度的作用，这也就形成了Inception v1的网络结构.</span><br><span class="line"></span><br><span class="line">1x1的卷积核有什么用呢？</span><br><span class="line">1x1卷积的主要目的是为了减少维度，还用于修正线性激活（ReLU）。比如，上一层的输出为100x100x128，经过具有256个通道的5x5卷积层之后(stride=1，pad=2)，输出数据为100x100x256，其中，卷积层的参数为128x5x5x256= 819200。而假如上一层输出先经过具有32个通道的1x1卷积层，再经过具有256个输出的5x5卷积层，那么输出数据仍为为100x100x256，但卷积参数量已经减少为128x1x1x32 + 32x5x5x256= 204800，大约减少了4倍。</span><br><span class="line"></span><br><span class="line">Inception2:</span><br><span class="line">卷积分解（Factorizing Convolutions）:和vgg一样</span><br><span class="line">n*n的卷积层分解为1*n之后接一个n*1的</span><br><span class="line">降低特征图大小</span><br><span class="line"></span><br><span class="line">Inception3:</span><br><span class="line">将7x7分解成两个一维的卷积（1x7,7x1），3x3也是一样（1x3,3x1），这样的好处，既可以加速计算，又可以将1个卷积拆成2个卷积，使得网络深度进一步增加，增加了网络的非线性（每增加一层都要进行ReLU）。</span><br><span class="line">另外，网络输入从224x224变为了299x299。</span><br><span class="line"></span><br><span class="line">Inception V4:</span><br><span class="line">Inception V4研究了Inception模块与残差连接的结合。ResNet结构大大地加深了网络深度，还极大地提升了训练速度，同时性能也有提升</span><br></pre></td></tr></table></figure><p>2.6:resnet(残差网络)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">残差跳跃式结构：</span><br><span class="line">随着网络层级的不断增加，模型精度不断得到提升，而当网络层级增加到一定的数目以后，训练精度和测试精度迅速下降，这说明当网络变得很深以后，深度网络就变得更加难以训练了。</span><br><span class="line">神经网络在反向传播过程中要不断地传播梯度，而当网络层数加深时，梯度在传播过程中会逐渐消失（假如采用Sigmoid函数，对于幅度为1的信号，每向后传递一层，梯度就衰减为原来的0.25，层数越多，衰减越厉害），导致无法对前面网络层的权重进行有效的调整。</span><br><span class="line"></span><br><span class="line">如果已经学习到较饱和的准确率（或者当发现下层的误差变大时），那么接下来的学习目标就转变为恒等映射的学习，也就是使输入x近似于输出H(x)，以保持在后面的层次中不会造成精度下降。</span><br><span class="line">通过“shortcut connections（捷径连接）”的方式，直接把输入x传到输出作为初始结果，输出结果为H(x)=F(x)+x，当F(x)=0时，那么H(x)=x，也就是上面所提到的恒等映射。于是，ResNet相当于将学习目标改变了，不再是学习一个完整的输出，而是目标值H(X)和x的差值，也就是所谓的残差F(x) := H(x)-x，因此，后面的训练目标就是要将残差结果逼近于0，使到随着网络加深，准确率不下降。</span><br></pre></td></tr></table></figure><p>2.7:SENet</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Sequeeze-and-Excitation(SE) block并不是一个完整的网络结构，而是一个子结构，可以嵌到其他分类或检测模型中，作者采用SENet block和ResNeXt结合在ILSVRC 2017的分类项目中拿到第一。</span><br><span class="line">SENet的核心思想在于通过网络根据loss去学习特征权重，使得有效的feature map权重大，无效或效果小的feature map权重小的方式训练模型达到更好的结果。</span><br><span class="line">作者的动机是希望显式地建模特征通道之间的相互依赖关系。另外，作者并未引入新的空间维度来进行特征通道间的融合，而是采用了一种全新的「特征重标定」策略。具体来说，就是通过学习的方式来自动获取到每个特征通道的重要程度，然后依照这个重要程度去提升有用的特征并抑制对当前任务用处不大的特征。</span><br><span class="line"></span><br><span class="line">给定一个输入 x，其特征通道数为 c_1，通过一系列卷积等一般变换后得到一个特征通道数为 c_2 的特征，传统的 CNN 不一样的是，接下来通过三个操作来重标定前面得到的特征。</span><br><span class="line"></span><br><span class="line">首先是 Squeeze 操作，顺着空间维度来进行特征压缩，将每个二维的特征通道变成一个实数，这个实数某种程度上具有全局的感受野，并且输出的维度和输入的特征通道数相匹配。它表征着在特征通道上响应的全局分布，而且使得靠近输入的层也可以获得全局的感受野，这一点在很多任务中都是非常有用的。</span><br><span class="line"></span><br><span class="line">其次是 Excitation 操作，它是一个类似于循环神经网络中门的机制。通过参数 w 来为每个特征通道生成权重，其中参数 w 被学习用来显式地建模特征通道间的相关性。</span><br><span class="line"></span><br><span class="line">最后是一个 Reweight 的操作，将 Excitation 的输出的权重看做是进过特征选择后的每个特征通道的重要性，然后通过乘法逐通道加权到先前的特征上，完成在通道维度上的对原始特征的重标定。</span><br></pre></td></tr></table></figure><p>2.8DenseNet</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">DenseNet的几个优点：</span><br><span class="line">1、减轻了vanishing-gradient（梯度消失）</span><br><span class="line">2、加强了feature的传递</span><br><span class="line">3、更有效地利用了feature</span><br><span class="line">4、一定程度上较少了参数数量</span><br><span class="line"></span><br><span class="line">在深度学习网络中，随着网络深度的加深，梯度消失问题会愈加明显，目前很多论文都针对这个问题提出了解决方案，比如ResNet，Highway Networks，Stochastic depth，FractalNets等，尽管这些算法的网络结构有差别，但是核心都在于：create short paths from early layers to later layers。那么作者是怎么做呢？延续这个思路，那就是在保证网络中层与层之间最大程度的信息传输的前提下，直接将所有层连接起来！</span><br><span class="line"></span><br><span class="line">在传统的卷积神经网络中，如果你有L层，那么就会有L个连接，但是在DenseNet中，会有L(L+1)/2个连接。简单讲，就是每一层的输入来自前面所有层的输出。</span><br><span class="line"></span><br><span class="line">DenseNet的一个优点是网络更窄，参数更少，很大一部分原因得益于这种dense block的设计，后面有提到在dense block中每个卷积层的输出feature map的数量都很小（小于100），而不是像其他网络一样动不动就几百上千的宽度。同时这种连接方式使得特征和梯度的传递更加有效，网络也就更加容易训练。原文的一句话非常喜欢：Each layer has direct access to the gradients from the loss function and the original input signal, leading to an implicit deep supervision.直接解释了为什么这个网络的效果会很好。前面提到过梯度消失问题在网络深度越深的时候越容易出现，原因就是输入信息和梯度信息在很多层之间传递导致的，而现在这种dense connection相当于每一层都直接连接input和loss，因此就可以减轻梯度消失现象，这样更深网络不是问题。另外作者还观察到这种dense connection有正则化的效果，因此对于过拟合有一定的抑制作用。</span><br><span class="line"></span><br><span class="line">该文章提出的DenseNet核心思想在于建立了不同层之间的连接关系，充分利用了feature，进一步减轻了梯度消失问题，加深网络不是问题，而且训练效果非常好。另外，利用bottleneck layer，Translation layer以及较小的growth rate使得网络变窄，参数减少，有效抑制了过拟合，同时计算量也减少了。DenseNet优点很多，而且在和ResNet的对比中优势还是非常明显的。</span><br></pre></td></tr></table></figure><p>EfficientNet</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pass(调参复杂)</span><br></pre></td></tr></table></figure><h3 id="2：数据增强"><a href="#2：数据增强" class="headerlink" title="2：数据增强"></a>2：数据增强</h3><p>镜像反射和随机剪裁</p><h3 id="3：加快学习的方式"><a href="#3：加快学习的方式" class="headerlink" title="3：加快学习的方式"></a>3：加快学习的方式</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;卷积神经网络&quot;&gt;&lt;a href=&quot;#卷积神经网络&quot; class=&quot;headerlink&quot; title=&quot;卷积神经网络&quot;&gt;&lt;/a&gt;卷积神经网络&lt;/h3&gt;&lt;p&gt;1：卷积神经网络的发展&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table
      
    
    </summary>
    
    
    
  </entry>
  
</feed>
