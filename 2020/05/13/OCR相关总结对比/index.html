<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="鄢玉兵的博客" type="application/atom+xml" />






<meta name="description" content="OCR总结和对比；实现书本的题干提取 1总结：OCR对于识别的准确率基本可以满足要求，只是前提是定位的准确和一些预处理操作以及对应不同场景的不同处理方案的搭配（如中英文不同，特殊字符的处理等等）  1：百度ocr 1.1:特点 12345678910111：付费2：偶尔报错Traceback (most recent call last):  File &amp;quot;C:&#x2F;Users&#x2F;yanyubi">
<meta property="og:type" content="article">
<meta property="og:title" content="OCR相关总结对比">
<meta property="og:url" content="https:&#x2F;&#x2F;yanyubing.xyz&#x2F;2020&#x2F;05&#x2F;13&#x2F;OCR%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%E5%AF%B9%E6%AF%94&#x2F;index.html">
<meta property="og:site_name" content="鄢玉兵的博客">
<meta property="og:description" content="OCR总结和对比；实现书本的题干提取 1总结：OCR对于识别的准确率基本可以满足要求，只是前提是定位的准确和一些预处理操作以及对应不同场景的不同处理方案的搭配（如中英文不同，特殊字符的处理等等）  1：百度ocr 1.1:特点 12345678910111：付费2：偶尔报错Traceback (most recent call last):  File &amp;quot;C:&#x2F;Users&#x2F;yanyubi">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2020-06-23T08:09:23.712Z">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://yanyubing.xyz/2020/05/13/OCR相关总结对比/"/>





  <title>OCR相关总结对比 | 鄢玉兵的博客</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
<a href="https://yanyubing.xyz"><img width="149" height="149" src="https://github.blog/wp-content/uploads/2008/12/forkme_left_red_aa0000.png?resize=149%2C149" class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">鄢玉兵的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://yanyubing.xyz/2020/05/13/OCR%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%E5%AF%B9%E6%AF%94/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="鄢玉兵">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="鄢玉兵的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">OCR相关总结对比</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-05-13T11:01:04+08:00">
                2020-05-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>OCR总结和对比；实现书本的题干提取</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">总结：OCR对于识别的准确率基本可以满足要求，只是前提是定位的准确和一些预处理操作以及对应不同场景的不同处理方案的搭配（如中英文不同，特殊字符的处理等等）</span><br></pre></td></tr></table></figure>

<p>1：百度ocr</p>
<p>1.1:特点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">1：付费</span><br><span class="line">2：偶尔报错</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;C:/Users/yanyubing/Desktop/zex/010_GUI/ocr/ocr_Topic.py&quot;, line 112, in &lt;module&gt;</span><br><span class="line">    results = client.general(image)[&quot;words_result&quot;]</span><br><span class="line">KeyError: &apos;words_result&apos;</span><br><span class="line">3：网络请求</span><br><span class="line">4：准确率基本满足要求</span><br><span class="line">5：识别数字很烂</span><br><span class="line"></span><br><span class="line">总结：可以满足生产需求</span><br></pre></td></tr></table></figure>

<p>1.2:代码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"># 题干的ocr</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import cv2</span><br><span class="line">from aip import AipOcr</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot; 你的 APPID AK SK &quot;&quot;&quot;</span><br><span class="line">#这里有更改</span><br><span class="line">APP_ID = &apos;198605*&apos;</span><br><span class="line">API_KEY = &apos;R7fGy5Yh900UQKXmlppPc69d&apos;</span><br><span class="line">SECRET_KEY = &apos;v2OKtKnslZq34qNQKQ4dZCGwjONxK9xY&apos;</span><br><span class="line"></span><br><span class="line">client = AipOcr(APP_ID, API_KEY, SECRET_KEY)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_file_content(filePath):</span><br><span class="line">    with open(filePath, &apos;rb&apos;) as fp:</span><br><span class="line">        return fp.read()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># step1：获取定位框的最左排序个数</span><br><span class="line"># num:输入获取的个数</span><br><span class="line">def getTopic(num):</span><br><span class="line">    # 没有题干的提前结束</span><br><span class="line">    if num == 0:</span><br><span class="line">        return</span><br><span class="line">    global str_temp</span><br><span class="line"></span><br><span class="line">    # 获取所有识别的集合</span><br><span class="line">    left_temp = []</span><br><span class="line"></span><br><span class="line">    for result in results:</span><br><span class="line">        # 文本</span><br><span class="line">        text = result[&quot;words&quot;]</span><br><span class="line"></span><br><span class="line">        # 定位</span><br><span class="line">        location = result[&quot;location&quot;]</span><br><span class="line"></span><br><span class="line">        # 得到字段：最左边，高度定位，和文本信息</span><br><span class="line">        strtemp = str(location[&apos;left&apos;]) + &apos;,&apos; + str(location[&apos;top&apos;]) + &apos;,&apos; + text</span><br><span class="line"></span><br><span class="line">        # 添加</span><br><span class="line">        left_temp.append(strtemp)</span><br><span class="line"></span><br><span class="line">    # 获取需要的集合,根据左边的位置排序</span><br><span class="line">    lefts = []</span><br><span class="line">    while 1:</span><br><span class="line">        # 获取最小的x值</span><br><span class="line">        min_x = 10000</span><br><span class="line">        for temp in left_temp:</span><br><span class="line">            if int(temp.split(&apos;,&apos;)[0]) &lt; min_x:</span><br><span class="line">                min_x = int(temp.split(&apos;,&apos;)[0])</span><br><span class="line">                str_temp = temp</span><br><span class="line"></span><br><span class="line">        lefts.append(str_temp)</span><br><span class="line">        # print(str_temp)</span><br><span class="line">        left_temp.remove(str_temp)</span><br><span class="line"></span><br><span class="line">        if len(lefts) == num:</span><br><span class="line">            break</span><br><span class="line">    # 左边位置排序之后再根据上下位置排序</span><br><span class="line">    result = []</span><br><span class="line"></span><br><span class="line">    while 1:</span><br><span class="line">        # 获取最小的x值</span><br><span class="line">        min_y = 10000</span><br><span class="line">        for temp in lefts:</span><br><span class="line">            if int(temp.split(&apos;,&apos;)[1]) &lt; min_y:</span><br><span class="line">                min_y = int(temp.split(&apos;,&apos;)[1])</span><br><span class="line">                str_temp = temp</span><br><span class="line"></span><br><span class="line">        result.append(str_temp)</span><br><span class="line">        # print(str_temp)</span><br><span class="line">        lefts.remove(str_temp)</span><br><span class="line"></span><br><span class="line">        if len(lefts) == 0:</span><br><span class="line">            # 过滤完全结束</span><br><span class="line">            break</span><br><span class="line"></span><br><span class="line">    return result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取所有书名，按照顺序排序</span><br><span class="line">def getBookNames(path):</span><br><span class="line">    booknames = []</span><br><span class="line">    filesname = os.listdir(path)</span><br><span class="line">    for i in range(len(filesname)):</span><br><span class="line">        name = path + &apos;/&apos; + str(i + 1) + &apos;.jpg&apos;</span><br><span class="line">        booknames.append(name)</span><br><span class="line">    return booknames</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 输入图片所在目录</span><br><span class="line">dir = input(&apos;输入图片所在文件夹:\n&apos;)</span><br><span class="line"></span><br><span class="line"># 获取所有的书名</span><br><span class="line">booknames = getBookNames(dir)</span><br><span class="line"></span><br><span class="line"># 输入对应要获取题干的个数，</span><br><span class="line"># nums = []</span><br><span class="line">nums = input(&apos;连续输入页码题干个数\n&apos;)</span><br><span class="line"># for bookname in booknames:</span><br><span class="line">#     num = int(input(&apos;输入需要获取页面:&apos; + bookname + &apos;的题干的个数:\n&apos;))</span><br><span class="line">#     nums.append(num)</span><br><span class="line"></span><br><span class="line"># 整本书的结果</span><br><span class="line">allResults = []</span><br><span class="line"># 遍历所有书</span><br><span class="line">for index in range(len(booknames)):</span><br><span class="line">    image = get_file_content(booknames[index])</span><br><span class="line"></span><br><span class="line">    &quot;&quot;&quot; 调用通用文字识别, 图片参数为本地图片 &quot;&quot;&quot;</span><br><span class="line">    results = client.general(image)[&quot;words_result&quot;]</span><br><span class="line"></span><br><span class="line">    # 一页书的结果</span><br><span class="line">    result = getTopic(int(nums[index]))</span><br><span class="line">    print(&quot;----&quot;, index, &quot;----&quot;)</span><br><span class="line">    for re in result:</span><br><span class="line">        # 添加页码信息</span><br><span class="line">        r = re + &apos;,&apos; + booknames[index]</span><br><span class="line">        # 整本书的结果</span><br><span class="line">        allResults.append(result)</span><br><span class="line"></span><br><span class="line"># 查看整本书的结果</span><br><span class="line">for result in allResults:</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure>



<p>2：pse+rcnn</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1：免费</span><br><span class="line">2：需要编译：本人使用vs2017+python3.7编译</span><br><span class="line">3：可以识别竖向文字，斜向文字也可以</span><br><span class="line">4：识别通用文字效果不太好:</span><br><span class="line">5：对于英文识别错误率高</span><br><span class="line">对于英文：误识，漏识严重</span><br><span class="line">对于中文:也存在一定的误识和漏识</span><br><span class="line">github地址：https://github.com/ouyanghuiyu/chineseocr_lite</span><br><span class="line"></span><br><span class="line">总结：无法满足生产需求。①定位有尺寸压缩，并且定位有偏差；②识别有误识</span><br><span class="line"></span><br><span class="line">解决方案：总体而言是因为pse定位存在误差，导致识别上的错误；使用自己的mark去定位，然后识别，准确率可以达到99%</span><br><span class="line">①取mark一定100%准确</span><br><span class="line">②根据mark去location一定100%准确</span><br><span class="line">③识别准确率才能到达极限</span><br><span class="line">④识别数字可以，识别英文很烂</span><br></pre></td></tr></table></figure>

<p>3：ocr.space</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">特点：</span><br><span class="line">①需要翻墙</span><br><span class="line">②多种语言和特殊字符的支持</span><br><span class="line">③使用简洁：但是有限制</span><br></pre></td></tr></table></figure>

<p>4： CRAFT(英文字符识别)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">地址：https://github.com/clovaai/CRAFT-pytorch+https://github.com/clovaai/deep-text-recognition-benchmark</span><br><span class="line">原理：CRAFT+deep-text-recognition(检测+识别)</span><br><span class="line">特点：</span><br><span class="line">①英文识别能力强，单个单词准确率达到99%</span><br><span class="line">②定位准确：切割单个单词准确率高99%</span><br><span class="line">③需要自己糅合</span><br></pre></td></tr></table></figure>

<p>4.1：定位</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"># 定位和识别一体</span><br><span class="line">import argparse</span><br><span class="line">import os</span><br><span class="line">import shutil</span><br><span class="line">import cv2</span><br><span class="line"></span><br><span class="line">from getLocations import getLocation</span><br><span class="line"></span><br><span class="line"># 存放txt的文件夹</span><br><span class="line">result_folder = &apos;txtResult/&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取txt文件</span><br><span class="line">def getTextFile(path):</span><br><span class="line">    # 存放定位之后的文件路径</span><br><span class="line"></span><br><span class="line">    # 存在结果文件夹</span><br><span class="line">    if os.path.exists(result_folder):</span><br><span class="line">        # 删除文件夹(非空)</span><br><span class="line">        shutil.rmtree(result_folder)</span><br><span class="line">    # 运行，会产生位置信息的txt文件</span><br><span class="line">    getLocation(path, result_folder)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 获取整个文件夹识别之后的集合</span><br><span class="line"># 格式为： &apos;&apos;&apos;文件路径：value&apos;&apos;&apos;</span><br><span class="line">def saveLocation(pathin, pathout):</span><br><span class="line">    if not os.path.exists(pathout):</span><br><span class="line">        os.mkdir(pathout)</span><br><span class="line">    # 获取原文件夹底下的文件列表</span><br><span class="line">    files = os.listdir(pathin)</span><br><span class="line">    # 遍历列表</span><br><span class="line">    for file in files:</span><br><span class="line">        # 获取不带后缀的文件名</span><br><span class="line">        filename = file.split(&apos;.&apos;)[0]</span><br><span class="line">        # 图片文件路径</span><br><span class="line">        ImgFilepath = pathin + &apos;/&apos; + file</span><br><span class="line">        # 读取图片</span><br><span class="line">        image = cv2.imread(ImgFilepath)</span><br><span class="line">        # 构建lines集合储存txt文件的lines</span><br><span class="line">        lines = []</span><br><span class="line">        # txt文件路径</span><br><span class="line">        TxtFilepath = result_folder + &apos;/&apos; + filename + &apos;.txt&apos;</span><br><span class="line">        # 读取txt文件</span><br><span class="line">        f = open(TxtFilepath)</span><br><span class="line">        line = f.readlines()</span><br><span class="line">        for li in line:</span><br><span class="line">            lines.append(li)</span><br><span class="line">        # 记录第几条数据</span><br><span class="line">        index = 0</span><br><span class="line">        # 去除多条数据中的空格</span><br><span class="line">        lines = [x.strip() for x in lines if x.strip() != &apos;&apos;]</span><br><span class="line">        # 根据横坐标位置排序，为了后面便于拼接</span><br><span class="line">        lines.sort(key=lambda x: int(x.split(&apos;,&apos;)[0]))</span><br><span class="line">        # 遍历lines，得到坐标位置</span><br><span class="line">        for line in lines:</span><br><span class="line">            # 除去每条数据中的空格</span><br><span class="line">            line = line[:-1]</span><br><span class="line">            index += 1</span><br><span class="line">            ls = line.split(&apos;,&apos;)</span><br><span class="line">            # 判断坐标位置的大小，得到左上和右下坐标的矩形框</span><br><span class="line">            # 左上</span><br><span class="line">            lt = (min(ls[0], ls[6]), min(ls[1], ls[3]))</span><br><span class="line"></span><br><span class="line">            # 右下</span><br><span class="line">            rd = (max(ls[4], ls[2]), max(ls[5], ls[7]))</span><br><span class="line">            # 得到定位之后的单个单词位置</span><br><span class="line">            imagetemp = image[int(lt[1]):int(rd[1]), int(lt[0]):int(rd[0])]</span><br><span class="line">            # 文件路径名，如1_1，则是第一个图的第一个单词</span><br><span class="line">            path_new = pathout + &apos;/&apos; + filename + &apos;_&apos; + str(index) + &apos;.jpg&apos;</span><br><span class="line">            cv2.imwrite(path_new, imagetemp)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 预处理文件处理,修改path</span><br><span class="line">path = &apos;two&apos;</span><br><span class="line">pathin = path</span><br><span class="line">pathout = path + &apos;out&apos;</span><br><span class="line">getTextFile(path)</span><br><span class="line"></span><br><span class="line">saveLocation(pathin, pathout)</span><br></pre></td></tr></table></figure>

<p>4.2:识别</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br></pre></td><td class="code"><pre><span class="line">import string</span><br><span class="line">import argparse</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torch.backends.cudnn as cudnn</span><br><span class="line">import torch.utils.data</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line">from utils import CTCLabelConverter, AttnLabelConverter</span><br><span class="line">from dataset import RawDataset, AlignCollate</span><br><span class="line">from model import Model</span><br><span class="line"></span><br><span class="line">device = torch.device(&apos;cuda&apos; if torch.cuda.is_available() else &apos;cpu&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def demo(opt):</span><br><span class="line">    # 储存所有的文本信息</span><br><span class="line">    # 格式：图片名称：值</span><br><span class="line">    values = []</span><br><span class="line">    # 临时存储，需要变换</span><br><span class="line">    valuetemp = []</span><br><span class="line">    &quot;&quot;&quot; model configuration &quot;&quot;&quot;</span><br><span class="line">    # CTC模型</span><br><span class="line">    if &apos;CTC&apos; in opt.Prediction:</span><br><span class="line">        converter = CTCLabelConverter(opt.character)</span><br><span class="line">    else:</span><br><span class="line">        converter = AttnLabelConverter(opt.character)</span><br><span class="line">    opt.num_class = len(converter.character)</span><br><span class="line"></span><br><span class="line">    if opt.rgb:</span><br><span class="line">        opt.input_channel = 3</span><br><span class="line">    model = Model(opt)</span><br><span class="line">    print(&apos;model input parameters&apos;, opt.imgH, opt.imgW, opt.num_fiducial, opt.input_channel, opt.output_channel,</span><br><span class="line">          opt.hidden_size, opt.num_class, opt.batch_max_length, opt.Transformation, opt.FeatureExtraction,</span><br><span class="line">          opt.SequenceModeling, opt.Prediction)</span><br><span class="line">    model = torch.nn.DataParallel(model).to(device)</span><br><span class="line"></span><br><span class="line">    # load model</span><br><span class="line">    print(&apos;loading pretrained model from %s&apos; % opt.saved_model)</span><br><span class="line">    model.load_state_dict(torch.load(opt.saved_model, map_location=device))</span><br><span class="line"></span><br><span class="line">    # prepare data. two demo images from https://github.com/bgshih/crnn#run-demo</span><br><span class="line">    AlignCollate_demo = AlignCollate(imgH=opt.imgH, imgW=opt.imgW, keep_ratio_with_pad=opt.PAD)</span><br><span class="line">    # 加载数据目录</span><br><span class="line">    demo_data = RawDataset(root=opt.image_folder, opt=opt)  # use RawDataset</span><br><span class="line">    #</span><br><span class="line">    demo_loader = torch.utils.data.DataLoader(</span><br><span class="line">        demo_data, batch_size=opt.batch_size,</span><br><span class="line">        shuffle=False,</span><br><span class="line">        num_workers=int(opt.workers),</span><br><span class="line">        collate_fn=AlignCollate_demo, pin_memory=True)</span><br><span class="line"></span><br><span class="line">    # predict</span><br><span class="line">    model.eval()</span><br><span class="line"></span><br><span class="line">    with torch.no_grad():</span><br><span class="line"></span><br><span class="line">        # image_path_list为文件夹列表</span><br><span class="line">        for image_tensors, image_path_list in demo_loader:</span><br><span class="line"></span><br><span class="line">            batch_size = image_tensors.size(0)</span><br><span class="line"></span><br><span class="line">            image = image_tensors.to(device)</span><br><span class="line"></span><br><span class="line">            # For max length prediction</span><br><span class="line">            length_for_pred = torch.IntTensor([opt.batch_max_length] * batch_size).to(device)</span><br><span class="line"></span><br><span class="line">            text_for_pred = torch.LongTensor(batch_size, opt.batch_max_length + 1).fill_(0).to(device)</span><br><span class="line"></span><br><span class="line">            if &apos;CTC&apos; in opt.Prediction:</span><br><span class="line">                preds = model(image, text_for_pred)</span><br><span class="line"></span><br><span class="line">                # Select max probabilty (greedy decoding) then decode index to character</span><br><span class="line">                preds_size = torch.IntTensor([preds.size(1)] * batch_size)</span><br><span class="line">                _, preds_index = preds.max(2)</span><br><span class="line">                preds_index = preds_index.view(-1)</span><br><span class="line">                preds_str = converter.decode(preds_index.data, preds_size.data)</span><br><span class="line"></span><br><span class="line">            else:</span><br><span class="line">                preds = model(image, text_for_pred, is_train=False)</span><br><span class="line"></span><br><span class="line">                # select max probabilty (greedy decoding) then decode index to character</span><br><span class="line">                _, preds_index = preds.max(2)</span><br><span class="line"></span><br><span class="line">                preds_str = converter.decode(preds_index, length_for_pred)</span><br><span class="line"></span><br><span class="line">            log = open(f&apos;./log_demo_result.txt&apos;, &apos;a&apos;)</span><br><span class="line"></span><br><span class="line">            dashed_line = &apos;-&apos; * 80</span><br><span class="line"></span><br><span class="line">            head = f&apos;&#123;&quot;image_path&quot;:25s&#125;\t&#123;&quot;predicted_labels&quot;:25s&#125;\tconfidence score&apos;</span><br><span class="line"></span><br><span class="line">            print(f&apos;&#123;dashed_line&#125;\n&#123;head&#125;\n&#123;dashed_line&#125;&apos;)</span><br><span class="line"></span><br><span class="line">            log.write(f&apos;&#123;dashed_line&#125;\n&#123;head&#125;\n&#123;dashed_line&#125;\n&apos;)</span><br><span class="line"></span><br><span class="line">            preds_prob = F.softmax(preds, dim=2)</span><br><span class="line"></span><br><span class="line">            preds_max_prob, _ = preds_prob.max(dim=2)</span><br><span class="line"></span><br><span class="line">            for img_name, pred, pred_max_prob in zip(image_path_list, preds_str, preds_max_prob):</span><br><span class="line"></span><br><span class="line">                if &apos;Attn&apos; in opt.Prediction:</span><br><span class="line">                    pred_EOS = pred.find(&apos;[s]&apos;)</span><br><span class="line"></span><br><span class="line">                    pred = pred[:pred_EOS]  # prune after &quot;end of sentence&quot; token ([s])</span><br><span class="line"></span><br><span class="line">                    pred_max_prob = pred_max_prob[:pred_EOS]</span><br><span class="line"></span><br><span class="line">                # calculate confidence score (= multiply of pred_max_prob)</span><br><span class="line">                confidence_score = pred_max_prob.cumprod(dim=0)[-1]</span><br><span class="line">                #</span><br><span class="line">                # print(f&apos;&#123;img_name:25s&#125;\t&#123;pred:25s&#125;\t&#123;confidence_score:0.4f&#125;&apos;)</span><br><span class="line">                # 拼接：文件名称:值</span><br><span class="line">                value = img_name + &quot;:&quot; + pred</span><br><span class="line">                valuetemp.append(value)</span><br><span class="line">                log.write(f&apos;&#123;img_name:25s&#125;\t&#123;pred:25s&#125;\t&#123;confidence_score:0.4f&#125;\n&apos;)</span><br><span class="line"></span><br><span class="line">            log.close()</span><br><span class="line"></span><br><span class="line">    # 遍历image_path_list</span><br><span class="line">    for i in image_path_list:</span><br><span class="line">        image_path = i.split(&apos;/&apos;)[1].split(&apos;_&apos;)[0]</span><br><span class="line">        # 开始处理临时储存</span><br><span class="line">        # 用于储存同一种的文件</span><br><span class="line">        onePicture = []</span><br><span class="line">        # 遍历添加</span><br><span class="line">        for v in valuetemp:</span><br><span class="line">            if v.split(&apos;/&apos;)[1].split(&apos;_&apos;)[0] == image_path:</span><br><span class="line">                # 得到一张图片的所有信息</span><br><span class="line">                onePicture.append(v)</span><br><span class="line">        # 根据.jpg的最后一个字符排序</span><br><span class="line">        onePicture.sort(key=lambda x: int(x.split(&apos;.&apos;)[0].split(&apos;_&apos;)[1]))</span><br><span class="line">        # 拼接每张图片</span><br><span class="line">        text = i.split(&apos;/&apos;)[0][:-3] + &apos;/&apos; + i.split(&apos;/&apos;)[1].split(&apos;_&apos;)[0] + &apos;.jpg&apos; + &apos;:&apos;</span><br><span class="line">        # 遍历onePicture</span><br><span class="line">        for o in onePicture:</span><br><span class="line">            text = text + o.split(&apos;:&apos;)[1] + &apos; &apos;</span><br><span class="line">        # 除去尾部空格</span><br><span class="line">        text = text.strip()</span><br><span class="line">        # 拼接完成之后添加</span><br><span class="line">        values.append(text)</span><br><span class="line">    return values</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 识别主程序</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(&apos;--image_folder&apos;, help=&apos;path to image_folder which contains text images&apos;)</span><br><span class="line">    parser.add_argument(&apos;--workers&apos;, type=int, help=&apos;number of data loading workers&apos;, default=4)</span><br><span class="line">    parser.add_argument(&apos;--batch_size&apos;, type=int, default=192, help=&apos;input batch size&apos;)</span><br><span class="line">    parser.add_argument(&apos;--saved_model&apos;, help=&quot;path to saved_model to evaluation&quot;)</span><br><span class="line">    &quot;&quot;&quot; Data processing &quot;&quot;&quot;</span><br><span class="line">    parser.add_argument(&apos;--batch_max_length&apos;, type=int, default=25, help=&apos;maximum-label-length&apos;)</span><br><span class="line">    parser.add_argument(&apos;--imgH&apos;, type=int, default=32, help=&apos;the height of the input image&apos;)</span><br><span class="line">    parser.add_argument(&apos;--imgW&apos;, type=int, default=100, help=&apos;the width of the input image&apos;)</span><br><span class="line">    parser.add_argument(&apos;--rgb&apos;, action=&apos;store_true&apos;, help=&apos;use rgb input&apos;)</span><br><span class="line">    parser.add_argument(&apos;--character&apos;, type=str, default=&apos;0123456789abcdefghijklmnopqrstuvwxyz&apos;, help=&apos;character label&apos;)</span><br><span class="line">    parser.add_argument(&apos;--sensitive&apos;, action=&apos;store_true&apos;, help=&apos;for sensitive character mode&apos;)</span><br><span class="line">    parser.add_argument(&apos;--PAD&apos;, action=&apos;store_true&apos;, help=&apos;whether to keep ratio then pad for image resize&apos;)</span><br><span class="line">    &quot;&quot;&quot; Model Architecture &quot;&quot;&quot;</span><br><span class="line">    parser.add_argument(&apos;--Transformation&apos;, type=str, help=&apos;Transformation stage. None|TPS&apos;)</span><br><span class="line">    parser.add_argument(&apos;--FeatureExtraction&apos;, type=str, help=&apos;FeatureExtraction stage. VGG|RCNN|ResNet&apos;)</span><br><span class="line">    parser.add_argument(&apos;--SequenceModeling&apos;, type=str, help=&apos;SequenceModeling stage. None|BiLSTM&apos;)</span><br><span class="line">    parser.add_argument(&apos;--Prediction&apos;, type=str, help=&apos;Prediction stage. CTC|Attn&apos;)</span><br><span class="line">    parser.add_argument(&apos;--num_fiducial&apos;, type=int, default=20, help=&apos;number of fiducial points of TPS-STN&apos;)</span><br><span class="line">    parser.add_argument(&apos;--input_channel&apos;, type=int, default=1, help=&apos;the number of input channel of Feature extractor&apos;)</span><br><span class="line">    parser.add_argument(&apos;--output_channel&apos;, type=int, default=512,</span><br><span class="line">                        help=&apos;the number of output channel of Feature extractor&apos;)</span><br><span class="line">    parser.add_argument(&apos;--hidden_size&apos;, type=int, default=256, help=&apos;the size of the LSTM hidden state&apos;)</span><br><span class="line"></span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line">    # 更改这里的位置</span><br><span class="line">    opt.image_folder = &apos;twoout/&apos;</span><br><span class="line">    &quot;&quot;&quot; vocab / character number configuration &quot;&quot;&quot;</span><br><span class="line">    if opt.sensitive:</span><br><span class="line">        opt.character = string.printable[:-6]  # same with ASTER setting (use 94 char).</span><br><span class="line"></span><br><span class="line">    cudnn.benchmark = True</span><br><span class="line">    cudnn.deterministic = True</span><br><span class="line">    opt.num_gpu = torch.cuda.device_count()</span><br><span class="line"></span><br><span class="line">    print(opt)</span><br><span class="line">    demo(opt)</span><br><span class="line"></span><br><span class="line">    values = demo(opt)</span><br><span class="line">    # 除去重复元素</span><br><span class="line">    values = list(set(values))</span><br><span class="line">    # 排序</span><br><span class="line">    values.sort(key=lambda x: int(x.split(&apos;/&apos;)[1].split(&apos;.&apos;)[0]))</span><br><span class="line">    for v in values:</span><br><span class="line">        print(v)</span><br></pre></td></tr></table></figure>

<p>5：paddle_ocr（微型模型，中英文混用，效果略优；通用模型也可以）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1：优势在于部署的时候有微型模型，中英文混用，速度快。</span><br><span class="line">2：适用于对精度要求不是特别高的场合</span><br><span class="line">3：免费</span><br><span class="line">4：部署简单</span><br></pre></td></tr></table></figure>


      
    </div>
    
    
    

	<div>
  
    ﻿<div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
  
</div>

    

		

    

    


	
    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/05/06/%E9%98%BF%E9%87%8C%E4%BA%91%E5%87%BD%E6%95%B0%E8%AE%A1%E7%AE%97/" rel="next" title="阿里云函数计算">
                <i class="fa fa-chevron-left"></i> 阿里云函数计算
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/05/22/%E5%80%BE%E6%96%9C%E6%A0%A1%E6%AD%A3%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93%E5%AF%B9%E6%AF%94/" rel="prev" title="倾斜校正相关总结对比">
                倾斜校正相关总结对比 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">鄢玉兵</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">91</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">鄢玉兵</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
