<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="鄢玉兵的博客" type="application/atom+xml" />






<meta name="description" content="从头开始实现算法——Python1:从头开始加载数据 12345678910111213141516171819# 加载数据，这样加载的问题是可能出现空行from csv import reader# Load a CSV filedef load_csv(filename):    file = open(filename, &amp;quot;r&amp;quot;)    lines = reader(fi">
<meta property="og:type" content="article">
<meta property="og:title" content="MachineLearningAlgorithms_Python">
<meta property="og:url" content="https:&#x2F;&#x2F;yanyubing.xyz&#x2F;2020&#x2F;03&#x2F;26&#x2F;MachineLearningAlgorithms_Python&#x2F;index.html">
<meta property="og:site_name" content="鄢玉兵的博客">
<meta property="og:description" content="从头开始实现算法——Python1:从头开始加载数据 12345678910111213141516171819# 加载数据，这样加载的问题是可能出现空行from csv import reader# Load a CSV filedef load_csv(filename):    file = open(filename, &amp;quot;r&amp;quot;)    lines = reader(fi">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2020-03-27T05:32:31.856Z">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://yanyubing.xyz/2020/03/26/MachineLearningAlgorithms_Python/"/>





  <title>MachineLearningAlgorithms_Python | 鄢玉兵的博客</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
<a href="https://yanyubing.xyz"><img width="149" height="149" src="https://github.blog/wp-content/uploads/2008/12/forkme_left_red_aa0000.png?resize=149%2C149" class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">鄢玉兵的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://yanyubing.xyz/2020/03/26/MachineLearningAlgorithms_Python/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="鄢玉兵">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="鄢玉兵的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">MachineLearningAlgorithms_Python</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-03-26T00:28:52+08:00">
                2020-03-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="从头开始实现算法——Python"><a href="#从头开始实现算法——Python" class="headerlink" title="从头开始实现算法——Python"></a>从头开始实现算法——Python</h1><p>1:从头开始加载数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 加载数据，这样加载的问题是可能出现空行</span><br><span class="line"></span><br><span class="line">from csv import reader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Load a CSV file</span><br><span class="line">def load_csv(filename):</span><br><span class="line">    file = open(filename, &quot;r&quot;)</span><br><span class="line">    lines = reader(file)</span><br><span class="line">    dataset = list(lines)</span><br><span class="line">    return dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># load dataset</span><br><span class="line">filename = &apos;pima-indians-diabetes.csv&apos;</span><br><span class="line">dataset = load_csv(filename)</span><br><span class="line"></span><br><span class="line">print(&apos;列：&apos;, len(dataset))</span><br><span class="line">print(&apos;行：&apos;, len(dataset[0]))</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># Example of loading Pima Indians CSV dataset</span><br><span class="line">#防止空行</span><br><span class="line">from csv import reader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Load a CSV file</span><br><span class="line">def load_csv(filename):</span><br><span class="line">    dataset = list()</span><br><span class="line">    with open(filename, &apos;r&apos;) as file:</span><br><span class="line">        csv_reader = reader(file)</span><br><span class="line">        for row in csv_reader:</span><br><span class="line">            if not row:</span><br><span class="line">                continue</span><br><span class="line">            dataset.append(row)</span><br><span class="line">    return dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Load dataset</span><br><span class="line">filename = &apos;pima-indians-diabetes.csv&apos;</span><br><span class="line">dataset = load_csv(filename)</span><br><span class="line">print(&apos;列：&apos;, len(dataset))</span><br><span class="line">print(&apos;行：&apos;, len(dataset[0]))</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># 机器学习中数据一般为数字，浮点型或者整数型,所以需要转换</span><br><span class="line"></span><br><span class="line">from csv import reader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Load a CSV file</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_csv(filename):</span><br><span class="line">    # 这里加rb报错</span><br><span class="line">    file = open(filename, &quot;r&quot;)</span><br><span class="line">    lines = reader(file)</span><br><span class="line">    dataset = list(lines)</span><br><span class="line">    return dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Convert string column to float</span><br><span class="line">def str_column_to_float(dataset, column):</span><br><span class="line">    for row in dataset:</span><br><span class="line">        row[column] = float(row[column].strip())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Load pima-indians-diabetes dataset</span><br><span class="line">filename = &apos;pima-indians-diabetes.csv&apos;</span><br><span class="line">dataset = load_csv(filename)</span><br><span class="line">print(dataset[0])</span><br><span class="line"># convert string columns to float</span><br><span class="line">for i in range(len(dataset[0])):</span><br><span class="line">    str_column_to_float(dataset, i)</span><br><span class="line">print(dataset[0])</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"># 机器学习中，有时候需要结果数据为0,1,2类型，而不是字符串,所以需要转换</span><br><span class="line">from csv import reader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Load a CSV file</span><br><span class="line">def load_csv(filename):</span><br><span class="line">    file = open(filename, &quot;r&quot;)</span><br><span class="line">    lines = reader(file)</span><br><span class="line">    dataset = list(lines)</span><br><span class="line">    return dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Convert string column to float</span><br><span class="line">def str_column_to_float(dataset, column):</span><br><span class="line">    for row in dataset:</span><br><span class="line">        row[column] = float(row[column].strip())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Convert string column to integer</span><br><span class="line">def str_column_to_int(dataset, column):</span><br><span class="line">    class_values = [row[column] for row in dataset]</span><br><span class="line">    unique = set(class_values)</span><br><span class="line">    lookup = dict()</span><br><span class="line">    # 这里进行了转换</span><br><span class="line">    for i, value in enumerate(unique):</span><br><span class="line">        lookup[value] = i</span><br><span class="line">    for row in dataset:</span><br><span class="line">        row[column] = lookup[row[column]]</span><br><span class="line">    return lookup</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Load iris dataset</span><br><span class="line">filename = &apos;iris.csv&apos;</span><br><span class="line">dataset = load_csv(filename)</span><br><span class="line">print(dataset[0])</span><br><span class="line"># convert string columns to float</span><br><span class="line">for i in range(4):</span><br><span class="line">    # 这里直接使用的函数，因为前面已经实现过</span><br><span class="line">    str_column_to_float(dataset, i)</span><br><span class="line"># convert class column to int</span><br><span class="line">lookup = str_column_to_int(dataset, 4)</span><br><span class="line">print(dataset[0])</span><br><span class="line">print(lookup)</span><br></pre></td></tr></table></figure>

<p>2:从头开始缩放数据</p>
<p>规范化数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"># 使数据分在0-1之间</span><br><span class="line">from csv import reader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Load a CSV file</span><br><span class="line">def load_csv(filename):</span><br><span class="line">    file = open(filename, &quot;r&quot;)</span><br><span class="line">    lines = reader(file)</span><br><span class="line">    dataset = list(lines)</span><br><span class="line">    return dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Convert string column to float</span><br><span class="line">def str_column_to_float(dataset, column):</span><br><span class="line">    for row in dataset:</span><br><span class="line">        row[column] = float(row[column].strip())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Find the min and max values for each column</span><br><span class="line">def dataset_minmax(dataset):</span><br><span class="line">    minmax = list()</span><br><span class="line">    for i in range(len(dataset[0])):</span><br><span class="line">        col_values = [row[i] for row in dataset]</span><br><span class="line">        value_min = min(col_values)</span><br><span class="line">        value_max = max(col_values)</span><br><span class="line">        minmax.append([value_min, value_max])</span><br><span class="line">    return minmax</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Rescale dataset columns to the range 0-1</span><br><span class="line">def normalize_dataset(dataset, minmax):</span><br><span class="line">    for row in dataset:</span><br><span class="line">        for i in range(len(row)):</span><br><span class="line">            # 核心转换步骤</span><br><span class="line">            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Load pima-indians-diabetes dataset</span><br><span class="line">filename = &apos;pima-indians-diabetes.csv&apos;</span><br><span class="line">dataset = load_csv(filename)</span><br><span class="line"># convert string columns to float</span><br><span class="line">for i in range(len(dataset[0])):</span><br><span class="line">    str_column_to_float(dataset, i)</span><br><span class="line">print(dataset[0])</span><br><span class="line"># Calculate min and max for each column</span><br><span class="line">minmax = dataset_minmax(dataset)</span><br><span class="line"># Normalize columns</span><br><span class="line">normalize_dataset(dataset, minmax)</span><br><span class="line">print(dataset[0])</span><br></pre></td></tr></table></figure>

<p>标准化数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"># 标准化是一种重新缩放技术，是指将数据的分布集中在值0上，标准偏差集中在值1上。</span><br><span class="line">from csv import reader</span><br><span class="line">from math import sqrt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Load a CSV file</span><br><span class="line">def load_csv(filename):</span><br><span class="line">    file = open(filename, &quot;r&quot;)</span><br><span class="line">    lines = reader(file)</span><br><span class="line">    dataset = list(lines)</span><br><span class="line">    return dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Convert string column to float</span><br><span class="line">def str_column_to_float(dataset, column):</span><br><span class="line">    for row in dataset:</span><br><span class="line">        row[column] = float(row[column].strip())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># calculate column means</span><br><span class="line">def column_means(dataset):</span><br><span class="line">    means = [0 for i in range(len(dataset[0]))]</span><br><span class="line">    for i in range(len(dataset[0])):</span><br><span class="line">        col_values = [row[i] for row in dataset]</span><br><span class="line">        means[i] = sum(col_values) / float(len(dataset))</span><br><span class="line">    return means</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># calculate column standard deviations</span><br><span class="line">def column_stdevs(dataset, means):</span><br><span class="line">    stdevs = [0 for i in range(len(dataset[0]))]</span><br><span class="line">    for i in range(len(dataset[0])):</span><br><span class="line">        variance = [pow(row[i] - means[i], 2) for row in dataset]</span><br><span class="line">        stdevs[i] = sum(variance)</span><br><span class="line">    stdevs = [sqrt(x / (float(len(dataset) - 1))) for x in stdevs]</span><br><span class="line">    return stdevs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># standardize dataset</span><br><span class="line">def standardize_dataset(dataset, means, stdevs):</span><br><span class="line">    for row in dataset:</span><br><span class="line">        for i in range(len(row)):</span><br><span class="line">            row[i] = (row[i] - means[i]) / stdevs[i]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Load pima-indians-diabetes dataset</span><br><span class="line">filename = &apos;pima-indians-diabetes.csv&apos;</span><br><span class="line">dataset = load_csv(filename)</span><br><span class="line"># convert string columns to float</span><br><span class="line">for i in range(len(dataset[0])):</span><br><span class="line">    str_column_to_float(dataset, i)</span><br><span class="line">print(dataset[0])</span><br><span class="line"># Estimate mean and standard deviation</span><br><span class="line">means = column_means(dataset)</span><br><span class="line">stdevs = column_stdevs(dataset, means)</span><br><span class="line"># standardize dataset</span><br><span class="line">standardize_dataset(dataset, means, stdevs)</span><br><span class="line">print(dataset[0])</span><br></pre></td></tr></table></figure>

<p>何时标准化或者规范化数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Standardization is a scaling technique that assumes your data conforms to a normal distribution.</span><br><span class="line"></span><br><span class="line">If a given data attribute is normal or close to normal, this is probably the scaling method to use.</span><br><span class="line"></span><br><span class="line">It is good practice to record the summary statistics used in the standardization process, so that you can apply them when standardizing data in the future that you may want to use with your model.</span><br><span class="line"></span><br><span class="line">Normalization is a scaling technique that does not assume any specific distribution.</span><br><span class="line"></span><br><span class="line">If your data is not normally distributed, consider normalizing it prior to applying your machine learning algorithm.</span><br><span class="line"></span><br><span class="line">It is good practice to record the minimum and maximum values for each column used in the normalization process, again, in case you need to normalize new data in the future to be used with your model.</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Extensions</span><br><span class="line">There are many other data transforms you could apply.</span><br><span class="line"></span><br><span class="line">The idea of data transforms is to best expose the structure of your problem in your data to the learning algorithm.</span><br><span class="line"></span><br><span class="line">It may not be clear what transforms are required upfront. A combination of trial and error and exploratory data analysis (plots and stats) can help tease out what may work.</span><br><span class="line"></span><br><span class="line">Below are some additional transforms you may want to consider researching and implementing:</span><br><span class="line"></span><br><span class="line">Normalization that permits a configurable range, such as -1 to 1 and more.</span><br><span class="line">Standardization that permits a configurable spread, such as 1, 2 or more standard deviations from the mean.</span><br><span class="line">Exponential transforms such as logarithm, square root and exponents.</span><br><span class="line">Power transforms such as box-cox for fixing the skew in normally distributed data.</span><br></pre></td></tr></table></figure>

<p>3:从头开始重采样技术</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">The goal of predictive modeling is to create models that make good predictions on new data.</span><br><span class="line"></span><br><span class="line">We don’t have access to this new data at the time of training, so we must use statistical methods to estimate the performance of a model on new data.</span><br></pre></td></tr></table></figure>

<p>训练集和测试集的拆分</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">from random import seed</span><br><span class="line">from random import randrange</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Split a dataset into a train and test set</span><br><span class="line">def train_test_split(dataset, split=0.60):</span><br><span class="line">    train = list()</span><br><span class="line">    train_size = split * len(dataset)</span><br><span class="line">    dataset_copy = list(dataset)</span><br><span class="line">    while len(train) &lt; train_size:</span><br><span class="line">        index = randrange(len(dataset_copy))</span><br><span class="line">        train.append(dataset_copy.pop(index))</span><br><span class="line">    return train, dataset_copy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># test train/test split</span><br><span class="line"># 随机种子，随机种子相同时，结果相同</span><br><span class="line">seed(1)</span><br><span class="line">dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]</span><br><span class="line">train, test = train_test_split(dataset)</span><br><span class="line">print(train)</span><br><span class="line">print(test)</span><br></pre></td></tr></table></figure>

<p>k倍交叉验证拆分</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 直接切分可能参数噪声干扰偏差，所有采用K倍交叉验证的方式切分数据集</span><br><span class="line"># 1:将数据集切分成k份，训练集为k-1的部分，测试集为余下的第k份；</span><br><span class="line"># 重复此过程，保证每一组都可以成为验证集</span><br><span class="line"># 数据集大的时候采用10倍交叉验证，数据集小采用3倍交叉验证</span><br><span class="line">from random import seed</span><br><span class="line">from random import randrange</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Split a dataset into k folds</span><br><span class="line">def cross_validation_split(dataset, folds=3):</span><br><span class="line">    dataset_split = list()</span><br><span class="line">    dataset_copy = list(dataset)</span><br><span class="line">    fold_size = int(len(dataset) / folds)</span><br><span class="line">    for i in range(folds):</span><br><span class="line">        fold = list()</span><br><span class="line">        while len(fold) &lt; fold_size:</span><br><span class="line">            index = randrange(len(dataset_copy))</span><br><span class="line">            fold.append(dataset_copy.pop(index))</span><br><span class="line">        dataset_split.append(fold)</span><br><span class="line">    return dataset_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># test cross validation split</span><br><span class="line">seed(1)</span><br><span class="line">dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]</span><br><span class="line">folds = cross_validation_split(dataset, 4)</span><br><span class="line">print(folds)</span><br></pre></td></tr></table></figure>

<p>怎么选择重采样模型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">数据小，执行速度快就采用切分方式；数据集大，需要精度高，则采用K倍交叉验证</span><br></pre></td></tr></table></figure>

<p>4：从头开始学习指标</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">用于评估模型的好坏</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1：准确度</span><br><span class="line">2：混淆矩阵</span><br><span class="line">3：平均绝对误差</span><br><span class="line">4：均方误差</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 1:准确度</span><br><span class="line"># 准确的结果值与所有预测的比值</span><br><span class="line"># Calculate accuracy percentage between two lists</span><br><span class="line"></span><br><span class="line">def accuracy_metric(actual, predicted):</span><br><span class="line">    correct = 0</span><br><span class="line">    for i in range(len(actual)):</span><br><span class="line">        if actual[i] == predicted[i]:</span><br><span class="line">            correct += 1</span><br><span class="line">    return correct / float(len(actual)) * 100.0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Test accuracy</span><br><span class="line">actual = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]</span><br><span class="line">predicted = [0, 1, 0, 0, 0, 1, 0, 1, 1, 1]</span><br><span class="line">accuracy = accuracy_metric(actual, predicted)</span><br><span class="line">print(accuracy)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">2:混淆矩阵</span><br><span class="line"># Example of Calculating and Displaying a Pretty Confusion Matrix</span><br><span class="line"></span><br><span class="line"># calculate a confusion matrix</span><br><span class="line">def confusion_matrix(actual, predicted):</span><br><span class="line">    unique = set(actual)</span><br><span class="line">    matrix = [list() for x in range(len(unique))]</span><br><span class="line">    for i in range(len(unique)):</span><br><span class="line">        matrix[i] = [0 for x in range(len(unique))]</span><br><span class="line">    lookup = dict()</span><br><span class="line">    for i, value in enumerate(unique):</span><br><span class="line">        lookup[value] = i</span><br><span class="line">    for i in range(len(actual)):</span><br><span class="line">        x = lookup[actual[i]]</span><br><span class="line">        y = lookup[predicted[i]]</span><br><span class="line">        matrix[y][x] += 1</span><br><span class="line">    return unique, matrix</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># pretty print a confusion matrix</span><br><span class="line">def print_confusion_matrix(unique, matrix):</span><br><span class="line">    print(&apos;(A)&apos; + &apos; &apos;.join(str(x) for x in unique))</span><br><span class="line">    print(&apos;(P)---&apos;)</span><br><span class="line">    for i, x in enumerate(unique):</span><br><span class="line">        print(&quot;%s| %s&quot; % (x, &apos; &apos;.join(str(x) for x in matrix[i])))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Test confusion matrix with integers</span><br><span class="line">actual = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]</span><br><span class="line">predicted = [0, 1, 1, 0, 0, 1, 0, 1, 1, 1]</span><br><span class="line">unique, matrix = confusion_matrix(actual, predicted)</span><br><span class="line">print_confusion_matrix(unique, matrix)</span><br><span class="line"></span><br><span class="line">输出结果为：</span><br><span class="line">(A)0 1</span><br><span class="line">(P)---</span><br><span class="line">0| 3 1</span><br><span class="line">1| 2 4</span><br><span class="line"></span><br><span class="line">A表示准确值，p表示预测值</span><br><span class="line">上面矩阵表达的是：实际为0，预测为0的个数为3，实际为1，预测为1的个数为4；实际为0，但是预测为0的个数是1，实际为0，但是预测为1的个数为2。即预测准确的为7个，预测错误的为3个。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 平均绝对误差</span><br><span class="line"># MAE = sum( abs(predicted_i - actual_i) ) / total predictions</span><br><span class="line"></span><br><span class="line"># Calculate mean absolute error</span><br><span class="line">def mae_metric(actual, predicted):</span><br><span class="line">    sum_error = 0.0</span><br><span class="line">    for i in range(len(actual)):</span><br><span class="line">        sum_error += abs(predicted[i] - actual[i])</span><br><span class="line">    return sum_error / float(len(actual))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Test RMSE</span><br><span class="line">actual = [0.1, 0.2, 0.3, 0.4, 0.5]</span><br><span class="line">predicted = [0.11, 0.19, 0.29, 0.41, 0.5]</span><br><span class="line">mae = mae_metric(actual, predicted)</span><br><span class="line">print(mae)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># 均方根误差</span><br><span class="line"># RMSE = sqrt( sum( (predicted_i - actual_i)^2 ) / total predictions)</span><br><span class="line"></span><br><span class="line">from math import sqrt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Calculate root mean squared error</span><br><span class="line">def rmse_metric(actual, predicted):</span><br><span class="line">    sum_error = 0.0</span><br><span class="line">    for i in range(len(actual)):</span><br><span class="line">        prediction_error = predicted[i] - actual[i]</span><br><span class="line">        sum_error += (prediction_error ** 2)</span><br><span class="line">    mean_error = sum_error / float(len(actual))</span><br><span class="line">    return sqrt(mean_error)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Test RMSE</span><br><span class="line">actual = [0.1, 0.2, 0.3, 0.4, 0.5]</span><br><span class="line">predicted = [0.11, 0.19, 0.29, 0.41, 0.5]</span><br><span class="line">rmse = rmse_metric(actual, predicted)</span><br><span class="line">print(rmse)</span><br></pre></td></tr></table></figure>

<p>5：基线算法</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">基线算法：假设基线算法得到的误差值为20%，那么你用到的算法误差值则需要比20%小，才说明算法有用！</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. Random Prediction Algorithm</span><br><span class="line">2. Zero Rule Algorithm</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">These steps will provide the foundations you need to handle implementing and calculating baseline performance for your machine learning algorithms.</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">1. Random Prediction Algorithm</span><br><span class="line"></span><br><span class="line">from random import seed</span><br><span class="line">from random import randrange</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Generate random predictions</span><br><span class="line">def random_algorithm(train, test):</span><br><span class="line">    output_values = [row[-1] for row in train]</span><br><span class="line">    unique = list(set(output_values))</span><br><span class="line">    predicted = list()</span><br><span class="line">    for row in test:</span><br><span class="line">        index = randrange(len(unique))</span><br><span class="line">        predicted.append(unique[index])</span><br><span class="line">    return predicted</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">seed(1)</span><br><span class="line">train = [[0], [1], [0], [1], [0], [1]]</span><br><span class="line">test = [[None], [None], [None], [None]]</span><br><span class="line">predictions = random_algorithm(train, test)</span><br><span class="line">print(predictions)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># The Zero Rule Algorithm is a better baseline than the random algorithm.</span><br><span class="line"># It uses more information about a given problem to create one rule in order to make predictions. This rule is different depending on the problem type.</span><br><span class="line"></span><br><span class="line">2. Zero Rule Algorithm  classification</span><br><span class="line"></span><br><span class="line">from random import seed</span><br><span class="line">from random import randrange</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># zero rule algorithm for classification</span><br><span class="line">def zero_rule_algorithm_classification(train, test):</span><br><span class="line">    output_values = [row[-1] for row in train]</span><br><span class="line">    prediction = max(set(output_values), key=output_values.count)</span><br><span class="line">    predicted = [prediction for i in range(len(train))]</span><br><span class="line">    return predicted</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">seed(1)</span><br><span class="line">train = [[&apos;0&apos;], [&apos;0&apos;], [&apos;0&apos;], [&apos;0&apos;], [&apos;1&apos;], [&apos;1&apos;]]</span><br><span class="line">test = [[None], [None], [None], [None]]</span><br><span class="line">predictions = zero_rule_algorithm_classification(train, test)</span><br><span class="line">print(predictions)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">from random import seed</span><br><span class="line">from random import randrange</span><br><span class="line"># 回归问题，预测平均值</span><br><span class="line"></span><br><span class="line"># zero rule algorithm for regression</span><br><span class="line">def zero_rule_algorithm_regression(train, test):</span><br><span class="line">    output_values = [row[-1] for row in train]</span><br><span class="line">    prediction = sum(output_values) / float(len(output_values))</span><br><span class="line">    predicted = [prediction for i in range(len(test))]</span><br><span class="line">    return predicted</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">seed(1)</span><br><span class="line">train = [[10], [15], [12], [15], [18], [20]]</span><br><span class="line">test = [[None], [None], [None], [None]]</span><br><span class="line">predictions = zero_rule_algorithm_regression(train, test)</span><br><span class="line">print(predictions)</span><br></pre></td></tr></table></figure>

<p>6：从头开始编写测试工具</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">目的：为了检测算法的性能</span><br><span class="line">1:The resampling method to split-up the dataset.</span><br><span class="line">重采样切分数据集</span><br><span class="line">2:The machine learning algorithm to evaluate.</span><br><span class="line">算法的计算</span><br><span class="line">3:The performance measure by which to evaluate predictions.</span><br><span class="line">用于评估预测的绩效指标</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">测试工具必须允许对不同的机器学习算法进行评估，同时数据集，重采样方法和性能指标应保持不变。</span><br><span class="line">测试工具分为以下两类，对应不同的重采样方法!</span><br><span class="line">区别是：第一种得到的是准确度，而第二种得到的是平均精度（因为会进行多次验证，保证所有的第k份都为测试集）</span><br><span class="line">1:Train-Test Algorithm Test Harness.</span><br><span class="line">2:Cross-Validation Algorithm Test Harness.</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">#1: Train-Test Test Harness</span><br><span class="line">from random import seed</span><br><span class="line">from random import randrange</span><br><span class="line">from csv import reader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Load a CSV file</span><br><span class="line"># 加载文件</span><br><span class="line">def load_csv(filename):</span><br><span class="line">    file = open(filename, &quot;r&quot;)</span><br><span class="line">    lines = reader(file)</span><br><span class="line">    dataset = list(lines)</span><br><span class="line">    return dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 字符串转换</span><br><span class="line"># Convert string column to float</span><br><span class="line">def str_column_to_float(dataset, column):</span><br><span class="line">    for row in dataset:</span><br><span class="line">        row[column] = float(row[column].strip())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 数据集的切割</span><br><span class="line"># Split a dataset into a train and test set</span><br><span class="line">def train_test_split(dataset, split):</span><br><span class="line">    train = list()</span><br><span class="line">    train_size = split * len(dataset)</span><br><span class="line">    dataset_copy = list(dataset)</span><br><span class="line">    while len(train) &lt; train_size:</span><br><span class="line">        index = randrange(len(dataset_copy))</span><br><span class="line">        train.append(dataset_copy.pop(index))</span><br><span class="line">    return train, dataset_copy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 计算准确度</span><br><span class="line"># Calculate accuracy percentage</span><br><span class="line">def accuracy_metric(actual, predicted):</span><br><span class="line">    correct = 0</span><br><span class="line">    for i in range(len(actual)):</span><br><span class="line">        if actual[i] == predicted[i]:</span><br><span class="line">            correct += 1</span><br><span class="line">    return correct / float(len(actual)) * 100.0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 使用train/split切割评估算法</span><br><span class="line"># Evaluate an algorithm using a train/test split</span><br><span class="line"></span><br><span class="line"># 使用到的函数有切割(),算法函数,准确度评估函数</span><br><span class="line">def evaluate_algorithm(dataset, algorithm, split, *args):</span><br><span class="line">    train, test = train_test_split(dataset, split)</span><br><span class="line">    test_set = list()</span><br><span class="line">    for row in test:</span><br><span class="line">        row_copy = list(row)</span><br><span class="line">        row_copy[-1] = None</span><br><span class="line">        test_set.append(row_copy)</span><br><span class="line">    predicted = algorithm(train, test_set, *args)</span><br><span class="line">    actual = [row[-1] for row in test]</span><br><span class="line">    accuracy = accuracy_metric(actual, predicted)</span><br><span class="line">    return accuracy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 分类问题的0规则算法</span><br><span class="line"># zero rule algorithm for classification</span><br><span class="line">def zero_rule_algorithm_classification(train, test):</span><br><span class="line">    output_values = [row[-1] for row in train]</span><br><span class="line">    prediction = max(set(output_values), key=output_values.count)</span><br><span class="line">    predicted = [prediction for i in range(len(test))]</span><br><span class="line">    return predicted</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Test the zero rule algorithm on the diabetes dataset</span><br><span class="line">seed(1)</span><br><span class="line"># load and prepare data</span><br><span class="line">filename = &apos;pima-indians-diabetes.csv&apos;</span><br><span class="line">dataset = load_csv(filename)</span><br><span class="line">for i in range(len(dataset[0])):</span><br><span class="line">    str_column_to_float(dataset, i)</span><br><span class="line"># evaluate algorithm</span><br><span class="line">split = 0.6</span><br><span class="line"># 评估0规则的分类算法</span><br><span class="line">accuracy = evaluate_algorithm(dataset, zero_rule_algorithm_classification, split)</span><br><span class="line">print(&apos;Accuracy: %.3f%%&apos; % (accuracy))</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"># 2：Cross-Validation Algorithm Test Harness</span><br><span class="line"></span><br><span class="line"># Cross Validation Test Harness</span><br><span class="line">from random import seed</span><br><span class="line">from random import randrange</span><br><span class="line">from csv import reader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Load a CSV file</span><br><span class="line">def load_csv(filename):</span><br><span class="line">    file = open(filename, &quot;r&quot;)</span><br><span class="line">    lines = reader(file)</span><br><span class="line">    dataset = list(lines)</span><br><span class="line">    return dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Convert string column to float</span><br><span class="line">def str_column_to_float(dataset, column):</span><br><span class="line">    for row in dataset:</span><br><span class="line">        row[column] = float(row[column].strip())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Split a dataset into k folds，使用K被交叉方式切割</span><br><span class="line">def cross_validation_split(dataset, n_folds):</span><br><span class="line">    dataset_split = list()</span><br><span class="line">    dataset_copy = list(dataset)</span><br><span class="line">    fold_size = int(len(dataset) / n_folds)</span><br><span class="line">    for i in range(n_folds):</span><br><span class="line">        fold = list()</span><br><span class="line">        while len(fold) &lt; fold_size:</span><br><span class="line">            index = randrange(len(dataset_copy))</span><br><span class="line">            fold.append(dataset_copy.pop(index))</span><br><span class="line">        dataset_split.append(fold)</span><br><span class="line">    return dataset_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Calculate accuracy percentage</span><br><span class="line">def accuracy_metric(actual, predicted):</span><br><span class="line">    correct = 0</span><br><span class="line">    for i in range(len(actual)):</span><br><span class="line">        if actual[i] == predicted[i]:</span><br><span class="line">            correct += 1</span><br><span class="line">    return correct / float(len(actual)) * 100.0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Evaluate an algorithm using a cross validation split</span><br><span class="line">def evaluate_algorithm(dataset, algorithm, n_folds, *args):</span><br><span class="line">    folds = cross_validation_split(dataset, n_folds)</span><br><span class="line">    scores = list()</span><br><span class="line">    for fold in folds:</span><br><span class="line">        train_set = list(folds)</span><br><span class="line">        train_set.remove(fold)</span><br><span class="line">        train_set = sum(train_set, [])</span><br><span class="line">        test_set = list()</span><br><span class="line">        for row in fold:</span><br><span class="line">            row_copy = list(row)</span><br><span class="line">            test_set.append(row_copy)</span><br><span class="line">            row_copy[-1] = None</span><br><span class="line">        predicted = algorithm(train_set, test_set, *args)</span><br><span class="line">        actual = [row[-1] for row in fold]</span><br><span class="line">        accuracy = accuracy_metric(actual, predicted)</span><br><span class="line">        scores.append(accuracy)</span><br><span class="line">    return scores</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># zero rule algorithm for classification</span><br><span class="line">def zero_rule_algorithm_classification(train, test):</span><br><span class="line">    output_values = [row[-1] for row in train]</span><br><span class="line">    prediction = max(set(output_values), key=output_values.count)</span><br><span class="line">    predicted = [prediction for i in range(len(test))]</span><br><span class="line">    return predicted</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Test the zero rule algorithm on the diabetes dataset</span><br><span class="line">seed(1)</span><br><span class="line"># load and prepare data</span><br><span class="line">filename = &apos;pima-indians-diabetes.csv&apos;</span><br><span class="line">dataset = load_csv(filename)</span><br><span class="line">for i in range(len(dataset[0])):</span><br><span class="line">    str_column_to_float(dataset, i)</span><br><span class="line"># evaluate algorithm</span><br><span class="line">n_folds = 5</span><br><span class="line">scores = evaluate_algorithm(dataset, zero_rule_algorithm_classification, n_folds)</span><br><span class="line">print(&apos;Scores: %s&apos; % scores)</span><br><span class="line">print(&apos;Mean Accuracy: %.3f%%&apos; % (sum(scores) / len(scores)))</span><br></pre></td></tr></table></figure>

<p>7：从头开始实现线性回归</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 简单线性回归,目标就是计算B0和B1的值</span><br><span class="line"># y = b0 + b1 * x</span><br><span class="line"># B1 = sum((x(i) - mean(x)) * (y(i) - mean(y))) / sum( (x(i) - mean(x))^2 )</span><br><span class="line"># B0 = mean(y) - B1 * mean(x)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">步骤为：</span><br><span class="line">1:Calculate Mean and Variance.</span><br><span class="line">2:Calculate Covariance.</span><br><span class="line">3:Estimate Coefficients.</span><br><span class="line">4:Make Predictions.</span><br><span class="line">5:Predict Insurance.</span><br><span class="line">计算均值和方差。</span><br><span class="line">计算协方差。</span><br><span class="line">估计系数。</span><br><span class="line">作出预测。</span><br><span class="line">预测保险。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"># 简单线性回归，目标就是求出B1和B0</span><br><span class="line"># y = b0 + b1 * x</span><br><span class="line"># B1 = sum((x(i) - mean(x)) * (y(i) - mean(y))) / sum( (x(i) - mean(x))^2 )</span><br><span class="line"># B0 = mean(y) - B1 * mean(x)</span><br><span class="line"></span><br><span class="line"># 计算均值和方差。</span><br><span class="line"># mean(x) = sum(x) / count(x)</span><br><span class="line"># variance = sum( (x - mean(x))^2 )</span><br><span class="line"></span><br><span class="line"># 计算协方差。</span><br><span class="line"># covariance = sum((x(i) - mean(x)) * (y(i) - mean(y)))</span><br><span class="line"></span><br><span class="line"># 估计系数。</span><br><span class="line"># B1 = sum((x(i) - mean(x)) * (y(i) - mean(y))) / sum( (x(i) - mean(x))^2 )</span><br><span class="line"># B1 = covariance(x, y) / variance(x)</span><br><span class="line"># B0 = mean(y) - B1 * mean(x)</span><br><span class="line"></span><br><span class="line"># 作出预测。</span><br><span class="line"># y = b0 + b1 * x</span><br><span class="line"></span><br><span class="line"># 预测保险。</span><br><span class="line"># RMSE 均方根误差</span><br><span class="line"></span><br><span class="line"># Simple Linear Regression on the Swedish Insurance Dataset</span><br><span class="line">from random import seed</span><br><span class="line">from random import randrange</span><br><span class="line">from csv import reader</span><br><span class="line">from math import sqrt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Load a CSV file</span><br><span class="line">def load_csv(filename):</span><br><span class="line">    dataset = list()</span><br><span class="line">    with open(filename, &apos;r&apos;) as file:</span><br><span class="line">        csv_reader = reader(file)</span><br><span class="line">        for row in csv_reader:</span><br><span class="line">            if not row:</span><br><span class="line">                continue</span><br><span class="line">            dataset.append(row)</span><br><span class="line">    return dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Convert string column to float</span><br><span class="line">def str_column_to_float(dataset, column):</span><br><span class="line">    for row in dataset:</span><br><span class="line">        row[column] = float(row[column].strip())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Split a dataset into a train and test set</span><br><span class="line">def train_test_split(dataset, split):</span><br><span class="line">    train = list()</span><br><span class="line">    train_size = split * len(dataset)</span><br><span class="line">    dataset_copy = list(dataset)</span><br><span class="line">    while len(train) &lt; train_size:</span><br><span class="line">        index = randrange(len(dataset_copy))</span><br><span class="line">        train.append(dataset_copy.pop(index))</span><br><span class="line">    return train, dataset_copy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Calculate root mean squared error</span><br><span class="line">def rmse_metric(actual, predicted):</span><br><span class="line">    sum_error = 0.0</span><br><span class="line">    for i in range(len(actual)):</span><br><span class="line">        prediction_error = predicted[i] - actual[i]</span><br><span class="line">        sum_error += (prediction_error ** 2)</span><br><span class="line">    mean_error = sum_error / float(len(actual))</span><br><span class="line">    return sqrt(mean_error)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Evaluate an algorithm using a train/test split</span><br><span class="line">def evaluate_algorithm(dataset, algorithm, split, *args):</span><br><span class="line">    train, test = train_test_split(dataset, split)</span><br><span class="line">    test_set = list()</span><br><span class="line">    for row in test:</span><br><span class="line">        row_copy = list(row)</span><br><span class="line">        row_copy[-1] = None</span><br><span class="line">        test_set.append(row_copy)</span><br><span class="line">    predicted = algorithm(train, test_set, *args)</span><br><span class="line">    actual = [row[-1] for row in test]</span><br><span class="line">    rmse = rmse_metric(actual, predicted)</span><br><span class="line">    return rmse</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Calculate the mean value of a list of numbers</span><br><span class="line">def mean(values):</span><br><span class="line">    return sum(values) / float(len(values))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Calculate covariance between x and y</span><br><span class="line">def covariance(x, mean_x, y, mean_y):</span><br><span class="line">    covar = 0.0</span><br><span class="line">    for i in range(len(x)):</span><br><span class="line">        covar += (x[i] - mean_x) * (y[i] - mean_y)</span><br><span class="line">    return covar</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Calculate the variance of a list of numbers</span><br><span class="line">def variance(values, mean):</span><br><span class="line">    return sum([(x - mean) ** 2 for x in values])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Calculate coefficients，返回B0和B1</span><br><span class="line">def coefficients(dataset):</span><br><span class="line">    x = [row[0] for row in dataset]</span><br><span class="line">    y = [row[1] for row in dataset]</span><br><span class="line">    x_mean, y_mean = mean(x), mean(y)</span><br><span class="line">    b1 = covariance(x, x_mean, y, y_mean) / variance(x, x_mean)</span><br><span class="line">    b0 = y_mean - b1 * x_mean</span><br><span class="line">    return [b0, b1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Simple linear regression algorithm</span><br><span class="line"># 训练集最终得到参数B0和B1，得到方程，并且进行预测，返回值为预测值</span><br><span class="line">def simple_linear_regression(train, test):</span><br><span class="line">    predictions = list()</span><br><span class="line">    b0, b1 = coefficients(train)</span><br><span class="line">    for row in test:</span><br><span class="line">        yhat = b0 + b1 * row[0]</span><br><span class="line">        predictions.append(yhat)</span><br><span class="line">    return predictions</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Simple linear regression on insurance dataset</span><br><span class="line">seed(1)</span><br><span class="line"># load and prepare data</span><br><span class="line">filename = &apos;insurance.csv&apos;</span><br><span class="line">dataset = load_csv(filename)</span><br><span class="line">for i in range(len(dataset[0])):</span><br><span class="line">    str_column_to_float(dataset, i)</span><br><span class="line"># evaluate algorithm</span><br><span class="line">split = 0.6</span><br><span class="line">rmse = evaluate_algorithm(dataset, simple_linear_regression, split)</span><br><span class="line">print(&apos;RMSE: %.3f&apos; % (rmse))</span><br></pre></td></tr></table></figure>

<p>8：从头开始实现逻辑回归</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">How to make predictions with a logistic regression model.</span><br><span class="line">How to estimate coefficients using stochastic gradient descent.</span><br><span class="line">How to apply logistic regression to a real prediction problem.</span><br><span class="line">如何使用逻辑回归模型进行预测。</span><br><span class="line">如何使用随机梯度下降法估算系数。</span><br><span class="line">如何将逻辑回归应用于实际的预测问题。</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br></pre></td><td class="code"><pre><span class="line"># A key difference from linear regression is that the output value being modeled is a binary value (0 or 1) rather than a numeric value.</span><br><span class="line"># 逻辑回归的输出值是0-1之间的数，和线性输出的整数值不一样</span><br><span class="line"># yhat = e^(b0 + b1 * x1) / (1 + e^(b0 + b1 * x1))</span><br><span class="line"># yhat = 1.0 / (1.0 + e^(-(b0 + b1 * x1)))</span><br><span class="line"></span><br><span class="line"># Stochastic Gradient Descent（随机梯度下降）</span><br><span class="line"># Gradient Descent is the process of minimizing a function by following the gradients of the cost function.</span><br><span class="line"># This involves knowing the form of the cost as well as the derivative so that from a given point you know the gradient and can move in that direction, e.g. downhill towards the minimum value.</span><br><span class="line"># In machine learning, we can use a technique that evaluates and updates the coefficients every iteration called stochastic gradient descent to minimize the error of a model on our training data.</span><br><span class="line"># The way this optimization algorithm works is that each training instance is shown to the model one at a time. The model makes a prediction for a training instance, the error is calculated and the model is updated in order to reduce the error for the next prediction.</span><br><span class="line"># This procedure can be used to find the set of coefficients in a model that result in the smallest error for the model on the training data. Each iteration, the coefficients (b) in machine learning language are updated using the equation:</span><br><span class="line"></span><br><span class="line"># 最终:b = b + learning_rate * (y - yhat) * yhat * (1 - yhat) * x</span><br><span class="line"></span><br><span class="line"># 1:Making Predictions.（做出预测）</span><br><span class="line"># 2:Estimating Coefficients.（求出参数）</span><br><span class="line"># 3:Diabetes Prediction.（预测）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Logistic Regression on Diabetes Dataset</span><br><span class="line">from random import seed</span><br><span class="line">from random import randrange</span><br><span class="line">from csv import reader</span><br><span class="line">from math import exp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Load a CSV file</span><br><span class="line"># 读取文件</span><br><span class="line">def load_csv(filename):</span><br><span class="line">    dataset = list()</span><br><span class="line">    with open(filename, &apos;r&apos;) as file:</span><br><span class="line">        csv_reader = reader(file)</span><br><span class="line">        for row in csv_reader:</span><br><span class="line">            if not row:</span><br><span class="line">                continue</span><br><span class="line">            dataset.append(row)</span><br><span class="line">    return dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 字符串转换</span><br><span class="line"># Convert string column to float</span><br><span class="line">def str_column_to_float(dataset, column):</span><br><span class="line">    for row in dataset:</span><br><span class="line">        row[column] = float(row[column].strip())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 找到最大值和最小值，为了进行转换</span><br><span class="line"># Find the min and max values for each column</span><br><span class="line">def dataset_minmax(dataset):</span><br><span class="line">    minmax = list()</span><br><span class="line">    for i in range(len(dataset[0])):</span><br><span class="line">        col_values = [row[i] for row in dataset]</span><br><span class="line">        value_min = min(col_values)</span><br><span class="line">        value_max = max(col_values)</span><br><span class="line">        minmax.append([value_min, value_max])</span><br><span class="line">    return minmax</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 数据转换</span><br><span class="line"># Rescale dataset columns to the range 0-1</span><br><span class="line">def normalize_dataset(dataset, minmax):</span><br><span class="line">    for row in dataset:</span><br><span class="line">        for i in range(len(row)):</span><br><span class="line">            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 使用K倍交叉验证</span><br><span class="line"># Split a dataset into k folds</span><br><span class="line">def cross_validation_split(dataset, n_folds):</span><br><span class="line">    dataset_split = list()</span><br><span class="line">    dataset_copy = list(dataset)</span><br><span class="line">    fold_size = int(len(dataset) / n_folds)</span><br><span class="line">    for i in range(n_folds):</span><br><span class="line">        fold = list()</span><br><span class="line">        while len(fold) &lt; fold_size:</span><br><span class="line">            index = randrange(len(dataset_copy))</span><br><span class="line">            fold.append(dataset_copy.pop(index))</span><br><span class="line">        dataset_split.append(fold)</span><br><span class="line">    return dataset_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 计算模型准确度</span><br><span class="line"># Calculate accuracy percentage</span><br><span class="line">def accuracy_metric(actual, predicted):</span><br><span class="line">    correct = 0</span><br><span class="line">    for i in range(len(actual)):</span><br><span class="line">        if actual[i] == predicted[i]:</span><br><span class="line">            correct += 1</span><br><span class="line">    return correct / float(len(actual)) * 100.0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 计算算法的平均准确度</span><br><span class="line"># Evaluate an algorithm using a cross validation split</span><br><span class="line">def evaluate_algorithm(dataset, algorithm, n_folds, *args):</span><br><span class="line">    folds = cross_validation_split(dataset, n_folds)</span><br><span class="line">    scores = list()</span><br><span class="line">    for fold in folds:</span><br><span class="line">        train_set = list(folds)</span><br><span class="line">        train_set.remove(fold)</span><br><span class="line">        train_set = sum(train_set, [])</span><br><span class="line">        test_set = list()</span><br><span class="line">        for row in fold:</span><br><span class="line">            row_copy = list(row)</span><br><span class="line">            test_set.append(row_copy)</span><br><span class="line">            row_copy[-1] = None</span><br><span class="line">        predicted = algorithm(train_set, test_set, *args)</span><br><span class="line">        actual = [row[-1] for row in fold]</span><br><span class="line">        accuracy = accuracy_metric(actual, predicted)</span><br><span class="line">        scores.append(accuracy)</span><br><span class="line">    return scores</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 通过参数进行预测</span><br><span class="line"># Make a prediction with coefficients</span><br><span class="line">def predict(row, coefficients):</span><br><span class="line">    yhat = coefficients[0]</span><br><span class="line">    for i in range(len(row) - 1):</span><br><span class="line">        yhat += coefficients[i + 1] * row[i]</span><br><span class="line">    return 1.0 / (1.0 + exp(-yhat))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 使用随机梯度下降，估算模型的参数</span><br><span class="line"># Estimate logistic regression coefficients using stochastic gradient descent</span><br><span class="line">def coefficients_sgd(train, l_rate, n_epoch):</span><br><span class="line">    coef = [0.0 for i in range(len(train[0]))]</span><br><span class="line">    for epoch in range(n_epoch):</span><br><span class="line">        for row in train:</span><br><span class="line">            yhat = predict(row, coef)</span><br><span class="line">            error = row[-1] - yhat</span><br><span class="line">            coef[0] = coef[0] + l_rate * error * yhat * (1.0 - yhat)</span><br><span class="line">            for i in range(len(row) - 1):</span><br><span class="line">                coef[i + 1] = coef[i + 1] + l_rate * error * yhat * (1.0 - yhat) * row[i]</span><br><span class="line">    return coef</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 线性回归使用随机梯度下降</span><br><span class="line"># Linear Regression Algorithm With Stochastic Gradient Descent</span><br><span class="line">def logistic_regression(train, test, l_rate, n_epoch):</span><br><span class="line">    predictions = list()</span><br><span class="line">    coef = coefficients_sgd(train, l_rate, n_epoch)</span><br><span class="line">    for row in test:</span><br><span class="line">        yhat = predict(row, coef)</span><br><span class="line">        yhat = round(yhat)</span><br><span class="line">        predictions.append(yhat)</span><br><span class="line">    return (predictions)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Test the logistic regression algorithm on the diabetes dataset</span><br><span class="line">seed(1)</span><br><span class="line"># load and prepare data</span><br><span class="line">filename = &apos;pima-indians-diabetes.csv&apos;</span><br><span class="line">dataset = load_csv(filename)</span><br><span class="line">for i in range(len(dataset[0])):</span><br><span class="line">    str_column_to_float(dataset, i)</span><br><span class="line"># normalize</span><br><span class="line">minmax = dataset_minmax(dataset)</span><br><span class="line">normalize_dataset(dataset, minmax)</span><br><span class="line"># evaluate algorithm</span><br><span class="line">n_folds = 5</span><br><span class="line">l_rate = 0.1</span><br><span class="line">n_epoch = 100</span><br><span class="line">scores = evaluate_algorithm(dataset, logistic_regression, n_folds, l_rate, n_epoch)</span><br><span class="line">print(&apos;Scores: %s&apos; % scores)</span><br><span class="line">print(&apos;Mean Accuracy: %.3f%%&apos; % (sum(scores) / float(len(scores))))</span><br></pre></td></tr></table></figure>


      
    </div>
    
    
    

	<div>
  
    ﻿<div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>
  
</div>

    

		

    

    


	
    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/03/25/MachineLearningAlgorithms/" rel="next" title="MachineLearningAlgorithms">
                <i class="fa fa-chevron-left"></i> MachineLearningAlgorithms
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/03/27/MachineLearning_ComputerVision/" rel="prev" title="MachineLearning_ComputerVision">
                MachineLearning_ComputerVision <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">鄢玉兵</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">38</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#从头开始实现算法——Python"><span class="nav-number">1.</span> <span class="nav-text">从头开始实现算法——Python</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">鄢玉兵</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
